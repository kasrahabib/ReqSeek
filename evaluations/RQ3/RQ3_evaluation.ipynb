{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ed1281-7049-4738-ad98-70b94086369d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# common imports\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../datasets/ARID_supporting_scripts\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import mapper\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80864f2-0e6a-4036-8342-da352f0cc31c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation_set = datasets.load_from_disk('../datasets/ARID_supporting_scripts/5_1_training_set')['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729a01b9-91a1-47de-a2f8-4205cebaf59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lbl_ = evaluation_set.features['label'].names\n",
    "label2id = {lbl: idx for idx, lbl in enumerate(lbl_)}\n",
    "id2label = {val: key for key, val in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad080d5-7439-428a-9573-8273b5fefe30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "    return tokenizer(dataset['Requirement Sentences'], padding = 'max_length', max_length = 256, truncation = True, return_tensors = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c10e92d-652e-49d8-a478-237ff259f80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    inputs = {'input_ids': tf.convert_to_tensor(batch['input_ids']),\n",
    "             'attention_mask': tf.convert_to_tensor(batch['attention_mask'])}\n",
    "    true_labels = tf.convert_to_tensor(batch['label'])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model(**inputs)\n",
    "        predicted_labels = tf.argmax(output.logits, axis = -1).numpy()\n",
    "        probas = tf.nn.softmax(output.logits, axis = -1).numpy()\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(true_labels, output.logits)\n",
    "\n",
    "    loss = loss.numpy()\n",
    "\n",
    "    return {\"loss\": loss, \n",
    "            \"y_preds\": [id2label[lbl] for lbl in predicted_labels],\n",
    "            \"y_probas\": [probas[i][predicted_labels[i]] for i in range(len(predicted_labels))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f3d3f14-8d18-45c5-b8c0-c170dce175a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M4 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 14:56:00.516813: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-26 14:56:00.516942: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ../ReqSeek/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "reqseek_path = '../ReqSeek/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(reqseek_path)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(reqseek_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74ba0fe-e3f2-40b8-8519-06f0712023f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mohammadkasrahabib/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.data.path.append(\"/Users/mohammadkasrahabib/nltk_data\")\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def remove_modal_verbs(text):\n",
    "    return re.sub(r'\\b(shall|should|may|will|must)\\b', '', text, flags = re.IGNORECASE)\n",
    "\n",
    "def add_minor_details(text):\n",
    "    nouns = [syn.lemmas()[0].name().replace('_', ' ') for syn in wn.all_synsets('n')]\n",
    "    adjs = [syn.lemmas()[0].name().replace('_', ' ') for syn in wn.all_synsets('a')]\n",
    "    verbs = [syn.lemmas()[0].name().replace('_', ' ') for syn in wn.all_synsets('v')]\n",
    "    patterns = [\n",
    "        lambda: f\"{random.choice(verbs)} {random.choice(adjs)} {random.choice(nouns)}\",\n",
    "        lambda: f\"in order to {random.choice(verbs)} {random.choice(nouns)}\",\n",
    "        lambda: f\"which {random.choice(verbs)} {random.choice(adjs)} {random.choice(nouns)}\",\n",
    "        lambda: f\"with {random.choice(adjs)} {random.choice(nouns)}\",\n",
    "        lambda: f\"for {random.choice(adjs)} {random.choice(nouns)}\"]\n",
    "    phrase = random.choice(patterns)()\n",
    "    ends_with_period = text.strip().endswith('.')\n",
    "    if ends_with_period:\n",
    "        base_text = text.strip()[:-1]\n",
    "        return f\"{base_text} {phrase}.\"\n",
    "    else:\n",
    "        return f\"{text} {phrase}.\"\n",
    "\n",
    "def reorder_words(text, num_swaps = 2):\n",
    "    protected_words = {'shall', 'should', 'will', 'may', 'must'}\n",
    "    if '.' in text:\n",
    "        parts = text.split('.', 1)\n",
    "        main_text = parts[0]\n",
    "        suffix = '.' + parts[1] if parts[1] else '.'\n",
    "    else:\n",
    "        main_text = text\n",
    "        suffix = ''\n",
    "    words = main_text.split(' ')\n",
    "    movable_indices = [\n",
    "        i for i, word in enumerate(words) \n",
    "        if word.lower() not in protected_words\n",
    "    ]\n",
    "    num_swaps = min(num_swaps, max(0, len(movable_indices) - 1))\n",
    "    for _ in range(num_swaps):\n",
    "        i, j = random.sample(movable_indices, 2)\n",
    "        words[i], words[j] = words[j], words[i]\n",
    "    result = ' '.join(words) + suffix\n",
    "    return result\n",
    "\n",
    "def remove_minor_details(text, num_to_pop = 2):\n",
    "    protected_words = {'shall', 'should', 'will', 'may', 'must'}\n",
    "    words = text.split(' ')\n",
    "    removable_indices = [i for i, word in enumerate(words) if word.lower() not in protected_words]\n",
    "    num_to_pop = min(num_to_pop, len(removable_indices))\n",
    "    if num_to_pop > 0:\n",
    "        random_indices = sorted(random.sample(removable_indices, num_to_pop), reverse=True)\n",
    "        for i in random_indices:\n",
    "            words.pop(i)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def apply_transformations_without_sk(text):\n",
    "    text = add_minor_details(text)\n",
    "    text = reorder_words(text)\n",
    "    text = remove_minor_details(text)\n",
    "    return text\n",
    "\n",
    "def apply_transformations(text):\n",
    "    text = remove_modal_verbs(text)\n",
    "    text = add_minor_details(text)\n",
    "    text = reorder_words(text)\n",
    "    text = remove_minor_details(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e294be43-3f5f-44d4-bae0-c297c97b79ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x38e832280> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ab350b901a475bb2bdefbe8ab62bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdccf5ae2f141ea863855a98b27517c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e26a4c2661a416b8f223e4727b417fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ebddec1fc14b90bf107a101225f46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36c3736b2cf4596abf27e9099eda47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_column = 'Requirement Sentences'\n",
    "\n",
    "t0 = evaluation_set\n",
    "t1 = evaluation_set.map(lambda text: {target_column: remove_modal_verbs(text[target_column])})\n",
    "t2 = evaluation_set.map(lambda text: {target_column: add_minor_details(text[target_column])})\n",
    "t3 = evaluation_set.map(lambda text: {target_column: reorder_words(text[target_column])})\n",
    "t4 = evaluation_set.map(lambda text: {target_column: remove_minor_details(text[target_column])})\n",
    "t5_without_sk = evaluation_set.map(lambda text: {target_column: apply_transformations_without_sk(text[target_column])})\n",
    "t5 = evaluation_set.map(lambda text: {target_column: apply_transformations(text[target_column])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c989f404-0463-41b8-8f45-34431512b10a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts = {'T0 -> No Transformation': t0,\n",
    "      'T1 -> Model Verb Removed': t1, \n",
    "      'T2 -> Add Minor Details': t2, \n",
    "      'T3 -> Re-order Words': t3, \n",
    "      'T4 -> Remove Minor Details': t4,\n",
    "      'T5 -> All Transformations Without SK': t5_without_sk,\n",
    "      'T5 -> All Transformations': t5\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e037929-1497-42b7-9d98-878f498e2bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://64adb73e-8634-440f-8232-d9ec34ded19c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://64adb73e-8634-440f-8232-d9ec34ded19c/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2e3b734182416aad474bfe172f8329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbce7272bbb5423eac285a8f32e6e430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a404a761-9b6f-4857-8a43-166f01af5aa6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a404a761-9b6f-4857-8a43-166f01af5aa6/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab6f41820624c8ab39aa0ccd7f50e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302d6c68ceaf425b887adb1a8dca2cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e9ca20cd-8d5e-4173-8824-0a42ec6d4efb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e9ca20cd-8d5e-4173-8824-0a42ec6d4efb/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb06c2d8fa80402b8854ea47ed2d0260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b3d07be69149ee9d7c9a2fb594e1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://19cf161a-afb7-4415-a3b3-66f9a9b8a3cd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://19cf161a-afb7-4415-a3b3-66f9a9b8a3cd/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74e96a49d1d475cb1894719538484d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587ba80f31c54172a6d7213ac21621b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://cea694d1-a62a-4f6a-b7cb-d45b86898b27/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://cea694d1-a62a-4f6a-b7cb-d45b86898b27/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c41c0b87a1e44d02a68c16b68dd76325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd4f1f5756246bb89c195cb8118f245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1f76a1e9-22f9-4575-a6f2-8382d671b799/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1f76a1e9-22f9-4575-a6f2-8382d671b799/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5242760f0df4277a15055411856eed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b364da10319d4adca70e01e4e9fb9bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://84b5ccb8-58be-4b15-baae-3db0797ec509/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://84b5ccb8-58be-4b15-baae-3db0797ec509/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34bf4ff09084c26b47ff4d8072548d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts_prediction = {}\n",
    "\n",
    "for k, v in ts.items():\n",
    "    evaluation_set_encoded = v.map(preprocess_function, batched = True)\n",
    "    evaluation_set_predicted = evaluation_set_encoded.map(forward_pass_with_label, batched = True, batch_size = 8)        \n",
    "    ts_prediction[k] = evaluation_set_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d35809-e95d-460c-8094-814fc53c5de1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b5d9a48-0ff7-4c65-9433-44158fdc8a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(y_true, y_pred, average = 'macro'):\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred, average = average)}\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred, average = average)}\")\n",
    "    print(f\"F1-Score: {f1_score(y_true, y_pred, average = average)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f96c523-05f8-4ac4-8646-47b2a18dcdf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_transformed_example(v, filter_id):\n",
    "    v = v.filter(lambda x: x['REQID'] == filter_id)\n",
    "    transformed_text = v[target_column]\n",
    "    y_true = mapper.map(v['signal_keyword'])\n",
    "    y_pred = mapper.map(v['y_preds'])\n",
    "    y_proba = v['y_probas'][0]\n",
    "    print(f'\\t Transformed Text: {transformed_text}')\n",
    "    print(f'\\t Original Label: {y_true}')\n",
    "    print(f'\\t Predicted Label: {y_pred}')\n",
    "    print(f'\\t Prediction Probability: {y_proba}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0c91498-cc78-4d13-8956-248a4acd3e56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T0 -> No Transformation\n",
      "Precision: 0.9541119708891043\n",
      "Recall: 0.9517460317460317\n",
      "F1-Score: 0.9528933151427276\n",
      "\n",
      "\n",
      "T1 -> Model Verb Removed\n",
      "Precision: 0.7969257961682922\n",
      "Recall: 0.6569047619047619\n",
      "F1-Score: 0.5301279684734296\n",
      "\n",
      "\n",
      "T2 -> Add Minor Details\n",
      "Precision: 0.9414124860821428\n",
      "Recall: 0.9450793650793651\n",
      "F1-Score: 0.9430915837004745\n",
      "\n",
      "\n",
      "T3 -> Re-order Words\n",
      "Precision: 0.9259381338742395\n",
      "Recall: 0.9253174603174603\n",
      "F1-Score: 0.9251619770577624\n",
      "\n",
      "\n",
      "T4 -> Remove Minor Details\n",
      "Precision: 0.929897098586419\n",
      "Recall: 0.9318253968253968\n",
      "F1-Score: 0.9307804768331084\n",
      "\n",
      "\n",
      "T5 -> All Transformations Without SK\n",
      "Precision: 0.9081544667230291\n",
      "Recall: 0.9070634920634921\n",
      "F1-Score: 0.9055839649899057\n",
      "\n",
      "\n",
      "T5 -> All Transformations\n",
      "Precision: 0.7813630374895197\n",
      "Recall: 0.6298412698412698\n",
      "F1-Score: 0.5037054253010643\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in  ts_prediction.items():\n",
    "    y_true = mapper.map(v['signal_keyword'])\n",
    "    y_pred = mapper.map(v['y_preds'])\n",
    "    print(k)\n",
    "    evaluate(y_true, y_pred)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94c7c93e-4230-4e5a-b57a-c503d949b764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T0 -> No Transformation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f316e74fabd24fd897c960ee8cae41ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Transformed Text: ['The system shall provide the ability to print and electronically fax prescriptions.']\n",
      "\t Original Label: ['requirement']\n",
      "\t Predicted Label: ['requirement']\n",
      "\t Prediction Probability: 0.9977893829345703\n",
      "\n",
      "\n",
      "T1 -> Model Verb Removed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d75ac4826884be5b8f08221319fba56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Transformed Text: ['The system  provide the ability to print and electronically fax prescriptions.']\n",
      "\t Original Label: ['requirement']\n",
      "\t Predicted Label: ['system_related_auxiliary']\n",
      "\t Prediction Probability: 0.9973887801170349\n",
      "\n",
      "\n",
      "T2 -> Add Minor Details\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86600b0ba9f4095886cfd9154e97851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Transformed Text: ['The system shall provide the ability to print and electronically fax prescriptions appropriate even old-age pension.']\n",
      "\t Original Label: ['requirement']\n",
      "\t Predicted Label: ['requirement']\n",
      "\t Prediction Probability: 0.9977896213531494\n",
      "\n",
      "\n",
      "T3 -> Re-order Words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d455c784127f4aed90236249c9889c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Transformed Text: ['The system shall provide and ability to prescriptions the electronically fax print.']\n",
      "\t Original Label: ['requirement']\n",
      "\t Predicted Label: ['requirement']\n",
      "\t Prediction Probability: 0.9977931976318359\n",
      "\n",
      "\n",
      "T4 -> Remove Minor Details\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c5d0ddc2b349bca5751fc0cd77d55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Transformed Text: ['The system shall provide the ability to and fax prescriptions.']\n",
      "\t Original Label: ['requirement']\n",
      "\t Predicted Label: ['requirement']\n",
      "\t Prediction Probability: 0.9977967739105225\n",
      "\n",
      "\n",
      "T5 -> All Transformations Without SK\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc3041226df4bb7b7d268c7edf68a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Transformed Text: ['The system shall provide the in light and electronically fax prescriptions to to initiate print.']\n",
      "\t Original Label: ['requirement']\n",
      "\t Predicted Label: ['requirement']\n",
      "\t Prediction Probability: 0.9977788329124451\n",
      "\n",
      "\n",
      "T5 -> All Transformations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41504b2711e4107ac1337622ab4745e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Transformed Text: ['The system  provide the ability to print electronically cast prescriptions become temptable fax']\n",
      "\t Original Label: ['requirement']\n",
      "\t Predicted Label: ['system_related_auxiliary']\n",
      "\t Prediction Probability: 0.9976505637168884\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing some example \n",
    "for k, v in  ts_prediction.items():\n",
    "    print(k)\n",
    "    print_transformed_example(v, '1700')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "499df545-6520-4b61-85cd-e42f99d0d3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextual_auxiliary: 119\n",
      "requirement: 213\n",
      "system_related_auxiliary: 148\n"
     ]
    }
   ],
   "source": [
    "class_names = np.unique(mapper.map(ts_prediction['T0 -> No Transformation']['y_preds']), return_counts = True)[0]\n",
    "samples_per_class = np.unique(mapper.map(ts_prediction['T0 -> No Transformation']['y_preds']), return_counts = True)[1]\n",
    "\n",
    "for name, ss in zip(class_names, samples_per_class):\n",
    "    print(f\"{name}: {ss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723bb2c-64d2-4cba-806b-e955a2b3acea",
   "metadata": {},
   "source": [
    "## McNemar Bowker Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b47fa83e-391d-480d-9b52-657a3ea80ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cohen_w(cn_table, stats):\n",
    "    N = np.sum(cn_table) \n",
    "    w = np.sqrt(stats.statistic / N)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd89ae95-c82e-4bba-9a80-0ee9ceeaf93a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def cohen_w_ci(w, cn_table, confidence_level = 0.95):\n",
    "    n = np.sum(cn_table)\n",
    "    se_w = w / np.sqrt(2 * n)\n",
    "    z = norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "    ci_lower = w - z * se_w\n",
    "    ci_upper = w + z * se_w\n",
    "    return max(0, ci_lower), ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "866673eb-dbef-405a-b904-d3d59e376d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cn_tables = {}\n",
    "y_t0 = mapper.map(ts_prediction['T0 -> No Transformation']['y_preds'])\n",
    "transformation_names = list(ts_prediction.keys())[1:]\n",
    "\n",
    "for name in transformation_names:\n",
    "    y_tx = mapper.map(ts_prediction[name]['y_preds'])\n",
    "    cm = confusion_matrix(y_t0, y_tx)\n",
    "    cn_tables['T0 x ' + name] = cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c937d44c-39d4-4c8c-a478-57d334567ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.contingency_tables import SquareTable\n",
    "\n",
    "\n",
    "\n",
    "dfs = []\n",
    "names = []\n",
    "p_values = []\n",
    "statistics = []\n",
    "effect_sizes = []\n",
    "w_lower, w_upper = [], []\n",
    "\n",
    "\n",
    "for name, cn_table in zip(cn_tables.keys(), cn_tables.values()):\n",
    "    result = SquareTable(cn_table).symmetry()\n",
    "    dfs.append(result.df)\n",
    "    statistics.append(result.statistic)\n",
    "    p_values.append(result.pvalue)\n",
    "    names.append(name)\n",
    "\n",
    "\n",
    "    w = cohen_w(cn_table, result)\n",
    "    effect_sizes.append(w)\n",
    "    \n",
    "    low, up = cohen_w_ci(w, cn_table)\n",
    "    w_lower.append(low)\n",
    "    w_upper.append(up)\n",
    "    \n",
    "reject, adj_pvals, _, _ = multipletests(pvals = p_values, alpha = 0.05, method = 'holm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f699eb3-351c-4b29-80d0-f309e5c0702b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T0 x T1 -> Model Verb Removed\n",
      "Degree of freedom: 3.0\n",
      "Statistics: 207.6714399363564\n",
      "Raw p-value: 0.0000000000\n",
      "Adjusted p-value: 0.0000000000\n",
      "Cohen's w: 0.658\n",
      "Cohen's W 95% CI [0.616, 0.699]\n",
      "Significant (α=0.05): Yes\n",
      "****************************** \n",
      "\n",
      "T0 x T2 -> Add Minor Details\n",
      "Degree of freedom: 3.0\n",
      "Statistics: 6.344444444444445\n",
      "Raw p-value: 0.0960032906\n",
      "Adjusted p-value: 0.2614358910\n",
      "Cohen's w: 0.115\n",
      "Cohen's W 95% CI [0.108, 0.122]\n",
      "Significant (α=0.05): No\n",
      "****************************** \n",
      "\n",
      "T0 x T3 -> Re-order Words\n",
      "Degree of freedom: 3.0\n",
      "Statistics: 6.564705882352941\n",
      "Raw p-value: 0.0871452970\n",
      "Adjusted p-value: 0.2614358910\n",
      "Cohen's w: 0.117\n",
      "Cohen's W 95% CI [0.110, 0.124]\n",
      "Significant (α=0.05): No\n",
      "****************************** \n",
      "\n",
      "T0 x T4 -> Remove Minor Details\n",
      "Degree of freedom: 3.0\n",
      "Statistics: 2.98974358974359\n",
      "Raw p-value: 0.3932092177\n",
      "Adjusted p-value: 0.3932092177\n",
      "Cohen's w: 0.079\n",
      "Cohen's W 95% CI [0.074, 0.084]\n",
      "Significant (α=0.05): No\n",
      "****************************** \n",
      "\n",
      "T0 x T5 -> All Transformations Without SK\n",
      "Degree of freedom: 3.0\n",
      "Statistics: 17.217777777777776\n",
      "Raw p-value: 0.0006374676\n",
      "Adjusted p-value: 0.0025498704\n",
      "Cohen's w: 0.189\n",
      "Cohen's W 95% CI [0.177, 0.201]\n",
      "Significant (α=0.05): Yes\n",
      "****************************** \n",
      "\n",
      "T0 x T5 -> All Transformations\n",
      "Degree of freedom: 3.0\n",
      "Statistics: 212.7450559033293\n",
      "Raw p-value: 0.0000000000\n",
      "Adjusted p-value: 0.0000000000\n",
      "Cohen's w: 0.666\n",
      "Cohen's W 95% CI [0.624, 0.708]\n",
      "Significant (α=0.05): Yes\n",
      "****************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, stats, df, p_raw, p_adj, efs, low, up, rej in zip(names, statistics, dfs, p_values, adj_pvals, effect_sizes, w_lower, w_upper, reject):\n",
    "    print(f\"{name}\")\n",
    "    print(f\"Degree of freedom: {df}\")\n",
    "    print(f\"Statistics: {stats}\")\n",
    "    print(f\"Raw p-value: {p_raw:.10f}\")\n",
    "    print(f\"Adjusted p-value: {p_adj:.10f}\")\n",
    "    print(f\"Cohen's w: {efs:.3f}\")\n",
    "    print(f\"Cohen's W 95% CI [{low:.3f}, {up:.3f}]\")\n",
    "    print(f\"Significant (α=0.05): {'Yes' if rej else 'No'}\")\n",
    "    print('*' * 30, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal-engine",
   "language": "python",
   "name": "metal-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

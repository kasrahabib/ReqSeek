{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ed1281-7049-4738-ad98-70b94086369d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# common imports\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../datasets/ARID_supporting_scripts\")\n",
    "\n",
    "import os\n",
    "import mapper\n",
    "import random\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80864f2-0e6a-4036-8342-da352f0cc31c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "evaluation_set = datasets.load_from_disk('../datasets/ARID_supporting_scripts/5_1_training_set')['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd907597-30db-4f68-a592-b23efcc3b94e",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94dd3a81-fd33-4c22-9061-e6fd65ddbee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "    return tokenizer(dataset['Requirement Sentences'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729a01b9-91a1-47de-a2f8-4205cebaf59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lbl_ = evaluation_set.features['label'].names\n",
    "label2id = {lbl: idx for idx, lbl in enumerate(lbl_)}\n",
    "id2label = {val: key for key, val in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae9536f-55de-4e6f-8dc3-43ec107972be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward_pass_with_label(batch):\n",
    "    input_ids = batch['input_ids']\n",
    "    attention_masks = batch['attention_mask']\n",
    "    true_labels = tf.convert_to_tensor( batch['label'])\n",
    "    input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids, padding = \"post\")\n",
    "    attention_masks = tf.keras.preprocessing.sequence.pad_sequences(attention_masks, padding = \"post\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model(input_ids, attention_masks)\n",
    "        probas = tf.nn.softmax(output.logits, axis = -1).numpy()\n",
    "        predicted_labels = tf.argmax(output.logits, axis = -1).numpy()\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(true_labels, output.logits)\n",
    "    loss = loss.numpy()\n",
    "    return {\"loss\": loss, \n",
    "            \"y_preds\": [id2label[lbl] for lbl in predicted_labels], \n",
    "            \"y_probas\": [probas[i][predicted_labels[i]] for i in range(len(predicted_labels))]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cafc1d4-1876-4b2e-b129-09761078b824",
   "metadata": {},
   "source": [
    "# Benchmark Noisy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de32dc3f-3a5c-4da5-9a05-eb7e2ce01c76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.1_seed_100'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.1_seed_19'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.1_seed_42'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/clean_roberta_base_noise_rate_0_seed_100'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/clean_roberta_base_noise_rate_0_seed_42'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.2_seed_42'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.2_seed_19'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/clean_roberta_base_noise_rate_0_seed_19'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.3_seed_19'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.4_seed_15'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.3_seed_42'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.4_seed_13'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.1_seed_13'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.1_seed_15'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.2_seed_100'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.3_seed_100'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.2_seed_15'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/clean_roberta_base_noise_rate_0_seed_15'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/clean_roberta_base_noise_rate_0_seed_13'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.2_seed_13'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.4_seed_100'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.3_seed_13'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.4_seed_42'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.3_seed_15'),\n",
       " PosixPath('training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.4_seed_19')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading noisy models\n",
    "noisy_models_path = Path('./training_scripts_and_models/models_with_inconsistency_levels/')\n",
    "\n",
    "noisy_models = [folder for folder in noisy_models_path.iterdir() if folder.is_dir() and not folder.name.startswith('.')]\n",
    "noisy_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7a9911-5f75-41cf-909e-4735ba4aced0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_models = {}\n",
    "\n",
    "for mdl in noisy_models:\n",
    "    split_mdl_id = mdl.name.split('_')\n",
    "    seed_number = split_mdl_id[-1]\n",
    "    noise_level = split_mdl_id[-3]\n",
    "    all_models[noise_level + '_' + seed_number] = mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3d3f14-8d18-45c5-b8c0-c170dce175a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M4 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 14:27:09.392683: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-26 14:27:09.392804: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.1_seed_100.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc241b356a19400e97288c12c3d37440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://742a3e2d-0c7b-4dd4-abbd-6a6fc4e56d5c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://742a3e2d-0c7b-4dd4-abbd-6a6fc4e56d5c/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5802ebcd896b44a8bea6136da0e921e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.1_seed_19.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0bb0b5e6c748af8a1d158c3563f2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3178cdaf-a041-4a09-a0de-3bf7e0eb4a63/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3178cdaf-a041-4a09-a0de-3bf7e0eb4a63/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1362bfe5aa154c378ed35590b2cdee74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.1_seed_42.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5c7a6f3fdb4f49a96b14907d67439b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://fe182109-8791-41cc-835a-f909638a904a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://fe182109-8791-41cc-835a-f909638a904a/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a2733509f74c8fba61794664ac4774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/clean_roberta_base_noise_rate_0_seed_100.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9dea4e62e54c1eabe17da6b58e90e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d556755a-97c0-44d1-957c-5a10b90937a6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d556755a-97c0-44d1-957c-5a10b90937a6/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be133abfdaf549f090201b9fa414409d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/clean_roberta_base_noise_rate_0_seed_42.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be19ae607151450d8a40bb9029dce85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://962c4206-dfb2-4be1-9635-f7ad3ea1e851/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://962c4206-dfb2-4be1-9635-f7ad3ea1e851/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0918e277fb14f4ca2a1ea52af2d904f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.2_seed_42.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73324af6edc843dcbb0475e216a49196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://bf84d5ac-009d-4d2d-9bbf-0d3be4b30ef3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://bf84d5ac-009d-4d2d-9bbf-0d3be4b30ef3/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c554faac403d4395b1d8bfcc0731c206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.2_seed_19.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2fc7d62d3a455d8026305d5cc6d3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://02c3cbdc-87e7-4296-9c65-0121dae462df/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://02c3cbdc-87e7-4296-9c65-0121dae462df/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94381629e8b4674bada9c9c6fb40c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/clean_roberta_base_noise_rate_0_seed_19.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c394c6d0f1294cd0ba0eb26f3afe1850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1082938a-6297-42bb-9fcb-3ff1c9fbbadb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1082938a-6297-42bb-9fcb-3ff1c9fbbadb/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f1a324e06a479eb874046d80f5c378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.3_seed_19.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e73b29c9993462ab652fad618088ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c2bf87ef-0df3-4937-8c47-005a5e36276a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c2bf87ef-0df3-4937-8c47-005a5e36276a/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbe909535744e51af5e80da6b88b304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.4_seed_15.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded3c0e74043426a832666d6d72ed4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://817967da-8210-4e8a-8365-7bbea29402f1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://817967da-8210-4e8a-8365-7bbea29402f1/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa0bb327b5f4a719f2ef87a0f5ceaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.3_seed_42.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd58801c8c440dd9c395bb118fee269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://2a60860c-7127-4831-93ab-bf45f0ed07d5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://2a60860c-7127-4831-93ab-bf45f0ed07d5/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3191460d60c4f1e943adffe09b388f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.4_seed_13.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7595a85303461ca107c8c0d09ed4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6d11963c-efe5-4c77-8ea1-83e2e0dc4cd1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6d11963c-efe5-4c77-8ea1-83e2e0dc4cd1/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a073ddf5d94bb8be879607339d7780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.1_seed_13.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27a080dc6fe4ff4971d977be7b841fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://5263e0e4-9d61-4b7c-91e6-74c441cc188c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://5263e0e4-9d61-4b7c-91e6-74c441cc188c/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e4bfbd221c4997ba3fc2812021a029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.1_seed_15.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c849f784c97b4529b689a64b5c4d4c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://48b4ed57-3496-42cc-be7c-3c594cdeb1f8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://48b4ed57-3496-42cc-be7c-3c594cdeb1f8/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d30ec4437cc4975b5f374aed69d99de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.2_seed_100.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50061e0d0524d638a043cd8c071a9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://309b2b24-546a-43c0-81c0-f4c9d7219123/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://309b2b24-546a-43c0-81c0-f4c9d7219123/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e92b24c6004101b821d4ddde6077e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.3_seed_100.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9611d8fc1d314fff9820e29a9588d53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e6fa7804-97df-471f-b996-ecccd7435553/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e6fa7804-97df-471f-b996-ecccd7435553/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69df489a375d436fa837209ceeb80bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.2_seed_15.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a6831cae604d3d96b105bbe521ad9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1664326e-2f7a-4bec-a470-a690cc17a85a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1664326e-2f7a-4bec-a470-a690cc17a85a/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd6fe75e4e14866a8d8f72aa710ef94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/clean_roberta_base_noise_rate_0_seed_15.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0b8f501e204436890a33b5eacd7c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://bf7126bb-46a7-46f1-a679-00468b710d7d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://bf7126bb-46a7-46f1-a679-00468b710d7d/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca775f1da744edd9b864d5aec1257e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/clean_roberta_base_noise_rate_0_seed_13.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e74d4ead4d47cba9ad92873a87807a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://26e1d6f4-981b-4a90-90f0-6d91440bed56/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://26e1d6f4-981b-4a90-90f0-6d91440bed56/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688e63c3918346a4add3d69e94cd9273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.2_seed_13.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91d6942e5ba4703a0083b7a83e7d37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://61f787d2-c107-49f1-856b-f7c79f6167b1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://61f787d2-c107-49f1-856b-f7c79f6167b1/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5929f8619f4c0d8e093b70efabb647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.4_seed_100.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4612696879b04f2c94c1d828c4d1daec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://0a1deaac-88a9-468d-8a05-bb85f4c60f16/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://0a1deaac-88a9-468d-8a05-bb85f4c60f16/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f28cd07be6247b99a222b6bb0fe8ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.3_seed_13.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8102609aa927438a9318a11aa1b5c736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3a4db675-d573-4a6d-8e49-c87115e9a998/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3a4db675-d573-4a6d-8e49-c87115e9a998/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c1b4f191844337a4d653619d868389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.4_seed_42.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3f2394a013467ea15521522703e84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1c9e1717-f552-4618-aa75-28709751e080/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1c9e1717-f552-4618-aa75-28709751e080/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a03f8a9d1f24ebbaaf2e3fe05fef92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.3_seed_15.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8f13a992f749b2baf78d1b13581205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://5dc7b108-88ce-457f-ba59-2539cbfde72a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://5dc7b108-88ce-457f-ba59-2539cbfde72a/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c34bca8d2a4b7e9a69ee60d62c51c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at training_scripts_and_models/models_with_inconsistency_levels/noisy_roberta_base_noise_rate_0.4_seed_19.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c438f535374505895f0e23e8f6745c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7984d756-fec4-44aa-8da9-d60fbf40c733/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7984d756-fec4-44aa-8da9-d60fbf40c733/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ddeeab1d614188811a2300cb5fe422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "all_models_prediction = {}\n",
    "for mdl_id in list(all_models.keys()):\n",
    "    model_path = all_models[mdl_id]\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    evaluation_set_encoded = evaluation_set.map(preprocess_function, batched = True)\n",
    "    evaluation_set_predicted = evaluation_set_encoded.map(forward_pass_with_label, batched = True, batch_size = 8)\n",
    "    all_models_prediction[mdl_id] = evaluation_set_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae4156c6-6914-4cc8-8e46-4ab1f59c0555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "grouped = {}\n",
    "for key, value in all_models_prediction.items():\n",
    "    group_id = key.split('_')[0]\n",
    "    if group_id not in grouped:\n",
    "        grouped[group_id] = [] \n",
    "    grouped[group_id].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70441dc1-fa94-4fdf-838d-a0622a50a159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(y_true, y_pred, average = 'macro'):\n",
    "    f1 = f1_score(y_true, y_pred, average = average)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "454f28b9-bb5e-43fd-87d3-3d6e55b7d545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation_results = {}\n",
    "\n",
    "for key, value in grouped.items():\n",
    "    evaluation_results[key] = [evaluate(mapper.map(y['signal_keyword']), mapper.map(y['y_preds'])) for y in value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f6514ab-55c7-423f-aaa7-f70ab806b491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Spliting F1 scores\n",
    "\n",
    "f1_clean = evaluation_results['0']\n",
    "f1_10 = evaluation_results['0.1']\n",
    "f1_20 = evaluation_results['0.2']\n",
    "f1_30 = evaluation_results['0.3']\n",
    "f1_40 = evaluation_results['0.4']\n",
    "\n",
    "noise_levels = ['0% Noise', '10% Noise', '20% Noise', '30% Noise', '40% Noise']\n",
    "f1_scores = [f1_clean, f1_10, f1_20, f1_30, f1_40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14549dba-c687-4894-9edb-4d750d226823",
   "metadata": {},
   "source": [
    "# Descriptive Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf26ab0c-5479-470c-aca6-22328edeb48f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% Noise:\n",
      "n 5\n",
      "Mean 0.944\n",
      "Standard Deviation 0.008\n",
      "*************************\n",
      "10% Noise:\n",
      "n 5\n",
      "Mean 0.938\n",
      "Standard Deviation 0.008\n",
      "*************************\n",
      "20% Noise:\n",
      "n 5\n",
      "Mean 0.921\n",
      "Standard Deviation 0.008\n",
      "*************************\n",
      "30% Noise:\n",
      "n 5\n",
      "Mean 0.887\n",
      "Standard Deviation 0.017\n",
      "*************************\n",
      "40% Noise:\n",
      "n 5\n",
      "Mean 0.867\n",
      "Standard Deviation 0.026\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "# Calculating basic statistics\n",
    "\n",
    "def calculate_statistics(sample):\n",
    "    n = len(sample)\n",
    "    mean = np.mean(sample)\n",
    "    std_dev = np.std(sample, ddof = 1)\n",
    "\n",
    "    print(f'n {n}')\n",
    "    print(f'Mean {mean:.3f}')\n",
    "    print(f'Standard Deviation {std_dev:.3f}')\n",
    "    \n",
    "for s_name, f1 in zip(noise_levels, f1_scores):\n",
    "    print(f'{s_name}:')\n",
    "    calculate_statistics(f1)\n",
    "    print('*' * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1df6a-ae94-4239-bf3c-45fc780ad3fe",
   "metadata": {},
   "source": [
    "# Inferential Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a0cae1e-3ef1-4383-9fb2-ad35344912c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Results for RoBERTa F1-scores across noise levels:\n",
      "F-statistic: 24.178287068132317\n",
      "p-value: 0.00000\n"
     ]
    }
   ],
   "source": [
    "# Performing ANOVA\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "F_statistic, p_value = f_oneway(f1_clean, f1_10, f1_20, f1_30, f1_40)\n",
    "\n",
    "print(\"ANOVA Results for RoBERTa F1-scores across noise levels:\")\n",
    "\n",
    "print(f\"F-statistic: {F_statistic}\")\n",
    "print(f\"p-value: {p_value:.5f}\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6d1c315-bbc4-464a-b15e-55e1f7201fde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial eta squared (): 0.8286397008732957\n"
     ]
    }
   ],
   "source": [
    "# Calculating effect size\n",
    "\n",
    "def compute_partial_eta_squared(F, df_effect, df_error):\n",
    "    eta_p_squared = (df_effect * F) / (df_effect * F + df_error)\n",
    "    return eta_p_squared\n",
    "\n",
    "\n",
    "df_effect = 4  # 5 groups: 5 - 1 = 4\n",
    "df_error = 20  # 25 total samples: 25 - 5 = 20\n",
    "\n",
    "eta_p2 = compute_partial_eta_squared(F_statistic, df_effect, df_error)\n",
    "print(\"Partial eta squared ():\", eta_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f272a281-c541-498a-9ce8-0e3f0b114b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computing CI using bootstrap\n",
    "\n",
    "def bootstrap_eta_p2(groups, n_bootstraps = 1000, random_state = None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    k = len(groups)\n",
    "    n_per_group = [len(g) for g in groups]\n",
    "    N = sum(n_per_group)\n",
    "    df_effect = k - 1\n",
    "    df_error = N - k\n",
    "    \n",
    "    boot_eta_p2 = []\n",
    "    \n",
    "    for i in range(n_bootstraps):\n",
    "        boot_groups = []\n",
    "        for group in groups:\n",
    "            boot_sample = np.random.choice(group, size=len(group), replace = True)\n",
    "            boot_groups.append(boot_sample)    \n",
    "        F_stat, _ = f_oneway(*boot_groups)\n",
    "        eta_p2 = compute_partial_eta_squared(F_stat, df_effect, df_error)\n",
    "        boot_eta_p2.append(eta_p2)\n",
    "    \n",
    "    boot_eta_p2 = np.array(boot_eta_p2)\n",
    "    ci_lower, ci_upper = np.percentile(boot_eta_p2, [2.5, 97.5])\n",
    "    mean_eta_p2 = np.mean(boot_eta_p2)\n",
    "\n",
    "    return {'ci_lower': ci_lower, 'ci_upper': ci_upper}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d14fa9-9876-4b21-8e77-f913cdcd3a98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [0.774, 0.944]\n"
     ]
    }
   ],
   "source": [
    "CI = bootstrap_eta_p2([f1_clean, f1_10, f1_20, f1_30, f1_40], random_state = 42)\n",
    "print(f\"95% Confidence Interval: [{CI['ci_lower']:.3f}, {CI['ci_upper']:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "775214c7-8c73-4302-9acb-9f9a56715793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Performing Tukey's HSD post-hoc test\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "data = f1_clean + f1_10 + f1_20 + f1_30 + f1_40\n",
    "\n",
    "groups = ([\"0% Noise\"] * len(f1_clean) +\n",
    "          [\"10% Noise\"] * len(f1_10) +\n",
    "          [\"20% Noise\"] * len(f1_20) +\n",
    "          [\"30% Noise\"] * len(f1_30) +\n",
    "          [\"40% Noise\"] * len(f1_40))\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"F1_Score\": data, \"Noise_Level\": groups})\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(endog = df[\"F1_Score\"],\n",
    "                                  groups = df[\"Noise_Level\"],\n",
    "                                  alpha = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2afb5305-977a-4a9b-bbb8-96caea0df066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multiple Comparison of Means - Tukey HSD, FWER=0.05</caption>\n",
       "<tr>\n",
       "   <th>group1</th>    <th>group2</th>   <th>meandiff</th>  <th>p-adj</th>  <th>lower</th>   <th>upper</th>  <th>reject</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>0% Noise</td>  <td>10% Noise</td>  <td>-0.006</td>  <td>0.9697</td> <td>-0.0348</td> <td>0.0228</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>0% Noise</td>  <td>20% Noise</td>  <td>-0.0231</td> <td>0.1573</td> <td>-0.0519</td> <td>0.0057</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>0% Noise</td>  <td>30% Noise</td>  <td>-0.0571</td> <td>0.0001</td> <td>-0.0859</td> <td>-0.0283</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>0% Noise</td>  <td>40% Noise</td>  <td>-0.0776</td>   <td>0.0</td>  <td>-0.1064</td> <td>-0.0488</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>10% Noise</td> <td>20% Noise</td>  <td>-0.0171</td> <td>0.4153</td> <td>-0.0459</td> <td>0.0117</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>10% Noise</td> <td>30% Noise</td>  <td>-0.0511</td> <td>0.0003</td> <td>-0.0799</td> <td>-0.0223</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>10% Noise</td> <td>40% Noise</td>  <td>-0.0716</td>   <td>0.0</td>  <td>-0.1004</td> <td>-0.0428</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>20% Noise</td> <td>30% Noise</td>  <td>-0.034</td>  <td>0.0159</td> <td>-0.0628</td> <td>-0.0052</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>20% Noise</td> <td>40% Noise</td>  <td>-0.0545</td> <td>0.0001</td> <td>-0.0833</td> <td>-0.0257</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>30% Noise</td> <td>40% Noise</td>  <td>-0.0205</td> <td>0.2475</td> <td>-0.0493</td> <td>0.0083</td>   <td>False</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{ccccccc}\n",
       "\\toprule\n",
       "\\textbf{group1} & \\textbf{group2} & \\textbf{meandiff} & \\textbf{p-adj} & \\textbf{lower} & \\textbf{upper} & \\textbf{reject}  \\\\\n",
       "\\midrule\n",
       "   0\\% Noise    &    10\\% Noise   &       -0.006      &     0.9697     &    -0.0348     &     0.0228     &      False       \\\\\n",
       "   0\\% Noise    &    20\\% Noise   &      -0.0231      &     0.1573     &    -0.0519     &     0.0057     &      False       \\\\\n",
       "   0\\% Noise    &    30\\% Noise   &      -0.0571      &     0.0001     &    -0.0859     &    -0.0283     &       True       \\\\\n",
       "   0\\% Noise    &    40\\% Noise   &      -0.0776      &      0.0       &    -0.1064     &    -0.0488     &       True       \\\\\n",
       "   10\\% Noise   &    20\\% Noise   &      -0.0171      &     0.4153     &    -0.0459     &     0.0117     &      False       \\\\\n",
       "   10\\% Noise   &    30\\% Noise   &      -0.0511      &     0.0003     &    -0.0799     &    -0.0223     &       True       \\\\\n",
       "   10\\% Noise   &    40\\% Noise   &      -0.0716      &      0.0       &    -0.1004     &    -0.0428     &       True       \\\\\n",
       "   20\\% Noise   &    30\\% Noise   &       -0.034      &     0.0159     &    -0.0628     &    -0.0052     &       True       \\\\\n",
       "   20\\% Noise   &    40\\% Noise   &      -0.0545      &     0.0001     &    -0.0833     &    -0.0257     &       True       \\\\\n",
       "   30\\% Noise   &    40\\% Noise   &      -0.0205      &     0.2475     &    -0.0493     &     0.0083     &      False       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Multiple Comparison of Means - Tukey HSD, FWER=0.05}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tukey_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76bdeab-ad98-4d0d-8ae7-6f85d24829b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal-engine",
   "language": "python",
   "name": "metal-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

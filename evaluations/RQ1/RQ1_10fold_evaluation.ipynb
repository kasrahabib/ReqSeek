{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5494593-96bd-4769-b2f0-bf4c917e30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path parsing and data reading\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import datasets\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict\n",
    "\n",
    "# commot ml imports\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "sys.path.append(\"../../ReqSeek/\")\n",
    "import mapper\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# some imports for visualisation\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52216f65-363f-4255-b5f2-8e3636545330",
   "metadata": {},
   "source": [
    "# Reading & Listing Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd41a328-e222-478f-96bb-f21becaa8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading trained models and test sets\n",
    "notebook_dir = Path.cwd()\n",
    "\n",
    "data_root = (notebook_dir / './training_scripts_and_models/models_10fold_dataset_splits').resolve()\n",
    "model_root = (notebook_dir / './training_scripts_and_models/models/tuned_10_fold/').resolve()\n",
    "\n",
    "target_data_dirs = {\n",
    "    'kfold_all_mini_l6v2_data',\n",
    "    'kfold_bert_base_cased_data',\n",
    "    'kfold_gpt2_data',\n",
    "    'kfold_roberta_base_data',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4909af5-e3ba-458a-8655-bb68f0897826",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_re = re.compile(r'fold[_-]?(?P<n>\\d+)', re.IGNORECASE)\n",
    "\n",
    "def extract_fold_number(path: Path) -> Optional[int]:\n",
    "    match = fold_re.search(path.name)\n",
    "    if match:\n",
    "        return int(match.group('n'))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ac8d01-ce40-402c-b437-6499c531cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_model_name(path: Path) -> Optional[str]:\n",
    "    parts = set(path.parts)\n",
    "    if 'reqseek_bert_base_cased_kfold_trained' in parts or 'kfold_bert_base_cased_data' in parts:\n",
    "        return 'bert_base_cased'\n",
    "    if 'reqseek_roberta_base_kfold_trained' in parts or 'kfold_roberta_base_data' in parts:\n",
    "        return 'roberta_base'\n",
    "    if 'reqseek_gpt2_kfold_trained' in parts or 'kfold_gpt2_data' in parts:\n",
    "        return 'gpt2' \n",
    "    if 'reqseek_all_mini_l6v2_kfold_trained' in parts or 'kfold_all_mini_l6v2_data' in parts:\n",
    "        return 'l6v6'\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c2ade6-803c-4a29-aca9-fd0557315627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_model_folds(model_root: Path) -> dict:\n",
    "    model_folds = {}\n",
    "    for p in model_root.rglob('trained_fold_*'):\n",
    "        if not p.is_dir():\n",
    "            continue\n",
    "        fold = extract_fold_number(p)\n",
    "        model_name = infer_model_name(p)\n",
    "        if fold is None or model_name is None:\n",
    "            continue\n",
    "        model_folds[(model_name, fold)] = p\n",
    "    return model_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b575c1-b9ce-44cc-aa00-174899a929f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_data_folds(data_root: Path) -> dict:\n",
    "    data_folds = {}\n",
    "    for root in data_root.rglob('*'):\n",
    "        if not root.is_dir():\n",
    "            continue\n",
    "        if root.name not in target_data_dirs:\n",
    "            continue\n",
    "        for fold_dir in root.iterdir():\n",
    "            if not fold_dir.is_dir():\n",
    "                continue\n",
    "            fold = extract_fold_number(fold_dir)\n",
    "            model_name = infer_model_name(fold_dir)\n",
    "            if fold is None or model_name is None:\n",
    "                continue\n",
    "            data_folds[(model_name, fold)] = fold_dir\n",
    "    return data_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83df32a-f963-4d4c-b512-6e42106e5d0c",
   "metadata": {},
   "source": [
    "# Paring kFold Models & Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622c6745-148b-4885-a4fc-85dd04718c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folds = discover_model_folds(model_root)\n",
    "data_folds = discover_data_folds(data_root)\n",
    "\n",
    "paired = {}\n",
    "missing = {'models': [], 'data': []}\n",
    "\n",
    "all_keys = set(model_folds) | set(data_folds)\n",
    "\n",
    "for key in sorted(all_keys):\n",
    "    model_name, fold = key\n",
    "    model_path = model_folds.get(key)\n",
    "    data_path = data_folds.get(key)\n",
    "    if model_path is None:\n",
    "        missing['models'].append(key)\n",
    "        continue\n",
    "    if data_path is None:\n",
    "        missing['data'].append(key)\n",
    "        continue\n",
    "    paired.setdefault(model_name, {})[fold] = {\n",
    "        'model_dir': model_path,\n",
    "        'data_dir': data_path,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbccc736-cbf8-4792-8722-426b481eb118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired model and data folds:\n",
      "  bert_base_cased: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  gpt2: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  l6v6: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  roberta_base: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check, if all model and data folds are paired\n",
    "print('Paired model and data folds:')\n",
    "for model, folds in paired.items():\n",
    "    print(f\"  {model}: {sorted(folds.keys())}\")\n",
    "\n",
    "# Sanity check, if any model or data fold is missing\n",
    "if missing['models'] or missing['data']:\n",
    "    print('missing entries:')\n",
    "    if missing['models']:\n",
    "        print('  missing models:', missing['models'])\n",
    "    if missing['data']:\n",
    "        print('  missing data:', missing['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb060af3-d62f-4f52-acde-289d0e26097a",
   "metadata": {},
   "source": [
    "# Evaluation Setup & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c52903-3a39-4f26-9985-0ee52a63c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e2c88c5-cd9d-41d7-b423-683a0a7726bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic settings, to process raw text for model\n",
    "batch_size = 4\n",
    "max_length_gpt2 = 64 \n",
    "\n",
    "# selecting appropriate device\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() \n",
    "                      and torch.cuda.device_count() > 1 \n",
    "                      else 'cuda:0' if torch.cuda.is_available() \n",
    "                      else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da54fcf6-7bda-4f7f-8e9f-25f10a323786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_per_class_prf(report_dict, class_labels):\n",
    "    macro_avg = report_dict['macro avg']\n",
    "    macro = (\n",
    "        macro_avg['precision'],\n",
    "        macro_avg['recall'],\n",
    "        macro_avg['f1-score'],\n",
    "    )\n",
    "    prf = {\n",
    "        cls: (\n",
    "            report_dict[cls][\"precision\"],\n",
    "            report_dict[cls][\"recall\"],\n",
    "            report_dict[cls][\"f1-score\"],\n",
    "        )\n",
    "        for cls in class_labels\n",
    "    }\n",
    "    return prf, macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c8f6a23-2aa9-48d5-9f3b-d1cefd790b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to receive computed metrics and decorate\n",
    "def print_cv_summary(all_folds, title = None):\n",
    "    print('\\033[1m' + title + '\\033[0m')\n",
    "    print('=' * 60)\n",
    "    print(f\"{'Class':<10} | {'Precision':<13} | {'Recall':<13} | {'F1-score':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Case 1: list of (p, r, f)\n",
    "    if isinstance(all_folds[0], (list, tuple)):\n",
    "        arr = np.asarray(all_folds, dtype=float)\n",
    "        mean = arr.mean(axis=0)\n",
    "        std = arr.std(axis=0)\n",
    "        print(\n",
    "            f\"{'Macro':<10} | \"\n",
    "            f\"{mean[0]:.3f} ± {std[0]:.3f} | \"\n",
    "            f\"{mean[1]:.3f} ± {std[1]:.3f} | \"\n",
    "            f\"{mean[2]:.3f} ± {std[2]:.3f}\"\n",
    "        )\n",
    "\n",
    "    # Case 2: list of dicts (per-class)\n",
    "    else:\n",
    "        class_names = all_folds[0].keys()\n",
    "        for cls in class_names:\n",
    "            arr = np.asarray([fold[cls] for fold in all_folds], dtype=float)\n",
    "            mean = arr.mean(axis=0)\n",
    "            std = arr.std(axis=0)\n",
    "            print(\n",
    "                f\"{cls:<10} | \"\n",
    "                f\"{mean[0]:.3f} ± {std[0]:.3f} | \"\n",
    "                f\"{mean[1]:.3f} ± {std[1]:.3f} | \"\n",
    "                f\"{mean[2]:.3f} ± {std[2]:.3f}\"\n",
    "            )\n",
    "    print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "732de4c2-000e-4aab-80b0-f0c01bbf9813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to identify fold-trained misclassification\n",
    "def majority_vote(preds_2d, n_classes):\n",
    "    out = np.empty(preds_2d.shape[1], dtype = int)\n",
    "    for j in range(preds_2d.shape[1]):\n",
    "        out[j] = np.bincount(preds_2d[:, j], minlength=n_classes).argmax()\n",
    "    return out\n",
    "\n",
    "def get_misclassified_reqids(promise_ds, y_true, y_pred):\n",
    "    reqids = np.array(promise_ds['REQID'])\n",
    "    return reqids[y_true != y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f992695c-006b-4659-b522-8502d9964fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run each fold and feed evaluation set\n",
    "def eval_fold_torch(model_dir, data_dir = None, batch_size = 8, override_test_ds = None, override_label_names = None):\n",
    "    # load test dataset\n",
    "    if override_test_ds is None:\n",
    "        dataset = datasets.load_from_disk(str(data_dir))\n",
    "        test_ds = dataset['test']\n",
    "        target_names = np.unique([mapper.map_hf(i) for i in dataset['train'].features['label'].names])\n",
    "    else:\n",
    "        test_ds = override_test_ds\n",
    "        target_names = override_label_names  # must be provided\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(str(model_dir))\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(str(model_dir), from_tf = True).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # setting specific settings if the model is GPT\n",
    "    is_gpt2 = 'gpt2' in str(model_dir).lower()\n",
    "    if is_gpt2:\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.padding_side = 'left'\n",
    "\n",
    "    texts = test_ds['Requirement Sentences']\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            enc = tokenizer(\n",
    "                batch_texts,\n",
    "                padding = 'max_length' if is_gpt2 else True,\n",
    "                truncation = True,\n",
    "                max_length = max_length_gpt2 if is_gpt2 else None,\n",
    "                return_tensors = 'pt',\n",
    "            )\n",
    "            enc = {k: v.to(device) for k, v in enc.items()}\n",
    "            logits = model(**enc).logits\n",
    "            y_pred.extend(torch.argmax(logits, dim = 1).cpu().numpy())\n",
    "\n",
    "    y_true = [mapper.map_hf(model.config.id2label[i]) for i in np.array(test_ds['label'])]\n",
    "    y_pred = [mapper.map_hf(model.config.id2label[i]) for i in np.array(y_pred)]\n",
    "    report_text = classification_report(y_true, y_pred, target_names = target_names)\n",
    "    report_dict = classification_report(y_true, y_pred, target_names = target_names, output_dict = True)\n",
    "\n",
    "    return y_true, y_pred, report_text, report_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b4efb-1dfb-4b2e-9e37-0eed45621c76",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0408cfcc-d32e-45b5-9160-ad17e3d6abe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m>>>>>\u001b[0mEvaluating GPT2 on fold-1\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 21:53:09.526899: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-13 21:53:09.526935: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-13 21:53:09.528158: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-13 21:53:09.535066: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-13 21:53:10.117502: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2026-01-13 21:53:10.655377: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.657517: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.661746: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.663479: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.666223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.668052: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.909075: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.910650: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.912182: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.913688: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.915173: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.916689: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.941608: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.943173: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.944674: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.946184: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.947667: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.949156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22153 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2026-01-13 21:53:10.949547: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-13 21:53:10.951001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22168 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "2026-01-13 21:53:11.606339: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "All TF 2.0 model weights were used when initializing GPT2ForSequenceClassification.\n",
      "\n",
      "All the weights of GPT2ForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.96      0.90      0.93        60\n",
      "             requirement       0.89      0.96      0.92       105\n",
      "system_related_auxiliary       0.90      0.84      0.87        75\n",
      "\n",
      "                accuracy                           0.91       240\n",
      "               macro avg       0.92      0.90      0.91       240\n",
      "            weighted avg       0.91      0.91      0.91       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating GPT2 on fold-2\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing GPT2ForSequenceClassification.\n",
      "\n",
      "All the weights of GPT2ForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.97      0.93      0.95        60\n",
      "             requirement       0.88      0.95      0.91       105\n",
      "system_related_auxiliary       0.93      0.84      0.88        75\n",
      "\n",
      "                accuracy                           0.91       240\n",
      "               macro avg       0.92      0.91      0.91       240\n",
      "            weighted avg       0.91      0.91      0.91       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating GPT2 on fold-3\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing GPT2ForSequenceClassification.\n",
      "\n",
      "All the weights of GPT2ForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.92      0.95        60\n",
      "             requirement       0.89      0.95      0.92       105\n",
      "system_related_auxiliary       0.88      0.84      0.86        75\n",
      "\n",
      "                accuracy                           0.91       240\n",
      "               macro avg       0.92      0.90      0.91       240\n",
      "            weighted avg       0.91      0.91      0.91       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating GPT2 on fold-4\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing GPT2ForSequenceClassification.\n",
      "\n",
      "All the weights of GPT2ForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.90      0.95        60\n",
      "             requirement       0.85      0.96      0.90       105\n",
      "system_related_auxiliary       0.91      0.81      0.86        75\n",
      "\n",
      "                accuracy                           0.90       240\n",
      "               macro avg       0.92      0.89      0.90       240\n",
      "            weighted avg       0.91      0.90      0.90       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating GPT2 on fold-5\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing GPT2ForSequenceClassification.\n",
      "\n",
      "All the weights of GPT2ForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.93      0.97        60\n",
      "             requirement       0.90      0.97      0.94       105\n",
      "system_related_auxiliary       0.93      0.88      0.90        75\n",
      "\n",
      "                accuracy                           0.93       240\n",
      "               macro avg       0.94      0.93      0.94       240\n",
      "            weighted avg       0.94      0.93      0.93       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating GPT2 on fold-6\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing GPT2ForSequenceClassification.\n",
      "\n",
      "All the weights of GPT2ForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.88      0.94        60\n",
      "             requirement       0.84      0.93      0.88       105\n",
      "system_related_auxiliary       0.84      0.79      0.81        75\n",
      "\n",
      "                accuracy                           0.88       240\n",
      "               macro avg       0.89      0.87      0.88       240\n",
      "            weighted avg       0.88      0.88      0.88       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating GPT2 on fold-7\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing GPT2ForSequenceClassification.\n",
      "\n",
      "All the weights of GPT2ForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.90      0.95        60\n",
      "             requirement       0.88      0.97      0.92       105\n",
      "system_related_auxiliary       0.93      0.86      0.90        74\n",
      "\n",
      "                accuracy                           0.92       239\n",
      "               macro avg       0.94      0.91      0.92       239\n",
      "            weighted avg       0.92      0.92      0.92       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating GPT2 on fold-8\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing GPT2ForSequenceClassification.\n",
      "\n",
      "All the weights of GPT2ForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.95      0.97        60\n",
      "             requirement       0.86      0.95      0.90       105\n",
      "system_related_auxiliary       0.92      0.81      0.86        74\n",
      "\n",
      "                accuracy                           0.91       239\n",
      "               macro avg       0.92      0.90      0.91       239\n",
      "            weighted avg       0.91      0.91      0.91       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating GPT2 on fold-9\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing GPT2ForSequenceClassification.\n",
      "\n",
      "All the weights of GPT2ForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.92      0.95        60\n",
      "             requirement       0.89      0.97      0.93       105\n",
      "system_related_auxiliary       0.93      0.85      0.89        74\n",
      "\n",
      "                accuracy                           0.92       239\n",
      "               macro avg       0.93      0.91      0.92       239\n",
      "            weighted avg       0.92      0.92      0.92       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating GPT2 on fold-10\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing GPT2ForSequenceClassification.\n",
      "\n",
      "All the weights of GPT2ForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.95      0.90      0.92        60\n",
      "             requirement       0.91      0.94      0.93       105\n",
      "system_related_auxiliary       0.88      0.86      0.87        74\n",
      "\n",
      "                accuracy                           0.91       239\n",
      "               macro avg       0.91      0.90      0.91       239\n",
      "            weighted avg       0.91      0.91      0.91       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "model_to_run = 'gpt2'  # or 'l6v6' | 'roberta_base' | 'bert_base_cased'\n",
    "\n",
    "fold_test_macro = []  \n",
    "fold_test_per_class_metrics = [] \n",
    "\n",
    "for fold, info in sorted(paired[model_to_run].items()):\n",
    "    model_dir = Path(info['model_dir'])\n",
    "    data_dir = Path(info['data_dir'])\n",
    "    fold_label_names = [mapper.map_hf(i) for i in datasets.load_from_disk(str(data_dir))['train'].features['label'].names]\n",
    "    print(f\"\\033[1m>>>>>\\033[0mEvaluating {model_to_run.upper()} on fold-{fold}\\033[1m<<<<<\\033[0m\")\n",
    "\n",
    "    # 1) evaluate on the fold's own held-out test set\n",
    "    y_true, y_pred, report_text, report_dict = eval_fold_torch(\n",
    "        model_dir = model_dir,\n",
    "        data_dir = data_dir,\n",
    "        batch_size = batch_size,\n",
    "        override_test_ds = None,\n",
    "    )\n",
    "    prf_on_heldout, m_on_heldout = collect_per_class_prf(report_dict, fold_label_names)\n",
    "    fold_test_per_class_metrics.append(prf_on_heldout)\n",
    "    fold_test_macro.append(m_on_heldout)\n",
    "    print(report_text) # classification report for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa9bb2b2-76b7-4462-90e7-314aa5158b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **GPT2 EVALUATION ON HELDOUT SET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10-folds Macro Average Mean±STD:\u001b[0m\n",
      "============================================================\n",
      "Class      | Precision     | Recall        | F1-score  \n",
      "------------------------------------------------------------\n",
      "Macro      | 0.921 ± 0.013 | 0.903 ± 0.015 | 0.911 ± 0.014\n",
      "============================================================\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m10-folds Per Class P,R,F Mean±STD:\u001b[0m\n",
      "============================================================\n",
      "Class      | Precision     | Recall        | F1-score  \n",
      "------------------------------------------------------------\n",
      "contextual_auxiliary | 0.982 ± 0.018 | 0.913 ± 0.019 | 0.946 ± 0.013\n",
      "requirement | 0.878 ± 0.022 | 0.957 ± 0.012 | 0.916 ± 0.015\n",
      "system_related_auxiliary | 0.904 ± 0.028 | 0.839 ± 0.027 | 0.870 ± 0.024\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "heldout_text = f'{model_to_run} Evaluation on Heldout Set:'\n",
    "\n",
    "display(Markdown(f\"### **{heldout_text.upper()}**\"))\n",
    "print_cv_summary(fold_test_macro, title = '10-folds Macro Average Mean±STD:')\n",
    "print('\\n\\n')\n",
    "print_cv_summary(fold_test_per_class_metrics, title = '10-folds Per Class P,R,F Mean±STD:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c99fdba9-73d0-4444-afb8-f5ad5ab34a87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m>>>>>\u001b[0mEvaluating L6V6 on fold-1\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.93      0.97        60\n",
      "             requirement       0.90      0.99      0.95       105\n",
      "system_related_auxiliary       0.99      0.91      0.94        75\n",
      "\n",
      "                accuracy                           0.95       240\n",
      "               macro avg       0.96      0.94      0.95       240\n",
      "            weighted avg       0.95      0.95      0.95       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating L6V6 on fold-2\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.97      0.95      0.96        60\n",
      "             requirement       0.91      0.95      0.93       105\n",
      "system_related_auxiliary       0.93      0.88      0.90        75\n",
      "\n",
      "                accuracy                           0.93       240\n",
      "               macro avg       0.93      0.93      0.93       240\n",
      "            weighted avg       0.93      0.93      0.93       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating L6V6 on fold-3\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.97      0.97        60\n",
      "             requirement       0.94      0.99      0.96       105\n",
      "system_related_auxiliary       0.97      0.91      0.94        75\n",
      "\n",
      "                accuracy                           0.96       240\n",
      "               macro avg       0.96      0.95      0.96       240\n",
      "            weighted avg       0.96      0.96      0.96       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating L6V6 on fold-4\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.97      0.97      0.97        60\n",
      "             requirement       0.94      0.97      0.96       105\n",
      "system_related_auxiliary       0.94      0.91      0.93        75\n",
      "\n",
      "                accuracy                           0.95       240\n",
      "               macro avg       0.95      0.95      0.95       240\n",
      "            weighted avg       0.95      0.95      0.95       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating L6V6 on fold-5\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.98      0.98        60\n",
      "             requirement       0.94      0.95      0.95       105\n",
      "system_related_auxiliary       0.95      0.93      0.94        75\n",
      "\n",
      "                accuracy                           0.95       240\n",
      "               macro avg       0.96      0.96      0.96       240\n",
      "            weighted avg       0.95      0.95      0.95       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating L6V6 on fold-6\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.92      0.96        60\n",
      "             requirement       0.84      0.98      0.90       105\n",
      "system_related_auxiliary       0.95      0.79      0.86        75\n",
      "\n",
      "                accuracy                           0.90       240\n",
      "               macro avg       0.93      0.89      0.91       240\n",
      "            weighted avg       0.91      0.90      0.90       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating L6V6 on fold-7\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.92      0.95        60\n",
      "             requirement       0.92      0.99      0.95       105\n",
      "system_related_auxiliary       0.94      0.89      0.92        74\n",
      "\n",
      "                accuracy                           0.94       239\n",
      "               macro avg       0.95      0.93      0.94       239\n",
      "            weighted avg       0.94      0.94      0.94       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating L6V6 on fold-8\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.97      0.97      0.97        60\n",
      "             requirement       0.90      0.96      0.93       105\n",
      "system_related_auxiliary       0.96      0.86      0.91        74\n",
      "\n",
      "                accuracy                           0.93       239\n",
      "               macro avg       0.94      0.93      0.94       239\n",
      "            weighted avg       0.93      0.93      0.93       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating L6V6 on fold-9\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.90      0.95        60\n",
      "             requirement       0.89      0.97      0.93       105\n",
      "system_related_auxiliary       0.94      0.89      0.92        74\n",
      "\n",
      "                accuracy                           0.93       239\n",
      "               macro avg       0.94      0.92      0.93       239\n",
      "            weighted avg       0.93      0.93      0.93       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating L6V6 on fold-10\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.93      0.97        60\n",
      "             requirement       0.89      0.98      0.93       105\n",
      "system_related_auxiliary       0.93      0.84      0.88        74\n",
      "\n",
      "                accuracy                           0.92       239\n",
      "               macro avg       0.94      0.92      0.93       239\n",
      "            weighted avg       0.93      0.92      0.92       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "model_to_run =  'l6v6' # or 'gpt2' | 'roberta_base' | 'bert_base_cased'\n",
    "\n",
    "fold_test_macro = []  \n",
    "fold_test_per_class_metrics = [] \n",
    "\n",
    "for fold, info in sorted(paired[model_to_run].items()):\n",
    "    model_dir = Path(info['model_dir'])\n",
    "    data_dir = Path(info['data_dir'])\n",
    "    fold_label_names = [mapper.map_hf(i) for i in datasets.load_from_disk(str(data_dir))['train'].features['label'].names]\n",
    "    print(f\"\\033[1m>>>>>\\033[0mEvaluating {model_to_run.upper()} on fold-{fold}\\033[1m<<<<<\\033[0m\")\n",
    "\n",
    "    # 1) evaluate on the fold's own held-out test set\n",
    "    y_true, y_pred, report_text, report_dict = eval_fold_torch(\n",
    "        model_dir = model_dir,\n",
    "        data_dir = data_dir,\n",
    "        batch_size = batch_size,\n",
    "        override_test_ds = None,\n",
    "    )\n",
    "    prf_on_heldout, m_on_heldout = collect_per_class_prf(report_dict, fold_label_names)\n",
    "    fold_test_per_class_metrics.append(prf_on_heldout)\n",
    "    fold_test_macro.append(m_on_heldout)\n",
    "    print(report_text) # classification report for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da882ba2-3597-419d-a921-03981348e4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **L6V6 EVALUATION ON HELDOUT SET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10-folds Macro Average Mean±STD:\u001b[0m\n",
      "============================================================\n",
      "Class      | Precision     | Recall        | F1-score  \n",
      "------------------------------------------------------------\n",
      "Macro      | 0.947 ± 0.011 | 0.933 ± 0.018 | 0.939 ± 0.015\n",
      "============================================================\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m10-folds Per Class P,R,F Mean±STD:\u001b[0m\n",
      "============================================================\n",
      "Class      | Precision     | Recall        | F1-score  \n",
      "------------------------------------------------------------\n",
      "contextual_auxiliary | 0.985 ± 0.014 | 0.943 ± 0.026 | 0.963 ± 0.011\n",
      "requirement | 0.907 ± 0.031 | 0.974 ± 0.014 | 0.939 ± 0.017\n",
      "system_related_auxiliary | 0.949 ± 0.017 | 0.881 ± 0.040 | 0.913 ± 0.025\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "heldout_text = f'{model_to_run} Evaluation on Heldout Set:'\n",
    "\n",
    "display(Markdown(f\"### **{heldout_text.upper()}**\"))\n",
    "print_cv_summary(fold_test_macro, title = '10-folds Macro Average Mean±STD:')\n",
    "print('\\n\\n')\n",
    "print_cv_summary(fold_test_per_class_metrics, title = '10-folds Per Class P,R,F Mean±STD:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "512d61eb-a5bd-455f-a527-da11ed8513ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m>>>>>\u001b[0mEvaluating ROBERTA_BASE on fold-1\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.97      0.93      0.95        60\n",
      "             requirement       0.90      0.99      0.95       105\n",
      "system_related_auxiliary       0.97      0.87      0.92        75\n",
      "\n",
      "                accuracy                           0.94       240\n",
      "               macro avg       0.95      0.93      0.94       240\n",
      "            weighted avg       0.94      0.94      0.94       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating ROBERTA_BASE on fold-2\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.95      0.97        60\n",
      "             requirement       0.93      0.95      0.94       105\n",
      "system_related_auxiliary       0.92      0.91      0.91        75\n",
      "\n",
      "                accuracy                           0.94       240\n",
      "               macro avg       0.94      0.94      0.94       240\n",
      "            weighted avg       0.94      0.94      0.94       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating ROBERTA_BASE on fold-3\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.95      0.95      0.95        60\n",
      "             requirement       0.93      0.96      0.94       105\n",
      "system_related_auxiliary       0.94      0.89      0.92        75\n",
      "\n",
      "                accuracy                           0.94       240\n",
      "               macro avg       0.94      0.94      0.94       240\n",
      "            weighted avg       0.94      0.94      0.94       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating ROBERTA_BASE on fold-4\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.93      0.96        60\n",
      "             requirement       0.89      0.96      0.93       105\n",
      "system_related_auxiliary       0.91      0.85      0.88        75\n",
      "\n",
      "                accuracy                           0.92       240\n",
      "               macro avg       0.93      0.92      0.92       240\n",
      "            weighted avg       0.92      0.92      0.92       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating ROBERTA_BASE on fold-5\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.98      0.99        60\n",
      "             requirement       0.93      0.94      0.94       105\n",
      "system_related_auxiliary       0.92      0.92      0.92        75\n",
      "\n",
      "                accuracy                           0.95       240\n",
      "               macro avg       0.95      0.95      0.95       240\n",
      "            weighted avg       0.95      0.95      0.95       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating ROBERTA_BASE on fold-6\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.93      0.97        60\n",
      "             requirement       0.89      0.99      0.94       105\n",
      "system_related_auxiliary       0.96      0.85      0.90        75\n",
      "\n",
      "                accuracy                           0.93       240\n",
      "               macro avg       0.95      0.93      0.93       240\n",
      "            weighted avg       0.94      0.93      0.93       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating ROBERTA_BASE on fold-7\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.95      0.97        60\n",
      "             requirement       0.90      0.98      0.94       105\n",
      "system_related_auxiliary       0.96      0.86      0.91        74\n",
      "\n",
      "                accuracy                           0.94       239\n",
      "               macro avg       0.95      0.93      0.94       239\n",
      "            weighted avg       0.94      0.94      0.94       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating ROBERTA_BASE on fold-8\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.97      0.97      0.97        60\n",
      "             requirement       0.92      0.96      0.94       105\n",
      "system_related_auxiliary       0.96      0.89      0.92        74\n",
      "\n",
      "                accuracy                           0.94       239\n",
      "               macro avg       0.95      0.94      0.94       239\n",
      "            weighted avg       0.94      0.94      0.94       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating ROBERTA_BASE on fold-9\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.95      0.97        60\n",
      "             requirement       0.92      0.98      0.95       105\n",
      "system_related_auxiliary       0.96      0.89      0.92        74\n",
      "\n",
      "                accuracy                           0.95       239\n",
      "               macro avg       0.95      0.94      0.95       239\n",
      "            weighted avg       0.95      0.95      0.95       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating ROBERTA_BASE on fold-10\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.92      0.95        60\n",
      "             requirement       0.91      0.96      0.94       105\n",
      "system_related_auxiliary       0.90      0.88      0.89        74\n",
      "\n",
      "                accuracy                           0.92       239\n",
      "               macro avg       0.93      0.92      0.92       239\n",
      "            weighted avg       0.93      0.92      0.92       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "model_to_run =  'roberta_base' #  | 'bert_base_cased'\n",
    "\n",
    "fold_test_macro = []  \n",
    "fold_test_per_class_metrics = [] \n",
    "\n",
    "for fold, info in sorted(paired[model_to_run].items()):\n",
    "    model_dir = Path(info['model_dir'])\n",
    "    data_dir = Path(info['data_dir'])\n",
    "    fold_label_names = [mapper.map_hf(i) for i in datasets.load_from_disk(str(data_dir))['train'].features['label'].names]\n",
    "    print(f\"\\033[1m>>>>>\\033[0mEvaluating {model_to_run.upper()} on fold-{fold}\\033[1m<<<<<\\033[0m\")\n",
    "\n",
    "    # 1) evaluate on the fold's own held-out test set\n",
    "    y_true, y_pred, report_text, report_dict = eval_fold_torch(\n",
    "        model_dir = model_dir,\n",
    "        data_dir = data_dir,\n",
    "        batch_size = batch_size,\n",
    "        override_test_ds = None,\n",
    "    )\n",
    "    prf_on_heldout, m_on_heldout = collect_per_class_prf(report_dict, fold_label_names)\n",
    "    fold_test_per_class_metrics.append(prf_on_heldout)\n",
    "    fold_test_macro.append(m_on_heldout)\n",
    "    print(report_text) # classification report for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9fe7178-bef1-4905-aad7-976074a77f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **ROBERTA_BASE EVALUATION ON HELDOUT SET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10-folds Macro Average Mean±STD:\u001b[0m\n",
      "============================================================\n",
      "Class      | Precision     | Recall        | F1-score  \n",
      "------------------------------------------------------------\n",
      "Macro      | 0.944 ± 0.008 | 0.932 ± 0.010 | 0.937 ± 0.008\n",
      "============================================================\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m10-folds Per Class P,R,F Mean±STD:\u001b[0m\n",
      "============================================================\n",
      "Class      | Precision     | Recall        | F1-score  \n",
      "------------------------------------------------------------\n",
      "contextual_auxiliary | 0.981 ± 0.016 | 0.947 ± 0.018 | 0.964 ± 0.013\n",
      "requirement | 0.912 ± 0.015 | 0.969 ± 0.015 | 0.939 ± 0.006\n",
      "system_related_auxiliary | 0.939 ± 0.022 | 0.882 ± 0.021 | 0.909 ± 0.013\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "heldout_text = f'{model_to_run} Evaluation on Heldout Set:'\n",
    "\n",
    "display(Markdown(f\"### **{heldout_text.upper()}**\"))\n",
    "print_cv_summary(fold_test_macro, title = '10-folds Macro Average Mean±STD:')\n",
    "print('\\n\\n')\n",
    "print_cv_summary(fold_test_per_class_metrics, title = '10-folds Per Class P,R,F Mean±STD:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b862573-66c0-485c-8a49-6e60882dfa92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m>>>>>\u001b[0mEvaluating BERT_BASE_CASED on fold-1\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.95      0.97        60\n",
      "             requirement       0.91      0.98      0.94       105\n",
      "system_related_auxiliary       0.97      0.91      0.94        75\n",
      "\n",
      "                accuracy                           0.95       240\n",
      "               macro avg       0.96      0.95      0.95       240\n",
      "            weighted avg       0.95      0.95      0.95       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating BERT_BASE_CASED on fold-2\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.97      0.97      0.97        60\n",
      "             requirement       0.92      0.99      0.95       105\n",
      "system_related_auxiliary       0.97      0.87      0.92        75\n",
      "\n",
      "                accuracy                           0.95       240\n",
      "               macro avg       0.95      0.94      0.95       240\n",
      "            weighted avg       0.95      0.95      0.95       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating BERT_BASE_CASED on fold-3\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.97      0.98        60\n",
      "             requirement       0.92      0.92      0.92       105\n",
      "system_related_auxiliary       0.88      0.89      0.89        75\n",
      "\n",
      "                accuracy                           0.93       240\n",
      "               macro avg       0.93      0.93      0.93       240\n",
      "            weighted avg       0.93      0.93      0.93       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating BERT_BASE_CASED on fold-4\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.97      0.97        60\n",
      "             requirement       0.90      0.97      0.94       105\n",
      "system_related_auxiliary       0.96      0.87      0.91        75\n",
      "\n",
      "                accuracy                           0.94       240\n",
      "               macro avg       0.95      0.93      0.94       240\n",
      "            weighted avg       0.94      0.94      0.94       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating BERT_BASE_CASED on fold-5\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.98      0.99        60\n",
      "             requirement       0.92      0.94      0.93       105\n",
      "system_related_auxiliary       0.92      0.89      0.91        75\n",
      "\n",
      "                accuracy                           0.94       240\n",
      "               macro avg       0.94      0.94      0.94       240\n",
      "            weighted avg       0.94      0.94      0.94       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating BERT_BASE_CASED on fold-6\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.92      0.96        60\n",
      "             requirement       0.86      0.97      0.91       105\n",
      "system_related_auxiliary       0.94      0.83      0.88        75\n",
      "\n",
      "                accuracy                           0.91       240\n",
      "               macro avg       0.93      0.90      0.92       240\n",
      "            weighted avg       0.92      0.91      0.91       240\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating BERT_BASE_CASED on fold-7\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.93      0.96        60\n",
      "             requirement       0.91      0.97      0.94       105\n",
      "system_related_auxiliary       0.94      0.89      0.92        74\n",
      "\n",
      "                accuracy                           0.94       239\n",
      "               macro avg       0.95      0.93      0.94       239\n",
      "            weighted avg       0.94      0.94      0.94       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating BERT_BASE_CASED on fold-8\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       0.98      0.98      0.98        60\n",
      "             requirement       0.90      0.97      0.94       105\n",
      "system_related_auxiliary       0.97      0.86      0.91        74\n",
      "\n",
      "                accuracy                           0.94       239\n",
      "               macro avg       0.95      0.94      0.94       239\n",
      "            weighted avg       0.94      0.94      0.94       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating BERT_BASE_CASED on fold-9\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.95      0.97        60\n",
      "             requirement       0.90      0.96      0.93       105\n",
      "system_related_auxiliary       0.93      0.88      0.90        74\n",
      "\n",
      "                accuracy                           0.93       239\n",
      "               macro avg       0.94      0.93      0.94       239\n",
      "            weighted avg       0.93      0.93      0.93       239\n",
      "\n",
      "\u001b[1m>>>>>\u001b[0mEvaluating BERT_BASE_CASED on fold-10\u001b[1m<<<<<\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    contextual_auxiliary       1.00      0.98      0.99        60\n",
      "             requirement       0.91      0.96      0.94       105\n",
      "system_related_auxiliary       0.94      0.88      0.91        74\n",
      "\n",
      "                accuracy                           0.94       239\n",
      "               macro avg       0.95      0.94      0.95       239\n",
      "            weighted avg       0.94      0.94      0.94       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "model_to_run = 'bert_base_cased'\n",
    "\n",
    "fold_test_macro = []  \n",
    "fold_test_per_class_metrics = [] \n",
    "\n",
    "for fold, info in sorted(paired[model_to_run].items()):\n",
    "    model_dir = Path(info['model_dir'])\n",
    "    data_dir = Path(info['data_dir'])\n",
    "    fold_label_names = [mapper.map_hf(i) for i in datasets.load_from_disk(str(data_dir))['train'].features['label'].names]\n",
    "    print(f\"\\033[1m>>>>>\\033[0mEvaluating {model_to_run.upper()} on fold-{fold}\\033[1m<<<<<\\033[0m\")\n",
    "\n",
    "    # 1) evaluate on the fold's own held-out test set\n",
    "    y_true, y_pred, report_text, report_dict = eval_fold_torch(\n",
    "        model_dir = model_dir,\n",
    "        data_dir = data_dir,\n",
    "        batch_size = batch_size,\n",
    "        override_test_ds = None,\n",
    "    )\n",
    "    prf_on_heldout, m_on_heldout = collect_per_class_prf(report_dict, fold_label_names)\n",
    "    fold_test_per_class_metrics.append(prf_on_heldout)\n",
    "    fold_test_macro.append(m_on_heldout)\n",
    "    print(report_text) # classification report for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a3e047a-13bc-43fe-af0b-655c74ca253a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **BERT_BASE_CASED EVALUATION ON HELDOUT SET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10-folds Macro Average Mean±STD:\u001b[0m\n",
      "============================================================\n",
      "Class      | Precision     | Recall        | F1-score  \n",
      "------------------------------------------------------------\n",
      "Macro      | 0.946 ± 0.008 | 0.934 ± 0.011 | 0.939 ± 0.010\n",
      "============================================================\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m10-folds Per Class P,R,F Mean±STD:\u001b[0m\n",
      "============================================================\n",
      "Class      | Precision     | Recall        | F1-score  \n",
      "------------------------------------------------------------\n",
      "contextual_auxiliary | 0.992 ± 0.011 | 0.960 ± 0.021 | 0.975 ± 0.012\n",
      "requirement | 0.905 ± 0.017 | 0.965 ± 0.018 | 0.934 ± 0.012\n",
      "system_related_auxiliary | 0.942 ± 0.027 | 0.877 ± 0.021 | 0.908 ± 0.015\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "heldout_text = f'{model_to_run} Evaluation on Heldout Set:'\n",
    "\n",
    "display(Markdown(f\"### **{heldout_text.upper()}**\"))\n",
    "print_cv_summary(fold_test_macro, title = '10-folds Macro Average Mean±STD:')\n",
    "print('\\n\\n')\n",
    "print_cv_summary(fold_test_per_class_metrics, title = '10-folds Per Class P,R,F Mean±STD:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286980a-611b-44f2-aebc-590b080bcccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal-engine",
   "language": "python",
   "name": "metal-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

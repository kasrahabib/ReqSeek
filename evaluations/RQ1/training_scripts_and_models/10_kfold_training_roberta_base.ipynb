{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUGJ4FNObH9C",
    "outputId": "98db096b-a6a7-43e6-e438-2c9c36b82c10",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 134.9 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qoXjOIb1bWCZ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 21:07:53.378327: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-12 21:07:53.378359: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-12 21:07:53.379592: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-12 21:07:53.386190: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-12 21:07:53.996579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# common imports\n",
    "\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "t7q96SlFBhil"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_from_disk('../../datasets/ARID_supporting_scripts/5_1_training_set')\n",
    "dataset = datasets.concatenate_datasets([dataset['train'], dataset['test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['may_signal_keyword_general_text',\n",
       " 'may_signal_keyword_requirement',\n",
       " 'may_signal_keyword_srs_text',\n",
       " 'must_signal_keyword_general_text',\n",
       " 'must_signal_keyword_requirement',\n",
       " 'must_signal_keyword_srs_text',\n",
       " 'no_signal_keyword_general_text',\n",
       " 'no_signal_keyword_srs_text',\n",
       " 'shall_signal_keyword_general_text',\n",
       " 'shall_signal_keyword_requirement',\n",
       " 'shall_signal_keyword_srs_text',\n",
       " 'should_signal_keyword_general_text',\n",
       " 'should_signal_keyword_requirement',\n",
       " 'should_signal_keyword_srs_text',\n",
       " 'will_signal_keyword_general_text',\n",
       " 'will_signal_keyword_requirement',\n",
       " 'will_signal_keyword_srs_text']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "m69JG3BCg7aL"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    metric1 = evaluate.load(\"precision\")\n",
    "    metric2 = evaluate.load(\"recall\")\n",
    "    metric3 = evaluate.load(\"f1\")\n",
    "\n",
    "    predictions, labels = eval_predictions\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "\n",
    "    precision = metric1.compute(predictions = predictions, references = labels, average = 'macro')[\"precision\"]\n",
    "    recall = metric2.compute(predictions = predictions, references = labels, average = 'macro')[\"recall\"]\n",
    "    f1_weighted = metric3.compute(predictions = predictions, references = labels, average = 'macro')[\"f1\"]\n",
    "    return {\"precision\": precision, \"recall\": recall, 'f1_macro': f1_weighted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430,
     "referenced_widgets": [
      "98016132c64b42738a58789a93fd444d",
      "e3b2d90a1e614ac1b3a363ee11ffef46",
      "f20d8637e285496dba5f1d9723c5c357",
      "5c640d5d481f4eec9757acc13b81ca43",
      "b6cd6c1965a04b409a38af281194ca43",
      "b4f4d6b221d74a20889e5ae8b1454742",
      "d64745f382bd48ef80509aa18de5b834",
      "afa55123cccc4f72b3f250dfc5e1ad5b",
      "93ca6ce65b754906bb44a592ae405232",
      "3354614af39e495a957910865e5fb9bc",
      "7e5ba2c25e6142bcbdcbafef90d2a092",
      "6394830521854e08bc52ea2b8b88cce3",
      "c5bbdb72803f442283c72b360b65655d",
      "9eae9d399e91441a9917e5e584eb5683",
      "025bc14bcbe04db8989880c3fc49cefc",
      "865134cd5bad4a4aa4805cb819c79312",
      "5e6b264578b0493192e46c7545b7f6bd",
      "45e456d7ebaa48f691bcc3dca3cc8300",
      "d78a7fabdda7469591360b54c5eaf986",
      "bac8814de4d14ca08af87d45c5b1f02d",
      "6896c761b93e4ce3bfc3cb1aef850be2",
      "2a3dc943d799432bbfd336ebf34e4330",
      "8a4eff533b464c95a7c37e434dd00649",
      "9dc82184850b4486b200b6798eb1ec0b",
      "d8e4cc90080e4bb4bc8988a5913d1510",
      "0a8db38b8133475c93920aeb7b835cc4",
      "03129c33565b4eb1b056be4d36ef2ad0",
      "4e022d85e8d142939c70b67dc1f6e50a",
      "f510cc7f99984b0fa2da61aefb08796c",
      "4c6547ebdcf64e4ab20b864551e7d29c",
      "eaa5364e608040a1988aec2bf953b8df",
      "2635e15a65414b119fcfa1057bc39129",
      "a4741e5d707142968b8bb03f4fa711c9",
      "419134004dc441598ad824fdd757bda0",
      "e11a72de91f8444bbfab4e1635b5ed9e",
      "b410c8c91c544768a5a25a094d50778b",
      "99d5c479f4fe4717be52420dca4f73f6",
      "19a46d1dea19416f948ddecb1c0fc12e",
      "487398b37b2c48ae8e6ee0b17f6b0df7",
      "cc5ffa53c56c41179a21464afdbafbc9",
      "7c345aea455e4348b3fc98300c7ba823",
      "3fe69a1a01064c9c826c650d4e8710da",
      "dd781468aed9428f91a9104af5758eb7",
      "ceb3b62808224b8fa59fa251f5f0e601",
      "aeb60b31f79c4457a2897c6794f3efc9",
      "9b87a4d305454f80ba41186821942850",
      "910baa00963d41f3b2a3e28662b92421",
      "e1851f210e3146eca6d05605808bc9bd",
      "5a50013069cb49dd98ebe3b798fc6144",
      "5eb0043c59a44bd185bf0a40361c1619",
      "cdab6beab178463981d3117eb10c4fa7",
      "625c731746824637b0a05cd8320b4fdc",
      "19f85814e6d64d4aa5028dc991d07f6c",
      "8fce9e8a9e38475787e3245b3bd9dc27",
      "ac93f628231245c19c0916dac34cecc0",
      "f02588e5767d4857b60ee518e1adc695",
      "adc20d9b72f448d0b356c097991130b2",
      "57fa5a83701a406a9a9c8af8ca63943e",
      "200c68bffe4843c094af65ed1e108f8f",
      "feb9154d5ef04b518828adfbb8fc290c",
      "3ef9c606ce9d4590bdfeeaba110d12d2",
      "8ac000106730407eb693f66622e10096",
      "70291fc3c15c4f039e61db6dc4159c40",
      "01a20f6bcff24017966167c503c85b3e",
      "0cf8a623d82f44068a25370099cd9619",
      "36b2efbf7ddb44eeb3f21dae67c09b1a"
     ]
    },
    "id": "UR7Lrk_7bw1W",
    "outputId": "5b767ee7-6b81-4649-b6ab-3a61749f5683"
   },
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "def train_fold(model_ckpt, encoded_tt_splits, lbl_, save_path):\n",
    "    label2id = {lbl: idx for idx, lbl in enumerate(lbl_)}\n",
    "    id2label = {val: key for key, val in label2id.items()}\n",
    "\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels = len(lbl_), id2label = id2label, label2id = label2id,)\n",
    "    \n",
    "    tf_train_dataset = model.prepare_tf_dataset(encoded_tt_splits['train'], shuffle = True, batch_size = batch_size, tokenizer = tokenizer)\n",
    "    tf_valid_dataset = model.prepare_tf_dataset(encoded_tt_splits['test'], shuffle = False, batch_size = batch_size, tokenizer = tokenizer)\n",
    "\n",
    "    batches_per_epoch = len(encoded_tt_splits['train']) // batch_size\n",
    "    total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "    optimizer, schedule = create_optimizer(init_lr = 2e-5, num_warmup_steps = 0, num_train_steps = total_train_steps)\n",
    "    \n",
    "    metric_callback = KerasMetricCallback(metric_fn = compute_metrics, eval_dataset = tf_valid_dataset)\n",
    "    \n",
    "    model.compile(optimizer = optimizer)\n",
    "    history = model.fit(tf_train_dataset, validation_data = (tf_valid_dataset), epochs = num_epochs, callbacks = [metric_callback])\n",
    "\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "    return tokenizer(dataset['Requirement Sentences'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] Fold 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6506f613a04922be7a8bb121781b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc39c738531e4eaf9d0ca60e7ee31da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 21:07:58.074108: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.076959: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.080609: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.083243: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.085999: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.088635: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.332597: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.334172: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.335732: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.337224: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.338745: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.340239: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.368308: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.369864: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.371386: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.372887: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.374403: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.375867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22153 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2026-01-12 21:07:58.376252: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-01-12 21:07:58.377726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22168 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2026-01-12 21:07:59.888578: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7c694c948820> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function infer_framework at 0x7c694c948820> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 21:08:35.020776: I external/local_xla/xla/service/service.cc:168] XLA service 0x7c667a242b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-01-12 21:08:35.020808: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2026-01-12 21:08:35.020818: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2026-01-12 21:08:35.030305: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-01-12 21:08:35.064850: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768248515.122175 3940741 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 94s 374ms/step - loss: 2.3224 - val_loss: 1.1870 - precision: 0.5939 - recall: 0.5788 - f1_macro: 0.5510\n",
      "Epoch 2/30\n",
      "  1/134 [..............................] - ETA: 9s - loss: 1.6595"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 25s 187ms/step - loss: 0.9099 - val_loss: 0.6363 - precision: 0.8606 - recall: 0.7854 - f1_macro: 0.8023\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 23s 175ms/step - loss: 0.5527 - val_loss: 0.5407 - precision: 0.8506 - recall: 0.8098 - f1_macro: 0.8221\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 23s 172ms/step - loss: 0.3899 - val_loss: 0.5876 - precision: 0.8203 - recall: 0.7859 - f1_macro: 0.7877\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 32s 239ms/step - loss: 0.2475 - val_loss: 0.4767 - precision: 0.8553 - recall: 0.8394 - f1_macro: 0.8406\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 20s 151ms/step - loss: 0.1766 - val_loss: 0.5141 - precision: 0.8619 - recall: 0.8330 - f1_macro: 0.8390\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 20s 153ms/step - loss: 0.1393 - val_loss: 0.5224 - precision: 0.8566 - recall: 0.8269 - f1_macro: 0.8356\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 20s 152ms/step - loss: 0.1103 - val_loss: 0.5376 - precision: 0.8520 - recall: 0.8224 - f1_macro: 0.8291\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0978 - val_loss: 0.6006 - precision: 0.8645 - recall: 0.8110 - f1_macro: 0.8237\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0927 - val_loss: 0.5532 - precision: 0.8543 - recall: 0.8146 - f1_macro: 0.8268\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0809 - val_loss: 0.6503 - precision: 0.8647 - recall: 0.8025 - f1_macro: 0.8176\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0670 - val_loss: 0.5592 - precision: 0.8781 - recall: 0.8507 - f1_macro: 0.8566\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0695 - val_loss: 0.5365 - precision: 0.8708 - recall: 0.8357 - f1_macro: 0.8450\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0563 - val_loss: 0.5224 - precision: 0.8783 - recall: 0.8525 - f1_macro: 0.8597\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 19s 138ms/step - loss: 0.0471 - val_loss: 0.5260 - precision: 0.8809 - recall: 0.8616 - f1_macro: 0.8661\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0476 - val_loss: 0.5122 - precision: 0.8795 - recall: 0.8543 - f1_macro: 0.8615\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0454 - val_loss: 0.5074 - precision: 0.8921 - recall: 0.8724 - f1_macro: 0.8766\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0402 - val_loss: 0.5500 - precision: 0.8809 - recall: 0.8623 - f1_macro: 0.8657\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 19s 142ms/step - loss: 0.0397 - val_loss: 0.5529 - precision: 0.8931 - recall: 0.8650 - f1_macro: 0.8740\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0412 - val_loss: 0.5539 - precision: 0.8840 - recall: 0.8584 - f1_macro: 0.8657\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0387 - val_loss: 0.5651 - precision: 0.8787 - recall: 0.8563 - f1_macro: 0.8620\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0350 - val_loss: 0.6037 - precision: 0.8775 - recall: 0.8484 - f1_macro: 0.8569\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0337 - val_loss: 0.5686 - precision: 0.8871 - recall: 0.8644 - f1_macro: 0.8709\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0347 - val_loss: 0.5808 - precision: 0.8942 - recall: 0.8670 - f1_macro: 0.8754\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0312 - val_loss: 0.5517 - precision: 0.8768 - recall: 0.8504 - f1_macro: 0.8575\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0334 - val_loss: 0.5281 - precision: 0.8754 - recall: 0.8590 - f1_macro: 0.8629\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0278 - val_loss: 0.5544 - precision: 0.8826 - recall: 0.8592 - f1_macro: 0.8655\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0274 - val_loss: 0.5614 - precision: 0.8806 - recall: 0.8534 - f1_macro: 0.8610\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0266 - val_loss: 0.5589 - precision: 0.8768 - recall: 0.8504 - f1_macro: 0.8575\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0240 - val_loss: 0.5638 - precision: 0.8806 - recall: 0.8534 - f1_macro: 0.8610\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee60b7bb1be47a8a9c745878ec5be70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e121c6cd1844ee6b17ffd943eef5e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] Fold 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91e91451b074e5d8a41881f11a541d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1be3b3b70594b14b0e9dcbe7a300424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "134/134 [==============================] - 77s 325ms/step - loss: 2.0626 - val_loss: 1.0548 - precision: 0.5360 - recall: 0.5362 - f1_macro: 0.4946\n",
      "Epoch 2/30\n",
      "  1/134 [..............................] - ETA: 17s - loss: 1.1516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 23s 175ms/step - loss: 0.8237 - val_loss: 0.6778 - precision: 0.7626 - recall: 0.6975 - f1_macro: 0.6866\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 21s 160ms/step - loss: 0.5159 - val_loss: 0.5823 - precision: 0.7849 - recall: 0.7649 - f1_macro: 0.7642\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.3544 - val_loss: 0.6191 - precision: 0.7760 - recall: 0.7547 - f1_macro: 0.7534\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 28s 209ms/step - loss: 0.2523 - val_loss: 0.6334 - precision: 0.7941 - recall: 0.7555 - f1_macro: 0.7586\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 23s 173ms/step - loss: 0.1579 - val_loss: 0.5611 - precision: 0.8083 - recall: 0.7904 - f1_macro: 0.7915\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 21s 158ms/step - loss: 0.1271 - val_loss: 0.6268 - precision: 0.8084 - recall: 0.7755 - f1_macro: 0.7827\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 21s 159ms/step - loss: 0.0960 - val_loss: 0.5883 - precision: 0.8474 - recall: 0.8339 - f1_macro: 0.8364\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 20s 145ms/step - loss: 0.0834 - val_loss: 0.6055 - precision: 0.8257 - recall: 0.8089 - f1_macro: 0.8123\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0734 - val_loss: 0.6406 - precision: 0.8252 - recall: 0.7958 - f1_macro: 0.7991\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0644 - val_loss: 0.5818 - precision: 0.8457 - recall: 0.8187 - f1_macro: 0.8209\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0579 - val_loss: 0.6253 - precision: 0.8065 - recall: 0.7974 - f1_macro: 0.7981\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0600 - val_loss: 0.6501 - precision: 0.8171 - recall: 0.8030 - f1_macro: 0.8043\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0515 - val_loss: 0.6118 - precision: 0.8192 - recall: 0.8121 - f1_macro: 0.8106\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0447 - val_loss: 0.6656 - precision: 0.8138 - recall: 0.7885 - f1_macro: 0.7896\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0479 - val_loss: 0.5815 - precision: 0.8493 - recall: 0.8473 - f1_macro: 0.8459\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0398 - val_loss: 0.6584 - precision: 0.8245 - recall: 0.8017 - f1_macro: 0.8026\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0387 - val_loss: 0.6424 - precision: 0.8358 - recall: 0.8292 - f1_macro: 0.8275\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0371 - val_loss: 0.6502 - precision: 0.8241 - recall: 0.8121 - f1_macro: 0.8135\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0353 - val_loss: 0.6493 - precision: 0.8427 - recall: 0.8338 - f1_macro: 0.8340\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0317 - val_loss: 0.6705 - precision: 0.8307 - recall: 0.8128 - f1_macro: 0.8133\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0344 - val_loss: 0.6958 - precision: 0.8285 - recall: 0.8130 - f1_macro: 0.8150\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 20s 152ms/step - loss: 0.0323 - val_loss: 0.6370 - precision: 0.8399 - recall: 0.8386 - f1_macro: 0.8358\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0290 - val_loss: 0.6710 - precision: 0.8291 - recall: 0.8181 - f1_macro: 0.8170\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 20s 145ms/step - loss: 0.0258 - val_loss: 0.6677 - precision: 0.8351 - recall: 0.8203 - f1_macro: 0.8225\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0263 - val_loss: 0.6539 - precision: 0.8325 - recall: 0.8173 - f1_macro: 0.8194\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0241 - val_loss: 0.6423 - precision: 0.8358 - recall: 0.8312 - f1_macro: 0.8304\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0230 - val_loss: 0.6516 - precision: 0.8342 - recall: 0.8259 - f1_macro: 0.8256\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0224 - val_loss: 0.6529 - precision: 0.8342 - recall: 0.8259 - f1_macro: 0.8256\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0216 - val_loss: 0.6541 - precision: 0.8342 - recall: 0.8259 - f1_macro: 0.8256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67d185405294a8daaf2655ebd88230e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2212e07d71a94ac9a8c5be1c4f8cb6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] Fold 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901c724839554d46825c5eb008d054d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7c3e51b5f647a5bd752eedc8f80b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "134/134 [==============================] - 77s 323ms/step - loss: 2.0720 - val_loss: 1.1730 - precision: 0.5960 - recall: 0.5238 - f1_macro: 0.4774\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 24s 177ms/step - loss: 0.8506 - val_loss: 0.6061 - precision: 0.8682 - recall: 0.8039 - f1_macro: 0.8091\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 21s 158ms/step - loss: 0.5222 - val_loss: 0.4649 - precision: 0.8434 - recall: 0.8101 - f1_macro: 0.8132\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.3308 - val_loss: 0.3800 - precision: 0.9165 - recall: 0.8800 - f1_macro: 0.8922\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.2236 - val_loss: 0.3704 - precision: 0.9008 - recall: 0.8773 - f1_macro: 0.8839\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.1541 - val_loss: 0.4647 - precision: 0.8890 - recall: 0.8612 - f1_macro: 0.8633\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.1291 - val_loss: 0.3958 - precision: 0.9122 - recall: 0.8925 - f1_macro: 0.8975\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0909 - val_loss: 0.4185 - precision: 0.8941 - recall: 0.8760 - f1_macro: 0.8782\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0808 - val_loss: 0.4255 - precision: 0.8788 - recall: 0.8775 - f1_macro: 0.8752\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0781 - val_loss: 0.4152 - precision: 0.8999 - recall: 0.8839 - f1_macro: 0.8876\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0669 - val_loss: 0.3875 - precision: 0.9141 - recall: 0.8946 - f1_macro: 0.8998\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0556 - val_loss: 0.4164 - precision: 0.9037 - recall: 0.8814 - f1_macro: 0.8881\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0493 - val_loss: 0.3958 - precision: 0.9278 - recall: 0.9019 - f1_macro: 0.9091\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0489 - val_loss: 0.4948 - precision: 0.8790 - recall: 0.8761 - f1_macro: 0.8724\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0456 - val_loss: 0.4340 - precision: 0.8990 - recall: 0.8918 - f1_macro: 0.8930\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0381 - val_loss: 0.4530 - precision: 0.9031 - recall: 0.8813 - f1_macro: 0.8856\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0377 - val_loss: 0.4859 - precision: 0.8918 - recall: 0.8868 - f1_macro: 0.8853\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0379 - val_loss: 0.4577 - precision: 0.9150 - recall: 0.8982 - f1_macro: 0.9007\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0372 - val_loss: 0.4828 - precision: 0.8955 - recall: 0.8831 - f1_macro: 0.8847\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 24s 180ms/step - loss: 0.0343 - val_loss: 0.4702 - precision: 0.9016 - recall: 0.8955 - f1_macro: 0.8956\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 23s 168ms/step - loss: 0.0318 - val_loss: 0.4785 - precision: 0.9044 - recall: 0.8934 - f1_macro: 0.8949\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 22s 162ms/step - loss: 0.0328 - val_loss: 0.4662 - precision: 0.9012 - recall: 0.8931 - f1_macro: 0.8941\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 23s 173ms/step - loss: 0.0280 - val_loss: 0.4854 - precision: 0.8966 - recall: 0.8901 - f1_macro: 0.8900\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 22s 168ms/step - loss: 0.0274 - val_loss: 0.4835 - precision: 0.8912 - recall: 0.8852 - f1_macro: 0.8847\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 32s 238ms/step - loss: 0.0246 - val_loss: 0.4896 - precision: 0.8985 - recall: 0.8879 - f1_macro: 0.8890\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 26s 193ms/step - loss: 0.0260 - val_loss: 0.5036 - precision: 0.8950 - recall: 0.8835 - f1_macro: 0.8847\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 21s 161ms/step - loss: 0.0255 - val_loss: 0.5020 - precision: 0.9078 - recall: 0.8910 - f1_macro: 0.8948\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0257 - val_loss: 0.4967 - precision: 0.8971 - recall: 0.8808 - f1_macro: 0.8832\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 22s 167ms/step - loss: 0.0221 - val_loss: 0.4977 - precision: 0.8985 - recall: 0.8879 - f1_macro: 0.8896\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 22s 167ms/step - loss: 0.0211 - val_loss: 0.4981 - precision: 0.9003 - recall: 0.8857 - f1_macro: 0.8882\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646f1d0577e344cf88b26596f72de651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55ecf0f823e4a3390e60a620a47f15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] Fold 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d30406167b44cdabe328668436e4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9b46871ff24dc5a9b64ef29c81c4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "134/134 [==============================] - 79s 335ms/step - loss: 2.2901 - val_loss: 1.2400 - precision: 0.5281 - recall: 0.5056 - f1_macro: 0.4551\n",
      "Epoch 2/30\n",
      "  2/134 [..............................] - ETA: 8s - loss: 1.3574 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 24s 184ms/step - loss: 0.9634 - val_loss: 0.7593 - precision: 0.7316 - recall: 0.6584 - f1_macro: 0.6647\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 24s 176ms/step - loss: 0.5739 - val_loss: 0.6029 - precision: 0.8145 - recall: 0.7747 - f1_macro: 0.7842\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 23s 175ms/step - loss: 0.3569 - val_loss: 0.5090 - precision: 0.8355 - recall: 0.8155 - f1_macro: 0.8168\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 22s 163ms/step - loss: 0.2421 - val_loss: 0.4437 - precision: 0.8531 - recall: 0.8429 - f1_macro: 0.8448\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 22s 163ms/step - loss: 0.1792 - val_loss: 0.5047 - precision: 0.8795 - recall: 0.8499 - f1_macro: 0.8592\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 27s 201ms/step - loss: 0.1312 - val_loss: 0.5725 - precision: 0.8777 - recall: 0.8267 - f1_macro: 0.8372\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 22s 166ms/step - loss: 0.1180 - val_loss: 0.5109 - precision: 0.8664 - recall: 0.8556 - f1_macro: 0.8551\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 26s 194ms/step - loss: 0.1004 - val_loss: 0.5651 - precision: 0.8636 - recall: 0.8449 - f1_macro: 0.8506\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0868 - val_loss: 0.4913 - precision: 0.8804 - recall: 0.8633 - f1_macro: 0.8698\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 21s 157ms/step - loss: 0.0626 - val_loss: 0.4929 - precision: 0.8877 - recall: 0.8691 - f1_macro: 0.8755\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 29s 214ms/step - loss: 0.0572 - val_loss: 0.6178 - precision: 0.8715 - recall: 0.8261 - f1_macro: 0.8383\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 20s 152ms/step - loss: 0.0743 - val_loss: 0.5925 - precision: 0.8783 - recall: 0.8524 - f1_macro: 0.8598\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 22s 162ms/step - loss: 0.0570 - val_loss: 0.6537 - precision: 0.8850 - recall: 0.8422 - f1_macro: 0.8534\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0488 - val_loss: 0.5802 - precision: 0.8946 - recall: 0.8642 - f1_macro: 0.8714\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0450 - val_loss: 0.6329 - precision: 0.8795 - recall: 0.8539 - f1_macro: 0.8608\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 19s 142ms/step - loss: 0.0397 - val_loss: 0.6083 - precision: 0.8773 - recall: 0.8530 - f1_macro: 0.8597\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 19s 142ms/step - loss: 0.0391 - val_loss: 0.6667 - precision: 0.8761 - recall: 0.8372 - f1_macro: 0.8473\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0381 - val_loss: 0.5868 - precision: 0.8905 - recall: 0.8695 - f1_macro: 0.8740\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0338 - val_loss: 0.6599 - precision: 0.8795 - recall: 0.8402 - f1_macro: 0.8510\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 19s 139ms/step - loss: 0.0324 - val_loss: 0.5883 - precision: 0.8795 - recall: 0.8607 - f1_macro: 0.8635\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0311 - val_loss: 0.6095 - precision: 0.8987 - recall: 0.8695 - f1_macro: 0.8752\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0312 - val_loss: 0.5907 - precision: 0.8933 - recall: 0.8670 - f1_macro: 0.8718\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0302 - val_loss: 0.6413 - precision: 0.8979 - recall: 0.8646 - f1_macro: 0.8714\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0293 - val_loss: 0.6500 - precision: 0.8804 - recall: 0.8534 - f1_macro: 0.8614\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0258 - val_loss: 0.6196 - precision: 0.8804 - recall: 0.8534 - f1_macro: 0.8614\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 19s 140ms/step - loss: 0.0258 - val_loss: 0.6242 - precision: 0.8901 - recall: 0.8646 - f1_macro: 0.8716\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0259 - val_loss: 0.6196 - precision: 0.8781 - recall: 0.8548 - f1_macro: 0.8626\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0241 - val_loss: 0.6240 - precision: 0.8779 - recall: 0.8548 - f1_macro: 0.8613\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0220 - val_loss: 0.6295 - precision: 0.8781 - recall: 0.8548 - f1_macro: 0.8626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8eb62eb5e0b40598d8588cf6b946294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec1b8b1a0c649f68df4a5724e66db1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] Fold 5/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97ce87910ac43a5bc70be21f6735135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0035246b3b0b4f41ae38fc459f6a7066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "134/134 [==============================] - 78s 323ms/step - loss: 2.1597 - val_loss: 1.1519 - precision: 0.5825 - recall: 0.5625 - f1_macro: 0.5349\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 24s 177ms/step - loss: 0.8705 - val_loss: 0.5939 - precision: 0.7692 - recall: 0.7769 - f1_macro: 0.7628\n",
      "Epoch 3/30\n",
      "  2/134 [..............................] - ETA: 8s - loss: 0.6435"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 22s 166ms/step - loss: 0.5246 - val_loss: 0.5262 - precision: 0.8423 - recall: 0.8020 - f1_macro: 0.8106\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 21s 152ms/step - loss: 0.3276 - val_loss: 0.4359 - precision: 0.8463 - recall: 0.8325 - f1_macro: 0.8325\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.2047 - val_loss: 0.4481 - precision: 0.8652 - recall: 0.8520 - f1_macro: 0.8524\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 20s 152ms/step - loss: 0.1539 - val_loss: 0.4170 - precision: 0.8890 - recall: 0.8758 - f1_macro: 0.8771\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.1109 - val_loss: 0.4365 - precision: 0.8835 - recall: 0.8680 - f1_macro: 0.8718\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0811 - val_loss: 0.4749 - precision: 0.8801 - recall: 0.8657 - f1_macro: 0.8686\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0772 - val_loss: 0.4809 - precision: 0.8796 - recall: 0.8685 - f1_macro: 0.8705\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0672 - val_loss: 0.4673 - precision: 0.8919 - recall: 0.8821 - f1_macro: 0.8820\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0684 - val_loss: 0.4405 - precision: 0.8756 - recall: 0.8674 - f1_macro: 0.8659\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0542 - val_loss: 0.4507 - precision: 0.8876 - recall: 0.8861 - f1_macro: 0.8828\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0553 - val_loss: 0.5067 - precision: 0.8750 - recall: 0.8714 - f1_macro: 0.8674\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 19s 142ms/step - loss: 0.0462 - val_loss: 0.4662 - precision: 0.8782 - recall: 0.8703 - f1_macro: 0.8707\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0462 - val_loss: 0.4724 - precision: 0.8627 - recall: 0.8495 - f1_macro: 0.8517\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0428 - val_loss: 0.4620 - precision: 0.8862 - recall: 0.8815 - f1_macro: 0.8806\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0423 - val_loss: 0.4727 - precision: 0.8833 - recall: 0.8708 - f1_macro: 0.8723\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 20s 145ms/step - loss: 0.0355 - val_loss: 0.4735 - precision: 0.8862 - recall: 0.8716 - f1_macro: 0.8741\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 20s 151ms/step - loss: 0.0330 - val_loss: 0.4861 - precision: 0.8857 - recall: 0.8719 - f1_macro: 0.8744\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0354 - val_loss: 0.4778 - precision: 0.8830 - recall: 0.8762 - f1_macro: 0.8764\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0321 - val_loss: 0.4907 - precision: 0.8969 - recall: 0.8910 - f1_macro: 0.8905\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0311 - val_loss: 0.4933 - precision: 0.8919 - recall: 0.8881 - f1_macro: 0.8867\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0282 - val_loss: 0.5087 - precision: 0.8940 - recall: 0.8862 - f1_macro: 0.8861\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0271 - val_loss: 0.5197 - precision: 0.8857 - recall: 0.8744 - f1_macro: 0.8760\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0264 - val_loss: 0.5204 - precision: 0.8907 - recall: 0.8773 - f1_macro: 0.8798\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0281 - val_loss: 0.5111 - precision: 0.8919 - recall: 0.8881 - f1_macro: 0.8867\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0248 - val_loss: 0.5156 - precision: 0.8898 - recall: 0.8821 - f1_macro: 0.8817\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0227 - val_loss: 0.5204 - precision: 0.8855 - recall: 0.8755 - f1_macro: 0.8764\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0238 - val_loss: 0.5256 - precision: 0.8905 - recall: 0.8785 - f1_macro: 0.8802\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0218 - val_loss: 0.5249 - precision: 0.8855 - recall: 0.8755 - f1_macro: 0.8764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4831613098e84d7e95035ce861142b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df8baff55f94adf99fdbcf3ddd6d228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] Fold 6/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f036fa583d0a4e76a723070aca16bfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21056060e39431faa475b3b3023f170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "134/134 [==============================] - 79s 330ms/step - loss: 2.1086 - val_loss: 1.1591 - precision: 0.5240 - recall: 0.4945 - f1_macro: 0.4532\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 24s 177ms/step - loss: 0.8690 - val_loss: 0.7531 - precision: 0.7954 - recall: 0.7019 - f1_macro: 0.6994\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 21s 159ms/step - loss: 0.5439 - val_loss: 0.5789 - precision: 0.8356 - recall: 0.7833 - f1_macro: 0.7920\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 21s 158ms/step - loss: 0.3341 - val_loss: 0.6526 - precision: 0.8437 - recall: 0.7618 - f1_macro: 0.7750\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 20s 153ms/step - loss: 0.2117 - val_loss: 0.5507 - precision: 0.8782 - recall: 0.8211 - f1_macro: 0.8347\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 20s 152ms/step - loss: 0.1593 - val_loss: 0.5121 - precision: 0.8546 - recall: 0.8257 - f1_macro: 0.8312\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.1289 - val_loss: 0.5797 - precision: 0.8825 - recall: 0.8239 - f1_macro: 0.8382\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 20s 151ms/step - loss: 0.1247 - val_loss: 0.5332 - precision: 0.8784 - recall: 0.8378 - f1_macro: 0.8514\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0923 - val_loss: 0.5535 - precision: 0.8724 - recall: 0.8355 - f1_macro: 0.8471\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 20s 152ms/step - loss: 0.0805 - val_loss: 0.5198 - precision: 0.8724 - recall: 0.8567 - f1_macro: 0.8594\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0772 - val_loss: 0.5609 - precision: 0.8798 - recall: 0.8475 - f1_macro: 0.8587\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0637 - val_loss: 0.5967 - precision: 0.8905 - recall: 0.8420 - f1_macro: 0.8577\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0579 - val_loss: 0.5672 - precision: 0.8933 - recall: 0.8494 - f1_macro: 0.8624\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0511 - val_loss: 0.5974 - precision: 0.8996 - recall: 0.8405 - f1_macro: 0.8539\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0484 - val_loss: 0.6142 - precision: 0.8507 - recall: 0.8263 - f1_macro: 0.8336\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0481 - val_loss: 0.6334 - precision: 0.8721 - recall: 0.8313 - f1_macro: 0.8443\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0415 - val_loss: 0.6353 - precision: 0.8601 - recall: 0.8303 - f1_macro: 0.8399\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0392 - val_loss: 0.6180 - precision: 0.8670 - recall: 0.8284 - f1_macro: 0.8408\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0331 - val_loss: 0.6273 - precision: 0.8832 - recall: 0.8340 - f1_macro: 0.8495\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 19s 140ms/step - loss: 0.0353 - val_loss: 0.7628 - precision: 0.8696 - recall: 0.8082 - f1_macro: 0.8252\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0324 - val_loss: 0.6062 - precision: 0.8809 - recall: 0.8471 - f1_macro: 0.8574\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 20s 145ms/step - loss: 0.0318 - val_loss: 0.6009 - precision: 0.8689 - recall: 0.8463 - f1_macro: 0.8520\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0332 - val_loss: 0.6220 - precision: 0.8550 - recall: 0.8363 - f1_macro: 0.8414\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0313 - val_loss: 0.6089 - precision: 0.8767 - recall: 0.8515 - f1_macro: 0.8606\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0294 - val_loss: 0.5948 - precision: 0.8953 - recall: 0.8627 - f1_macro: 0.8732\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0251 - val_loss: 0.5952 - precision: 0.8767 - recall: 0.8539 - f1_macro: 0.8618\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0247 - val_loss: 0.5954 - precision: 0.8863 - recall: 0.8520 - f1_macro: 0.8632\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0255 - val_loss: 0.6127 - precision: 0.8904 - recall: 0.8550 - f1_macro: 0.8673\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0238 - val_loss: 0.6193 - precision: 0.8837 - recall: 0.8455 - f1_macro: 0.8579\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0257 - val_loss: 0.6124 - precision: 0.8863 - recall: 0.8520 - f1_macro: 0.8632\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde5b4173b4c4458a66d000e91229ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d875e45fe23443d8b5352f14d76a2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] Fold 7/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d5388e4d764417ad45596238de13df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bff350a4c04b7bbdb924f8ca427516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/239 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "134/134 [==============================] - 82s 361ms/step - loss: 2.2278 - val_loss: 1.1618 - precision: 0.5282 - recall: 0.5160 - f1_macro: 0.4696\n",
      "Epoch 2/30\n",
      "  2/134 [..............................] - ETA: 9s - loss: 1.3059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 24s 177ms/step - loss: 0.8982 - val_loss: 0.6396 - precision: 0.7940 - recall: 0.7093 - f1_macro: 0.7103\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.5593 - val_loss: 0.5923 - precision: 0.8312 - recall: 0.7562 - f1_macro: 0.7609\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 21s 158ms/step - loss: 0.3518 - val_loss: 0.4605 - precision: 0.8639 - recall: 0.8216 - f1_macro: 0.8279\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 21s 154ms/step - loss: 0.2175 - val_loss: 0.4857 - precision: 0.8696 - recall: 0.8273 - f1_macro: 0.8348\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.1539 - val_loss: 0.5560 - precision: 0.8679 - recall: 0.8244 - f1_macro: 0.8290\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.1196 - val_loss: 0.5456 - precision: 0.8725 - recall: 0.8360 - f1_macro: 0.8439\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 20s 145ms/step - loss: 0.0860 - val_loss: 0.4946 - precision: 0.8790 - recall: 0.8489 - f1_macro: 0.8572\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0832 - val_loss: 0.5061 - precision: 0.8759 - recall: 0.8435 - f1_macro: 0.8505\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0708 - val_loss: 0.8601 - precision: 0.8335 - recall: 0.7484 - f1_macro: 0.7578\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0716 - val_loss: 0.6717 - precision: 0.8400 - recall: 0.7937 - f1_macro: 0.7994\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0629 - val_loss: 0.6183 - precision: 0.8523 - recall: 0.8181 - f1_macro: 0.8278\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0554 - val_loss: 0.5953 - precision: 0.8495 - recall: 0.8310 - f1_macro: 0.8339\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0481 - val_loss: 0.5199 - precision: 0.8671 - recall: 0.8366 - f1_macro: 0.8448\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0440 - val_loss: 0.5090 - precision: 0.8726 - recall: 0.8425 - f1_macro: 0.8508\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0417 - val_loss: 0.5356 - precision: 0.8519 - recall: 0.8340 - f1_macro: 0.8386\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0407 - val_loss: 0.5729 - precision: 0.8754 - recall: 0.8354 - f1_macro: 0.8401\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 19s 141ms/step - loss: 0.0341 - val_loss: 0.5130 - precision: 0.8713 - recall: 0.8498 - f1_macro: 0.8534\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0367 - val_loss: 0.6335 - precision: 0.8612 - recall: 0.8154 - f1_macro: 0.8212\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0319 - val_loss: 0.5537 - precision: 0.8687 - recall: 0.8406 - f1_macro: 0.8479\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0294 - val_loss: 0.6881 - precision: 0.8730 - recall: 0.8212 - f1_macro: 0.8282\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0307 - val_loss: 0.5924 - precision: 0.8586 - recall: 0.8347 - f1_macro: 0.8408\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0283 - val_loss: 0.5997 - precision: 0.8687 - recall: 0.8406 - f1_macro: 0.8479\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0287 - val_loss: 0.5644 - precision: 0.8666 - recall: 0.8424 - f1_macro: 0.8459\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0267 - val_loss: 0.5814 - precision: 0.8872 - recall: 0.8582 - f1_macro: 0.8666\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0231 - val_loss: 0.5851 - precision: 0.8735 - recall: 0.8464 - f1_macro: 0.8541\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 20s 145ms/step - loss: 0.0265 - val_loss: 0.6031 - precision: 0.8802 - recall: 0.8440 - f1_macro: 0.8527\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0244 - val_loss: 0.6119 - precision: 0.8802 - recall: 0.8440 - f1_macro: 0.8527\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0230 - val_loss: 0.6242 - precision: 0.8802 - recall: 0.8380 - f1_macro: 0.8475\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0219 - val_loss: 0.6136 - precision: 0.8839 - recall: 0.8434 - f1_macro: 0.8521\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d261998408524a2ab25890a774fa8c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3c71e5356a4fdf8880ab48df3fba7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/239 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] Fold 8/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5a7bcffa8744b49933a37e6319d583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3cfbbca4f74c9a8d5edce0c5b52b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/239 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "134/134 [==============================] - 83s 359ms/step - loss: 2.1186 - val_loss: 1.0655 - precision: 0.6949 - recall: 0.5433 - f1_macro: 0.5284\n",
      "Epoch 2/30\n",
      "134/134 [==============================] - 24s 179ms/step - loss: 0.8696 - val_loss: 0.7192 - precision: 0.7420 - recall: 0.6920 - f1_macro: 0.6927\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 22s 159ms/step - loss: 0.5325 - val_loss: 0.6557 - precision: 0.8084 - recall: 0.7275 - f1_macro: 0.7249\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 21s 157ms/step - loss: 0.3227 - val_loss: 0.4730 - precision: 0.8477 - recall: 0.8188 - f1_macro: 0.8248\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 20s 153ms/step - loss: 0.2209 - val_loss: 0.5115 - precision: 0.8236 - recall: 0.8169 - f1_macro: 0.8119\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 20s 153ms/step - loss: 0.1433 - val_loss: 0.4521 - precision: 0.8432 - recall: 0.8265 - f1_macro: 0.8304\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 20s 152ms/step - loss: 0.1070 - val_loss: 0.5295 - precision: 0.8457 - recall: 0.8131 - f1_macro: 0.8232\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0899 - val_loss: 0.6521 - precision: 0.8116 - recall: 0.8065 - f1_macro: 0.8041\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0945 - val_loss: 0.6278 - precision: 0.8443 - recall: 0.8120 - f1_macro: 0.8166\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0951 - val_loss: 0.7062 - precision: 0.8504 - recall: 0.7954 - f1_macro: 0.8077\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0648 - val_loss: 0.6086 - precision: 0.8519 - recall: 0.8225 - f1_macro: 0.8290\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0572 - val_loss: 0.5441 - precision: 0.8577 - recall: 0.8374 - f1_macro: 0.8426\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.0600 - val_loss: 0.5748 - precision: 0.8493 - recall: 0.8219 - f1_macro: 0.8298\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0508 - val_loss: 0.5833 - precision: 0.8517 - recall: 0.8232 - f1_macro: 0.8295\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0453 - val_loss: 0.5527 - precision: 0.8530 - recall: 0.8349 - f1_macro: 0.8372\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0438 - val_loss: 0.5540 - precision: 0.8463 - recall: 0.8259 - f1_macro: 0.8283\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0462 - val_loss: 0.6393 - precision: 0.8365 - recall: 0.8315 - f1_macro: 0.8304\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 20s 151ms/step - loss: 0.0387 - val_loss: 0.6286 - precision: 0.8301 - recall: 0.8173 - f1_macro: 0.8195\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0374 - val_loss: 0.6068 - precision: 0.8486 - recall: 0.8294 - f1_macro: 0.8335\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0321 - val_loss: 0.5372 - precision: 0.8680 - recall: 0.8540 - f1_macro: 0.8548\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0299 - val_loss: 0.5734 - precision: 0.8563 - recall: 0.8328 - f1_macro: 0.8383\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0316 - val_loss: 0.5890 - precision: 0.8562 - recall: 0.8389 - f1_macro: 0.8419\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 19s 139ms/step - loss: 0.0285 - val_loss: 0.5960 - precision: 0.8574 - recall: 0.8383 - f1_macro: 0.8412\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0288 - val_loss: 0.5449 - precision: 0.8719 - recall: 0.8605 - f1_macro: 0.8597\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0253 - val_loss: 0.5816 - precision: 0.8595 - recall: 0.8349 - f1_macro: 0.8410\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0246 - val_loss: 0.5769 - precision: 0.8660 - recall: 0.8468 - f1_macro: 0.8513\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0242 - val_loss: 0.5697 - precision: 0.8639 - recall: 0.8501 - f1_macro: 0.8517\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 19s 142ms/step - loss: 0.0230 - val_loss: 0.5802 - precision: 0.8605 - recall: 0.8448 - f1_macro: 0.8467\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0237 - val_loss: 0.5864 - precision: 0.8562 - recall: 0.8389 - f1_macro: 0.8419\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0239 - val_loss: 0.5877 - precision: 0.8609 - recall: 0.8415 - f1_macro: 0.8457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30691531f2074284ac32b7812095c368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686db43738144ec78c52aa47f921b58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/239 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] Fold 9/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bb9db7e63c4c438b7ac1c5c08b8bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1d4c87f03a4b4fb72bb3248e093a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/239 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "134/134 [==============================] - 82s 372ms/step - loss: 2.2375 - val_loss: 1.2663 - precision: 0.5138 - recall: 0.4943 - f1_macro: 0.4460\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 24s 179ms/step - loss: 0.9258 - val_loss: 0.7525 - precision: 0.8113 - recall: 0.6943 - f1_macro: 0.6980\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 22s 161ms/step - loss: 0.5363 - val_loss: 0.5162 - precision: 0.8584 - recall: 0.8278 - f1_macro: 0.8302\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 20s 153ms/step - loss: 0.3359 - val_loss: 0.4701 - precision: 0.8922 - recall: 0.8460 - f1_macro: 0.8551\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.1927 - val_loss: 0.4660 - precision: 0.8549 - recall: 0.8462 - f1_macro: 0.8487\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.1324 - val_loss: 0.5310 - precision: 0.8544 - recall: 0.8400 - f1_macro: 0.8420\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.1282 - val_loss: 0.6264 - precision: 0.8223 - recall: 0.8189 - f1_macro: 0.8146\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0955 - val_loss: 0.5248 - precision: 0.8526 - recall: 0.8321 - f1_macro: 0.8361\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0837 - val_loss: 0.5398 - precision: 0.8557 - recall: 0.8360 - f1_macro: 0.8387\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0654 - val_loss: 0.6061 - precision: 0.8376 - recall: 0.8093 - f1_macro: 0.8159\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0670 - val_loss: 0.6344 - precision: 0.8522 - recall: 0.8264 - f1_macro: 0.8284\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0601 - val_loss: 0.5458 - precision: 0.8713 - recall: 0.8552 - f1_macro: 0.8593\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 0.0524 - val_loss: 0.6306 - precision: 0.8470 - recall: 0.8254 - f1_macro: 0.8269\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0583 - val_loss: 0.5541 - precision: 0.8575 - recall: 0.8408 - f1_macro: 0.8430\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0397 - val_loss: 0.5363 - precision: 0.8678 - recall: 0.8547 - f1_macro: 0.8583\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0469 - val_loss: 0.5471 - precision: 0.8719 - recall: 0.8542 - f1_macro: 0.8581\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 19s 140ms/step - loss: 0.0389 - val_loss: 0.5479 - precision: 0.8718 - recall: 0.8547 - f1_macro: 0.8587\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 19s 141ms/step - loss: 0.0369 - val_loss: 0.5893 - precision: 0.8704 - recall: 0.8489 - f1_macro: 0.8534\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0372 - val_loss: 0.5531 - precision: 0.8592 - recall: 0.8434 - f1_macro: 0.8459\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0425 - val_loss: 0.5412 - precision: 0.8674 - recall: 0.8491 - f1_macro: 0.8532\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0365 - val_loss: 0.6083 - precision: 0.8503 - recall: 0.8412 - f1_macro: 0.8409\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 19s 146ms/step - loss: 0.0332 - val_loss: 0.5918 - precision: 0.8693 - recall: 0.8490 - f1_macro: 0.8532\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0290 - val_loss: 0.5709 - precision: 0.8685 - recall: 0.8517 - f1_macro: 0.8534\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0281 - val_loss: 0.5444 - precision: 0.8692 - recall: 0.8522 - f1_macro: 0.8555\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0259 - val_loss: 0.5804 - precision: 0.8734 - recall: 0.8548 - f1_macro: 0.8585\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0256 - val_loss: 0.5718 - precision: 0.8682 - recall: 0.8494 - f1_macro: 0.8522\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 19s 142ms/step - loss: 0.0251 - val_loss: 0.5618 - precision: 0.8682 - recall: 0.8494 - f1_macro: 0.8522\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 19s 143ms/step - loss: 0.0266 - val_loss: 0.5637 - precision: 0.8615 - recall: 0.8465 - f1_macro: 0.8487\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 19s 139ms/step - loss: 0.0243 - val_loss: 0.5667 - precision: 0.8615 - recall: 0.8465 - f1_macro: 0.8487\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0221 - val_loss: 0.5675 - precision: 0.8682 - recall: 0.8494 - f1_macro: 0.8522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032ac79eeeb049f0b7c11bac81f5c782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db49a6a103974fd9b39ada56236bb5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/239 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] Fold 10/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c73068ca7b644ae9961d75b6e978e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcba9ef7f124c2985902f01fc549973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/239 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "134/134 [==============================] - 83s 361ms/step - loss: 2.2562 - val_loss: 1.2589 - precision: 0.3638 - recall: 0.4564 - f1_macro: 0.3710\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 24s 177ms/step - loss: 0.9748 - val_loss: 0.7424 - precision: 0.7456 - recall: 0.6931 - f1_macro: 0.6899\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 21s 160ms/step - loss: 0.5862 - val_loss: 0.5586 - precision: 0.7859 - recall: 0.7791 - f1_macro: 0.7693\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.3884 - val_loss: 0.6665 - precision: 0.8199 - recall: 0.7369 - f1_macro: 0.7460\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 20s 151ms/step - loss: 0.2472 - val_loss: 0.5317 - precision: 0.8617 - recall: 0.8365 - f1_macro: 0.8420\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 0.1669 - val_loss: 0.5141 - precision: 0.8564 - recall: 0.8384 - f1_macro: 0.8354\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 20s 150ms/step - loss: 0.1378 - val_loss: 0.5220 - precision: 0.8453 - recall: 0.8196 - f1_macro: 0.8265\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.1056 - val_loss: 0.4892 - precision: 0.8385 - recall: 0.8359 - f1_macro: 0.8356\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 20s 153ms/step - loss: 0.0941 - val_loss: 0.5527 - precision: 0.8485 - recall: 0.8293 - f1_macro: 0.8324\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0776 - val_loss: 0.5264 - precision: 0.8526 - recall: 0.8495 - f1_macro: 0.8437\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 0.0776 - val_loss: 0.6500 - precision: 0.8462 - recall: 0.8126 - f1_macro: 0.8214\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0748 - val_loss: 0.5682 - precision: 0.8485 - recall: 0.8233 - f1_macro: 0.8298\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 20s 146ms/step - loss: 0.0761 - val_loss: 0.5498 - precision: 0.8589 - recall: 0.8445 - f1_macro: 0.8466\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 0.0550 - val_loss: 0.5625 - precision: 0.8472 - recall: 0.8320 - f1_macro: 0.8374\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 23s 172ms/step - loss: 0.0560 - val_loss: 0.6059 - precision: 0.8539 - recall: 0.8389 - f1_macro: 0.8409\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 23s 173ms/step - loss: 0.0446 - val_loss: 0.6109 - precision: 0.8768 - recall: 0.8474 - f1_macro: 0.8567\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 22s 165ms/step - loss: 0.0387 - val_loss: 0.6039 - precision: 0.8566 - recall: 0.8405 - f1_macro: 0.8454\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 27s 203ms/step - loss: 0.0373 - val_loss: 0.5786 - precision: 0.8697 - recall: 0.8520 - f1_macro: 0.8560\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 21s 158ms/step - loss: 0.0356 - val_loss: 0.6318 - precision: 0.8575 - recall: 0.8413 - f1_macro: 0.8454\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 22s 167ms/step - loss: 0.0363 - val_loss: 0.5864 - precision: 0.8785 - recall: 0.8478 - f1_macro: 0.8579\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 22s 168ms/step - loss: 0.0335 - val_loss: 0.6298 - precision: 0.8643 - recall: 0.8410 - f1_macro: 0.8487\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 26s 197ms/step - loss: 0.0342 - val_loss: 0.6458 - precision: 0.8698 - recall: 0.8411 - f1_macro: 0.8511\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 22s 165ms/step - loss: 0.0322 - val_loss: 0.6341 - precision: 0.8737 - recall: 0.8460 - f1_macro: 0.8551\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 21s 157ms/step - loss: 0.0299 - val_loss: 0.6371 - precision: 0.8517 - recall: 0.8335 - f1_macro: 0.8391\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 21s 159ms/step - loss: 0.0367 - val_loss: 0.6308 - precision: 0.8528 - recall: 0.8446 - f1_macro: 0.8440\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 27s 202ms/step - loss: 0.0274 - val_loss: 0.6367 - precision: 0.8556 - recall: 0.8401 - f1_macro: 0.8435\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 21s 159ms/step - loss: 0.0287 - val_loss: 0.6188 - precision: 0.8768 - recall: 0.8494 - f1_macro: 0.8583\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 22s 164ms/step - loss: 0.0261 - val_loss: 0.6161 - precision: 0.8702 - recall: 0.8469 - f1_macro: 0.8539\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 21s 159ms/step - loss: 0.0259 - val_loss: 0.6171 - precision: 0.8768 - recall: 0.8494 - f1_macro: 0.8583\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 21s 158ms/step - loss: 0.0246 - val_loss: 0.6234 - precision: 0.8838 - recall: 0.8543 - f1_macro: 0.8636\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ec50b33835474d9c5fe0f124260023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e896ff99174570841d48f783ac27b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/239 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "K = 10\n",
    "batch_size = 16\n",
    "num_epochs = 30\n",
    "model_ckpt = 'FacebookAI/roberta-base'\n",
    "model_name = model_ckpt.split('/')[-1]\n",
    "label_names = dataset.features['label'].names\n",
    "\n",
    "labels = np.array(dataset[\"label\"])\n",
    "skf = StratifiedKFold(n_splits = K, shuffle = True, random_state = 42)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(np.zeros(len(labels)), labels), start = 1):\n",
    "    print(f'[TRAINING] Fold {fold}/{K}')\n",
    "    train_split = dataset.select(train_idx.tolist())\n",
    "    test_split  = dataset.select(test_idx.tolist())\n",
    "    train_data = datasets.DatasetDict({\"train\": train_split, \"test\": test_split})\n",
    "    encoded_tt_splits = train_data.map(preprocess_function, batched = True)        \n",
    "\n",
    "    save_path = f'./models/tuned_10_fold/reqseek_roberta_base_kfold_trained/trained_fold_{fold}'\n",
    "    train_fold(model_ckpt, encoded_tt_splits, label_names, save_path)\n",
    "\n",
    "    train_data.save_to_disk(f'./models_10fold_dataset_splits/kfold_roberta_base_data/train_test_fold_{fold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "metal-engine",
   "language": "python",
   "name": "metal-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

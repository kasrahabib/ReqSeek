{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uaRTxkZHawrU",
    "outputId": "b9b5fb6e-9a73-404a-a5fe-09ce51e56160",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUGJ4FNObH9C",
    "outputId": "98db096b-a6a7-43e6-e438-2c9c36b82c10",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 134.9 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "qoXjOIb1bWCZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# common imports\n",
    "\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "5afa48832566455881654b7a075050fc",
      "e9212e179e554fde8c4a82965db76bbc",
      "4730c04d352041ee895c3e759cfab5bd",
      "b14748f029f94f2dbb0d0537da857f1a",
      "103d00127cab4f17ae37ae25b35a2d36",
      "d7248dcabb9d4983adf1f9fbc3674a6f",
      "83e5964aa7464c7d91d3a330b969dae2",
      "a81343e882c3491eaac6382b994c2eed",
      "30696bcac17948e8815ca3181ad40f2f",
      "10dc0d75cec74637b745fb58c1552713",
      "ccb41ea913bf45e899053c66b7ddaf22",
      "51c262bef6a64f20af6c91261f4a9735",
      "b8cec805ddbc4f459c047d48ba359699",
      "30e4804b67aa4ed1b8483588ce8908b4",
      "ce9dd753d7b74f90bb321e842cb34e46",
      "0b21cb58e05d4d3b8414fb5273559baf",
      "3f5b0d4a731b4132aaa50f052b88f511",
      "ffe16eb2c2d247998133bd8d6803c91b",
      "8869a162b5aa41febdda3e7a12db5644",
      "d0271c462b6f43a5ba5c278877df3884",
      "e1e662df08e24161bb9c7c36a60ccc38",
      "62918492203b4325959fb17e6a2e2cd4",
      "9b5fe2cb5746472782a687c058b113a8",
      "55427c443afd49f5acb24b319f6cc24c",
      "8e551efd97004794bade4d94776295c6",
      "578370a1a34244829e11c6d43efd7563",
      "df5654ec7533409a9d2bbd71ab0a0ee3",
      "be79000be1bd47cf8f828e6f19b4e10d",
      "70ce6f28b95549549156797845d1af81",
      "8ad882f67b25419f9c1bdba0bddf98ec",
      "2ba5cba8cbf74e02af3b35d68e146abc",
      "0b717fe15142422e8d88f8eb85355eb8"
     ]
    },
    "id": "I2_7Pm2JhWqM",
    "outputId": "817126af-49e6-4f6a-88ce-499db6ec547d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b6703246db483e898587227dd4b922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "t7q96SlFBhil"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_from_disk('./ARID/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mdr0QFwhsKKV",
    "outputId": "df128e24-6edf-4433-da67-1d6cd654afb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label'],\n",
       "        num_rows: 1916\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430,
     "referenced_widgets": [
      "98016132c64b42738a58789a93fd444d",
      "e3b2d90a1e614ac1b3a363ee11ffef46",
      "f20d8637e285496dba5f1d9723c5c357",
      "5c640d5d481f4eec9757acc13b81ca43",
      "b6cd6c1965a04b409a38af281194ca43",
      "b4f4d6b221d74a20889e5ae8b1454742",
      "d64745f382bd48ef80509aa18de5b834",
      "afa55123cccc4f72b3f250dfc5e1ad5b",
      "93ca6ce65b754906bb44a592ae405232",
      "3354614af39e495a957910865e5fb9bc",
      "7e5ba2c25e6142bcbdcbafef90d2a092",
      "6394830521854e08bc52ea2b8b88cce3",
      "c5bbdb72803f442283c72b360b65655d",
      "9eae9d399e91441a9917e5e584eb5683",
      "025bc14bcbe04db8989880c3fc49cefc",
      "865134cd5bad4a4aa4805cb819c79312",
      "5e6b264578b0493192e46c7545b7f6bd",
      "45e456d7ebaa48f691bcc3dca3cc8300",
      "d78a7fabdda7469591360b54c5eaf986",
      "bac8814de4d14ca08af87d45c5b1f02d",
      "6896c761b93e4ce3bfc3cb1aef850be2",
      "2a3dc943d799432bbfd336ebf34e4330",
      "8a4eff533b464c95a7c37e434dd00649",
      "9dc82184850b4486b200b6798eb1ec0b",
      "d8e4cc90080e4bb4bc8988a5913d1510",
      "0a8db38b8133475c93920aeb7b835cc4",
      "03129c33565b4eb1b056be4d36ef2ad0",
      "4e022d85e8d142939c70b67dc1f6e50a",
      "f510cc7f99984b0fa2da61aefb08796c",
      "4c6547ebdcf64e4ab20b864551e7d29c",
      "eaa5364e608040a1988aec2bf953b8df",
      "2635e15a65414b119fcfa1057bc39129",
      "a4741e5d707142968b8bb03f4fa711c9",
      "419134004dc441598ad824fdd757bda0",
      "e11a72de91f8444bbfab4e1635b5ed9e",
      "b410c8c91c544768a5a25a094d50778b",
      "99d5c479f4fe4717be52420dca4f73f6",
      "19a46d1dea19416f948ddecb1c0fc12e",
      "487398b37b2c48ae8e6ee0b17f6b0df7",
      "cc5ffa53c56c41179a21464afdbafbc9",
      "7c345aea455e4348b3fc98300c7ba823",
      "3fe69a1a01064c9c826c650d4e8710da",
      "dd781468aed9428f91a9104af5758eb7",
      "ceb3b62808224b8fa59fa251f5f0e601",
      "aeb60b31f79c4457a2897c6794f3efc9",
      "9b87a4d305454f80ba41186821942850",
      "910baa00963d41f3b2a3e28662b92421",
      "e1851f210e3146eca6d05605808bc9bd",
      "5a50013069cb49dd98ebe3b798fc6144",
      "5eb0043c59a44bd185bf0a40361c1619",
      "cdab6beab178463981d3117eb10c4fa7",
      "625c731746824637b0a05cd8320b4fdc",
      "19f85814e6d64d4aa5028dc991d07f6c",
      "8fce9e8a9e38475787e3245b3bd9dc27",
      "ac93f628231245c19c0916dac34cecc0",
      "f02588e5767d4857b60ee518e1adc695",
      "adc20d9b72f448d0b356c097991130b2",
      "57fa5a83701a406a9a9c8af8ca63943e",
      "200c68bffe4843c094af65ed1e108f8f",
      "feb9154d5ef04b518828adfbb8fc290c",
      "3ef9c606ce9d4590bdfeeaba110d12d2",
      "8ac000106730407eb693f66622e10096",
      "70291fc3c15c4f039e61db6dc4159c40",
      "01a20f6bcff24017966167c503c85b3e",
      "0cf8a623d82f44068a25370099cd9619",
      "36b2efbf7ddb44eeb3f21dae67c09b1a"
     ]
    },
    "id": "UR7Lrk_7bw1W",
    "outputId": "5b767ee7-6b81-4649-b6ab-3a61749f5683"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "lbl_ = dataset['train'].features['label'].names\n",
    "label2id = {lbl: idx for idx, lbl in enumerate(lbl_)}\n",
    "id2label = {val: key for key, val in label2id.items()}\n",
    "id2label\n",
    "\n",
    "model_ckpt = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_ckpt,\n",
    "                                                             num_labels = len(lbl_),\n",
    "                                                             id2label = id2label,\n",
    "                                                             label2id = label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "0YFNjrmBcyoA"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "    return tokenizer(dataset['Requirement Sentences'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "864d301a305e43099803a1bf2f101ada",
      "0ce59739c3a2451798cf03353099f009",
      "9b336d730d1e4855a020cdff862f3e63",
      "d51ffe54a8fd431baaaf7dc1dd6bd2ac",
      "21a293fb9ab54497a09ca7ee132fa10c",
      "5cf9f6d16c9b4c3387e8dcbdf519b710",
      "986af7cb713e4b659d2318064af54869",
      "f51005bfe9fc42acb241bd917500551b",
      "5d96cc739e2c48e29a9bd15414fcc1a1",
      "4c502b382e7e4dfe915195551f1ec921",
      "2e47707aebde422fbb4d58890ea9b777",
      "da91770e50fc4afcbedfc5a52fbd7a78",
      "1b75500d63c94b2fa6986b230f5d3eb4",
      "0ba410460dd641bba17d06b2ecf56074",
      "429015e2d4ce4d4a854afdbc5be2ceeb",
      "6356d3de0fbf4a27a59d204b641045bd",
      "82a96cdb33204da09d159b056c7506a5",
      "02d7319d8b7b4220bb786e0255ed8b78",
      "6d133465efcb49b5b180a92eff4aa4f9",
      "b5534615050b4be4b04ebb3eb9a4560a",
      "5f99d060710049b19ba9803a370dbc3e",
      "3674c268a2164f56b443011fa0671482"
     ]
    },
    "id": "tRT7UwnXdah0",
    "outputId": "cbc17e9e-2a92-4f71-ea36-dec149a8396b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d813d0077634c8a89e3c0548a235b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1916 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab476336caa4c338a148c1eeb8de1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_encoded = dataset.map(preprocess_function, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RC3PDyxfRSR",
    "outputId": "a05d97a1-0e75-4bd8-ca44-0053ee0a0235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DWA must request DWA acknowledgment flashing when the DWA has assumed the \"armed\" state and the outer skin is closed.\n",
      "[101, 1996, 1040, 4213, 2442, 5227, 1040, 4213, 9353, 2243, 19779, 3709, 21693, 4765, 12659, 2043, 1996, 1040, 4213, 2038, 5071, 1996, 1000, 4273, 1000, 2110, 1998, 1996, 6058, 3096, 2003, 2701, 1012, 102]\n",
      "['[CLS]', 'the', 'd', '##wa', 'must', 'request', 'd', '##wa', 'ac', '##k', '##now', '##led', '##gm', '##ent', 'flashing', 'when', 'the', 'd', '##wa', 'has', 'assumed', 'the', '\"', 'armed', '\"', 'state', 'and', 'the', 'outer', 'skin', 'is', 'closed', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_encoded['train']['Requirement Sentences'][0])\n",
    "print(X_train_encoded['train']['input_ids'][0])\n",
    "print(tokenizer.convert_ids_to_tokens(X_train_encoded['train']['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cN4cvC-E6fQu",
    "outputId": "dc14773b-583c-4706-e135-2b286044f00e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1916\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "SnG0qKqFgtGU"
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    X_train_encoded['train'],\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size,\n",
    "    tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "tf_valid_dataset = model.prepare_tf_dataset(\n",
    "    X_train_encoded['test'],\n",
    "    shuffle = False,\n",
    "    batch_size = batch_size,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "OhEjcWQyg5Lv"
   },
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "num_epochs = 30\n",
    "batches_per_epoch = len(X_train_encoded['train']) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr = 2e-5, num_warmup_steps = 0, num_train_steps = total_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "m69JG3BCg7aL"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    metric1 = evaluate.load(\"precision\")\n",
    "    metric2 = evaluate.load(\"recall\")\n",
    "    metric3 = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "    predictions, labels = eval_predictions\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "\n",
    "    precision = metric1.compute(predictions = predictions, references = labels, average = 'macro')[\"precision\"]\n",
    "    recall = metric2.compute(predictions = predictions, references = labels, average = 'macro')[\"recall\"]\n",
    "    f1 = metric3.compute(predictions = predictions, references = labels, average = 'macro')[\"f1\"]\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "metric_callback = KerasMetricCallback(metric_fn = compute_metrics, eval_dataset = tf_valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2TnaIPRhAFq",
    "outputId": "0f7f6596-c678-4460-ab4c-7280cda1880a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "Cloning https://huggingface.co/kasrahabib/all-MiniLM-L6-v2-finetuned-isobased-req-detector_v3 into local empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model_name = model_ckpt.split(\"/\")[-1]\n",
    "print(model_name)\n",
    "push_to_hub_model_id = f'{model_name}-finetuned-iso29148-req-detector'\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./requirement_detector_model_save/logs\")\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir = \"./requirement_detector_model_save\",\n",
    "    tokenizer = tokenizer,\n",
    "    hub_model_id = push_to_hub_model_id,\n",
    ")\n",
    "\n",
    "callbacks = [push_to_hub_callback, tensorboard_callback, metric_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8a0cafdc8b6b4452a3d5b751890fbf70",
      "6e9437eee8604d02ad82e730fddd1261",
      "e12e6367e092428d8f422d54ed8f12a5",
      "ddd12b87963545a4a0a91352e760d2d6",
      "fe5dfe56325b4bd9ad5e7de4ddcaa591",
      "01bcd56182dc45a195faa95a5c8d4563",
      "ea178e1fc62b4c0f93dd6570dc66ec4d",
      "d2adca5fafdf4e198ebe7669f25614a6",
      "8cefa68ad6b34475882d02deb1d7dd95",
      "efe461131dd5490db01740bf7c0a7f13",
      "bfee86796ccb4f3594c226da52daea7d",
      "5d54b86e1ea746418341e3e2c08f433e",
      "63b4c446e21b42aebd216122c62ea178",
      "a314f91f87414c4094dc3897f9cde532",
      "cdfefb83b68349fda516226ae082cc10",
      "387f0c53a2b744eca2bd3335191f50f9",
      "62d8e3df70e344ca94e2bb0ee97378fc",
      "67bbe91f4b22422aa419e0663aa80470",
      "f8e665e9d44f4feb938af4a5de37281d",
      "0cad3b78aaac4267947c8a1adcd67868",
      "ebacdd7671264c50bbcbdf963dd0f800",
      "46f5b63f4d17421f9b7c602df2994c3f",
      "4d08e9451f2d41c984681fd5f4d8b743",
      "899599fc878e4ddfb535cce7b9940182",
      "ce0edf70b781464cbbc29ed3b9b8fa8a",
      "681751c762134a00a3e1da2ed08ceb27",
      "11fd4035396046a9a89f8adce9841581",
      "d0d67ff6264c4a65a2b6dc10c056aa47",
      "9f015e06e52447de95b1ce84b2d1c2af",
      "b6cf2ff97c0748b6b232dcbb962efa68",
      "3fc0dbdec19742e69891d50902731b62",
      "60b6e29b7a6648329f3c327cf7eae043",
      "9df8264671f54c00928c94f3943daa50"
     ]
    },
    "id": "LtlqcfYPhOGL",
    "outputId": "73e00738-713c-4ec6-e418-4a280d6fb5b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "119/119 [==============================] - 35s 202ms/step - loss: 2.7669 - val_loss: 2.5868 - precision: 0.2399 - recall: 0.3095 - f1: 0.2184\n",
      "Epoch 2/30\n",
      "  1/119 [..............................] - ETA: 12s - loss: 2.6834"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 2.2742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 19s 158ms/step - loss: 2.2742 - val_loss: 1.8750 - precision: 0.5127 - recall: 0.5271 - f1: 0.4721\n",
      "Epoch 3/30\n",
      "  1/119 [..............................] - ETA: 16s - loss: 1.8646"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/119 [============================>.] - ETA: 0s - loss: 1.6951"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (3) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 17s 144ms/step - loss: 1.6937 - val_loss: 1.4343 - precision: 0.6401 - recall: 0.5844 - f1: 0.5451\n",
      "Epoch 4/30\n",
      "  5/119 [>.............................] - ETA: 3s - loss: 1.4577"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 1.3318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (4) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 16s 136ms/step - loss: 1.3318 - val_loss: 1.1742 - precision: 0.7592 - recall: 0.6869 - f1: 0.6734\n",
      "Epoch 5/30\n",
      "  1/119 [..............................] - ETA: 11s - loss: 1.4434"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 1.0835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (5) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 16s 133ms/step - loss: 1.0835 - val_loss: 0.9818 - precision: 0.8007 - recall: 0.7427 - f1: 0.7412\n",
      "Epoch 6/30\n",
      "  5/119 [>.............................] - ETA: 3s - loss: 0.8370"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/119 [============================>.] - ETA: 0s - loss: 0.9091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (6) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 16s 133ms/step - loss: 0.9073 - val_loss: 0.8713 - precision: 0.8483 - recall: 0.7595 - f1: 0.7658\n",
      "Epoch 7/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.7707"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (7) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 16s 133ms/step - loss: 0.7707 - val_loss: 0.7725 - precision: 0.8408 - recall: 0.7846 - f1: 0.7914\n",
      "Epoch 8/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.6586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (8) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 131ms/step - loss: 0.6586 - val_loss: 0.6982 - precision: 0.8662 - recall: 0.8074 - f1: 0.8189\n",
      "Epoch 9/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.5697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (9) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 131ms/step - loss: 0.5697 - val_loss: 0.6336 - precision: 0.8743 - recall: 0.8343 - f1: 0.8466\n",
      "Epoch 10/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.4915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (10) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 126ms/step - loss: 0.4915 - val_loss: 0.6005 - precision: 0.8682 - recall: 0.8349 - f1: 0.8458\n",
      "Epoch 11/30\n",
      "118/119 [============================>.] - ETA: 0s - loss: 0.4295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (11) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 130ms/step - loss: 0.4294 - val_loss: 0.5569 - precision: 0.8468 - recall: 0.8290 - f1: 0.8338\n",
      "Epoch 12/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.3730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (12) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 130ms/step - loss: 0.3730 - val_loss: 0.5356 - precision: 0.8754 - recall: 0.8384 - f1: 0.8505\n",
      "Epoch 13/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.3214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (13) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 127ms/step - loss: 0.3214 - val_loss: 0.4918 - precision: 0.8839 - recall: 0.8525 - f1: 0.8635\n",
      "Epoch 14/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.2801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (14) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 128ms/step - loss: 0.2801 - val_loss: 0.4575 - precision: 0.8913 - recall: 0.8641 - f1: 0.8744\n",
      "Epoch 15/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.2496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (15) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 129ms/step - loss: 0.2496 - val_loss: 0.4503 - precision: 0.8849 - recall: 0.8603 - f1: 0.8691\n",
      "Epoch 16/30\n",
      "118/119 [============================>.] - ETA: 0s - loss: 0.2154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (16) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 126ms/step - loss: 0.2151 - val_loss: 0.4572 - precision: 0.8893 - recall: 0.8508 - f1: 0.8628\n",
      "Epoch 17/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (17) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 129ms/step - loss: 0.1918 - val_loss: 0.4230 - precision: 0.8811 - recall: 0.8550 - f1: 0.8645\n",
      "Epoch 18/30\n",
      "118/119 [============================>.] - ETA: 0s - loss: 0.1770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (18) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 127ms/step - loss: 0.1767 - val_loss: 0.4110 - precision: 0.8817 - recall: 0.8665 - f1: 0.8726\n",
      "Epoch 19/30\n",
      "118/119 [============================>.] - ETA: 0s - loss: 0.1605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (19) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 129ms/step - loss: 0.1604 - val_loss: 0.4110 - precision: 0.8740 - recall: 0.8557 - f1: 0.8631\n",
      "Epoch 20/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (20) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 16s 138ms/step - loss: 0.1471 - val_loss: 0.4040 - precision: 0.8753 - recall: 0.8702 - f1: 0.8716\n",
      "Epoch 21/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1380"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (21) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 126ms/step - loss: 0.1380 - val_loss: 0.4070 - precision: 0.8912 - recall: 0.8654 - f1: 0.8749\n",
      "Epoch 22/30\n",
      "118/119 [============================>.] - ETA: 0s - loss: 0.1282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (22) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 130ms/step - loss: 0.1282 - val_loss: 0.3987 - precision: 0.8835 - recall: 0.8622 - f1: 0.8700\n",
      "Epoch 23/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (23) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 128ms/step - loss: 0.1242 - val_loss: 0.4021 - precision: 0.8801 - recall: 0.8635 - f1: 0.8689\n",
      "Epoch 24/30\n",
      "118/119 [============================>.] - ETA: 0s - loss: 0.1189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (24) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 126ms/step - loss: 0.1185 - val_loss: 0.3951 - precision: 0.8807 - recall: 0.8644 - f1: 0.8697\n",
      "Epoch 25/30\n",
      "118/119 [============================>.] - ETA: 0s - loss: 0.1112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (25) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 126ms/step - loss: 0.1108 - val_loss: 0.3915 - precision: 0.8775 - recall: 0.8630 - f1: 0.8678\n",
      "Epoch 26/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (26) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 129ms/step - loss: 0.1058 - val_loss: 0.3937 - precision: 0.8876 - recall: 0.8687 - f1: 0.8756\n",
      "Epoch 27/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (27) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 127ms/step - loss: 0.1037 - val_loss: 0.3988 - precision: 0.8849 - recall: 0.8625 - f1: 0.8709\n",
      "Epoch 28/30\n",
      "118/119 [============================>.] - ETA: 0s - loss: 0.1003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (28) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 128ms/step - loss: 0.1000 - val_loss: 0.3914 - precision: 0.8857 - recall: 0.8656 - f1: 0.8731\n",
      "Epoch 29/30\n",
      "118/119 [============================>.] - ETA: 0s - loss: 0.0994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (29) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 127ms/step - loss: 0.0989 - val_loss: 0.3908 - precision: 0.8857 - recall: 0.8656 - f1: 0.8731\n",
      "Epoch 30/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (30) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 15s 128ms/step - loss: 0.0937 - val_loss: 0.3926 - precision: 0.8832 - recall: 0.8641 - f1: 0.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (31) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "EOF\n",
      "error: failed to push some refs to 'https://huggingface.co/kasrahabib/all-MiniLM-L6-v2-finetuned-isobased-req-detector_v3'\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "EOF\nerror: failed to push some refs to 'https://huggingface.co/kasrahabib/all-MiniLM-L6-v2-finetuned-isobased-req-detector_v3'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m optimizer)\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_valid_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1229\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1228\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/transformers/keras_callbacks.py:413\u001b[0m, in \u001b[0;36mPushToHubCallback.on_train_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    412\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(model_card)\n\u001b[0;32m--> 413\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnd of training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/huggingface_hub/repository.py:1325\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_add(auto_lfs_track\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_commit(commit_message)\n\u001b[0;32m-> 1325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgit_push\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_branch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/huggingface_hub/repository.py:1120\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocking:\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstatus_method\u001b[39m():\n",
      "\u001b[0;31mOSError\u001b[0m: EOF\nerror: failed to push some refs to 'https://huggingface.co/kasrahabib/all-MiniLM-L6-v2-finetuned-isobased-req-detector_v3'\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = optimizer)\n",
    "history = model.fit(tf_train_dataset, validation_data = (tf_valid_dataset), epochs = num_epochs, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6cf3f180c71441fa76f2fc636d3a67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f73febef5743049a6866ff261f4c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715005761.iste.358702.2.v2:   0%|          | 0.00/1.86M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116100668f1c4ad78bc2c470a7d9d92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/91.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46a0a477c5246499df833a6caa20678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715005788.iste.358702.3.v2:   0%|          | 0.00/4.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/kasrahabib/all-MiniLM-L6-v2-finetuned-isobased-req-detector_v3/commit/429fdd3b4de59bc7f4b4eb09aad306db2b187a80', commit_message='Upload folder using huggingface_hub', commit_description='', oid='429fdd3b4de59bc7f4b4eb09aad306db2b187a80', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path = \"./requirement_detector_model_save\",\n",
    "    repo_id = \"kasrahabib/\" + push_to_hub_model_id,\n",
    "    repo_type = \"model\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "metal-engine",
   "language": "python",
   "name": "metal-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
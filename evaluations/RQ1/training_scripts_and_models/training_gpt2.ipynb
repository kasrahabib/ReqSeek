{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUGJ4FNObH9C",
    "outputId": "98db096b-a6a7-43e6-e438-2c9c36b82c10",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 134.9 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qoXjOIb1bWCZ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 17:03:00.649870: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-09 17:03:00.649907: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-09 17:03:00.651209: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-09 17:03:00.657855: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-09 17:03:01.206397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# common imports\n",
    "\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "5afa48832566455881654b7a075050fc",
      "e9212e179e554fde8c4a82965db76bbc",
      "4730c04d352041ee895c3e759cfab5bd",
      "b14748f029f94f2dbb0d0537da857f1a",
      "103d00127cab4f17ae37ae25b35a2d36",
      "d7248dcabb9d4983adf1f9fbc3674a6f",
      "83e5964aa7464c7d91d3a330b969dae2",
      "a81343e882c3491eaac6382b994c2eed",
      "30696bcac17948e8815ca3181ad40f2f",
      "10dc0d75cec74637b745fb58c1552713",
      "ccb41ea913bf45e899053c66b7ddaf22",
      "51c262bef6a64f20af6c91261f4a9735",
      "b8cec805ddbc4f459c047d48ba359699",
      "30e4804b67aa4ed1b8483588ce8908b4",
      "ce9dd753d7b74f90bb321e842cb34e46",
      "0b21cb58e05d4d3b8414fb5273559baf",
      "3f5b0d4a731b4132aaa50f052b88f511",
      "ffe16eb2c2d247998133bd8d6803c91b",
      "8869a162b5aa41febdda3e7a12db5644",
      "d0271c462b6f43a5ba5c278877df3884",
      "e1e662df08e24161bb9c7c36a60ccc38",
      "62918492203b4325959fb17e6a2e2cd4",
      "9b5fe2cb5746472782a687c058b113a8",
      "55427c443afd49f5acb24b319f6cc24c",
      "8e551efd97004794bade4d94776295c6",
      "578370a1a34244829e11c6d43efd7563",
      "df5654ec7533409a9d2bbd71ab0a0ee3",
      "be79000be1bd47cf8f828e6f19b4e10d",
      "70ce6f28b95549549156797845d1af81",
      "8ad882f67b25419f9c1bdba0bddf98ec",
      "2ba5cba8cbf74e02af3b35d68e146abc",
      "0b717fe15142422e8d88f8eb85355eb8"
     ]
    },
    "id": "I2_7Pm2JhWqM",
    "outputId": "817126af-49e6-4f6a-88ce-499db6ec547d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8a05c9255045b5bc82498eb825042e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t7q96SlFBhil"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_from_disk('./ARID/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mdr0QFwhsKKV",
    "outputId": "df128e24-6edf-4433-da67-1d6cd654afb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label'],\n",
       "        num_rows: 1916\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430,
     "referenced_widgets": [
      "98016132c64b42738a58789a93fd444d",
      "e3b2d90a1e614ac1b3a363ee11ffef46",
      "f20d8637e285496dba5f1d9723c5c357",
      "5c640d5d481f4eec9757acc13b81ca43",
      "b6cd6c1965a04b409a38af281194ca43",
      "b4f4d6b221d74a20889e5ae8b1454742",
      "d64745f382bd48ef80509aa18de5b834",
      "afa55123cccc4f72b3f250dfc5e1ad5b",
      "93ca6ce65b754906bb44a592ae405232",
      "3354614af39e495a957910865e5fb9bc",
      "7e5ba2c25e6142bcbdcbafef90d2a092",
      "6394830521854e08bc52ea2b8b88cce3",
      "c5bbdb72803f442283c72b360b65655d",
      "9eae9d399e91441a9917e5e584eb5683",
      "025bc14bcbe04db8989880c3fc49cefc",
      "865134cd5bad4a4aa4805cb819c79312",
      "5e6b264578b0493192e46c7545b7f6bd",
      "45e456d7ebaa48f691bcc3dca3cc8300",
      "d78a7fabdda7469591360b54c5eaf986",
      "bac8814de4d14ca08af87d45c5b1f02d",
      "6896c761b93e4ce3bfc3cb1aef850be2",
      "2a3dc943d799432bbfd336ebf34e4330",
      "8a4eff533b464c95a7c37e434dd00649",
      "9dc82184850b4486b200b6798eb1ec0b",
      "d8e4cc90080e4bb4bc8988a5913d1510",
      "0a8db38b8133475c93920aeb7b835cc4",
      "03129c33565b4eb1b056be4d36ef2ad0",
      "4e022d85e8d142939c70b67dc1f6e50a",
      "f510cc7f99984b0fa2da61aefb08796c",
      "4c6547ebdcf64e4ab20b864551e7d29c",
      "eaa5364e608040a1988aec2bf953b8df",
      "2635e15a65414b119fcfa1057bc39129",
      "a4741e5d707142968b8bb03f4fa711c9",
      "419134004dc441598ad824fdd757bda0",
      "e11a72de91f8444bbfab4e1635b5ed9e",
      "b410c8c91c544768a5a25a094d50778b",
      "99d5c479f4fe4717be52420dca4f73f6",
      "19a46d1dea19416f948ddecb1c0fc12e",
      "487398b37b2c48ae8e6ee0b17f6b0df7",
      "cc5ffa53c56c41179a21464afdbafbc9",
      "7c345aea455e4348b3fc98300c7ba823",
      "3fe69a1a01064c9c826c650d4e8710da",
      "dd781468aed9428f91a9104af5758eb7",
      "ceb3b62808224b8fa59fa251f5f0e601",
      "aeb60b31f79c4457a2897c6794f3efc9",
      "9b87a4d305454f80ba41186821942850",
      "910baa00963d41f3b2a3e28662b92421",
      "e1851f210e3146eca6d05605808bc9bd",
      "5a50013069cb49dd98ebe3b798fc6144",
      "5eb0043c59a44bd185bf0a40361c1619",
      "cdab6beab178463981d3117eb10c4fa7",
      "625c731746824637b0a05cd8320b4fdc",
      "19f85814e6d64d4aa5028dc991d07f6c",
      "8fce9e8a9e38475787e3245b3bd9dc27",
      "ac93f628231245c19c0916dac34cecc0",
      "f02588e5767d4857b60ee518e1adc695",
      "adc20d9b72f448d0b356c097991130b2",
      "57fa5a83701a406a9a9c8af8ca63943e",
      "200c68bffe4843c094af65ed1e108f8f",
      "feb9154d5ef04b518828adfbb8fc290c",
      "3ef9c606ce9d4590bdfeeaba110d12d2",
      "8ac000106730407eb693f66622e10096",
      "70291fc3c15c4f039e61db6dc4159c40",
      "01a20f6bcff24017966167c503c85b3e",
      "0cf8a623d82f44068a25370099cd9619",
      "36b2efbf7ddb44eeb3f21dae67c09b1a"
     ]
    },
    "id": "UR7Lrk_7bw1W",
    "outputId": "5b767ee7-6b81-4649-b6ab-3a61749f5683"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-05-09 17:03:16.403172: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.403439: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.404412: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.404637: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.404854: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.405066: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.537737: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.537997: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.538215: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.538425: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.538634: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.538853: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.562102: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.562372: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.562596: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.562808: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.563038: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.563222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22206 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-05-09 17:03:16.563587: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 17:03:16.563765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22277 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "All PyTorch model weights were used when initializing TFGPT2ForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFGPT2ForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2ForSequenceClassification\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "lbl_ = dataset['train'].features['label'].names\n",
    "label2id = {lbl: idx for idx, lbl in enumerate(lbl_)}\n",
    "id2label = {val: key for key, val in label2id.items()}\n",
    "id2label\n",
    "\n",
    "model_ckpt = 'openai-community/gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "model = TFGPT2ForSequenceClassification.from_pretrained(model_ckpt,\n",
    "                                                        num_labels = len(lbl_),\n",
    "                                                        id2label = id2label,\n",
    "                                                        label2id = label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token ID is not set. Setting now...\n",
      "New Pad Token ID set: 50256\n"
     ]
    }
   ],
   "source": [
    "# important to do as the model itself does not\n",
    "# if not done, error while training\n",
    "if model.config.pad_token_id is None:\n",
    "    print(\"Pad token ID is not set. Setting now...\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    print(\"New Pad Token ID set:\", model.config.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0YFNjrmBcyoA"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "    return tokenizer(dataset['Requirement Sentences'], padding = 'max_length', max_length = 256, truncation = True, return_tensors = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "864d301a305e43099803a1bf2f101ada",
      "0ce59739c3a2451798cf03353099f009",
      "9b336d730d1e4855a020cdff862f3e63",
      "d51ffe54a8fd431baaaf7dc1dd6bd2ac",
      "21a293fb9ab54497a09ca7ee132fa10c",
      "5cf9f6d16c9b4c3387e8dcbdf519b710",
      "986af7cb713e4b659d2318064af54869",
      "f51005bfe9fc42acb241bd917500551b",
      "5d96cc739e2c48e29a9bd15414fcc1a1",
      "4c502b382e7e4dfe915195551f1ec921",
      "2e47707aebde422fbb4d58890ea9b777",
      "da91770e50fc4afcbedfc5a52fbd7a78",
      "1b75500d63c94b2fa6986b230f5d3eb4",
      "0ba410460dd641bba17d06b2ecf56074",
      "429015e2d4ce4d4a854afdbc5be2ceeb",
      "6356d3de0fbf4a27a59d204b641045bd",
      "82a96cdb33204da09d159b056c7506a5",
      "02d7319d8b7b4220bb786e0255ed8b78",
      "6d133465efcb49b5b180a92eff4aa4f9",
      "b5534615050b4be4b04ebb3eb9a4560a",
      "5f99d060710049b19ba9803a370dbc3e",
      "3674c268a2164f56b443011fa0671482"
     ]
    },
    "id": "tRT7UwnXdah0",
    "outputId": "cbc17e9e-2a92-4f71-ea36-dec149a8396b"
   },
   "outputs": [],
   "source": [
    "X_train_encoded = dataset.map(preprocess_function, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RC3PDyxfRSR",
    "outputId": "a05d97a1-0e75-4bd8-ca44-0053ee0a0235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DWA must request DWA acknowledgment flashing when the DWA has assumed the \"armed\" state and the outer skin is closed.\n",
      "[50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 464, 360, 15543, 1276, 2581, 360, 15543, 48182, 25293, 618, 262, 360, 15543, 468, 9672, 262, 366, 12026, 1, 1181, 290, 262, 12076, 4168, 318, 4838, 13]\n",
      "['<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', 'The', 'Ä D', 'WA', 'Ä must', 'Ä request', 'Ä D', 'WA', 'Ä acknowledgment', 'Ä flashing', 'Ä when', 'Ä the', 'Ä D', 'WA', 'Ä has', 'Ä assumed', 'Ä the', 'Ä \"', 'armed', '\"', 'Ä state', 'Ä and', 'Ä the', 'Ä outer', 'Ä skin', 'Ä is', 'Ä closed', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_encoded['train']['Requirement Sentences'][0])\n",
    "print(X_train_encoded['train']['input_ids'][0])\n",
    "print(tokenizer.convert_ids_to_tokens(X_train_encoded['train']['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cN4cvC-E6fQu",
    "outputId": "dc14773b-583c-4706-e135-2b286044f00e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1916\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SnG0qKqFgtGU"
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    X_train_encoded['train'],\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size,\n",
    "    tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "tf_valid_dataset = model.prepare_tf_dataset(\n",
    "    X_train_encoded['test'],\n",
    "    shuffle = False,\n",
    "    batch_size = batch_size,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "OhEjcWQyg5Lv"
   },
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "num_epochs = 30\n",
    "batches_per_epoch = len(X_train_encoded['train']) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr = 2e-5, num_warmup_steps = 0, num_train_steps = total_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "m69JG3BCg7aL"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    metric1 = evaluate.load(\"precision\")\n",
    "    metric2 = evaluate.load(\"recall\")\n",
    "    metric3 = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "    predictions, labels = eval_predictions\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "\n",
    "    precision = metric1.compute(predictions = predictions, references = labels, average = 'macro')[\"precision\"]\n",
    "    recall = metric2.compute(predictions = predictions, references = labels, average = 'macro')[\"recall\"]\n",
    "    f1 = metric3.compute(predictions = predictions, references = labels, average = 'macro')[\"f1\"]\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "metric_callback = KerasMetricCallback(metric_fn = compute_metrics, eval_dataset = tf_valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2TnaIPRhAFq",
    "outputId": "0f7f6596-c678-4460-ab4c-7280cda1880a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/home/kasra/classification/requirement_detector_model_save_2 is already a clone of https://huggingface.co/kasrahabib/gpt2-finetuned-iso29148-req-detector. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2\n"
     ]
    }
   ],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model_name = model_ckpt.split(\"/\")[-1]\n",
    "print(model_name)\n",
    "push_to_hub_model_id = f'{model_name}-finetuned-iso29148-req-detector'\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./requirement_detector_model_save_2/logs\")\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir = \"./requirement_detector_model_save_2\",\n",
    "    tokenizer = tokenizer,\n",
    "    hub_model_id = push_to_hub_model_id,\n",
    ")\n",
    "\n",
    "callbacks = [push_to_hub_callback, tensorboard_callback, metric_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8a0cafdc8b6b4452a3d5b751890fbf70",
      "6e9437eee8604d02ad82e730fddd1261",
      "e12e6367e092428d8f422d54ed8f12a5",
      "ddd12b87963545a4a0a91352e760d2d6",
      "fe5dfe56325b4bd9ad5e7de4ddcaa591",
      "01bcd56182dc45a195faa95a5c8d4563",
      "ea178e1fc62b4c0f93dd6570dc66ec4d",
      "d2adca5fafdf4e198ebe7669f25614a6",
      "8cefa68ad6b34475882d02deb1d7dd95",
      "efe461131dd5490db01740bf7c0a7f13",
      "bfee86796ccb4f3594c226da52daea7d",
      "5d54b86e1ea746418341e3e2c08f433e",
      "63b4c446e21b42aebd216122c62ea178",
      "a314f91f87414c4094dc3897f9cde532",
      "cdfefb83b68349fda516226ae082cc10",
      "387f0c53a2b744eca2bd3335191f50f9",
      "62d8e3df70e344ca94e2bb0ee97378fc",
      "67bbe91f4b22422aa419e0663aa80470",
      "f8e665e9d44f4feb938af4a5de37281d",
      "0cad3b78aaac4267947c8a1adcd67868",
      "ebacdd7671264c50bbcbdf963dd0f800",
      "46f5b63f4d17421f9b7c602df2994c3f",
      "4d08e9451f2d41c984681fd5f4d8b743",
      "899599fc878e4ddfb535cce7b9940182",
      "ce0edf70b781464cbbc29ed3b9b8fa8a",
      "681751c762134a00a3e1da2ed08ceb27",
      "11fd4035396046a9a89f8adce9841581",
      "d0d67ff6264c4a65a2b6dc10c056aa47",
      "9f015e06e52447de95b1ce84b2d1c2af",
      "b6cf2ff97c0748b6b232dcbb962efa68",
      "3fc0dbdec19742e69891d50902731b62",
      "60b6e29b7a6648329f3c327cf7eae043",
      "9df8264671f54c00928c94f3943daa50"
     ]
    },
    "id": "LtlqcfYPhOGL",
    "outputId": "73e00738-713c-4ec6-e418-4a280d6fb5b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 17:03:36.970930: I external/local_xla/xla/service/service.cc:168] XLA service 0x70145b511880 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-09 17:03:36.970960: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-05-09 17:03:36.970966: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-05-09 17:03:36.975908: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-09 17:03:36.990703: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715267017.066167  748698 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 53s 297ms/step - loss: 3.0225 - val_loss: 2.8144 - precision: 0.0263 - recall: 0.0657 - f1: 0.0278\n",
      "Epoch 2/30\n",
      "  1/119 [..............................] - ETA: 13s - loss: 2.7783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 2.7666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 49s 413ms/step - loss: 2.7666 - val_loss: 2.7501 - precision: 0.0740 - recall: 0.1039 - f1: 0.0563\n",
      "Epoch 3/30\n",
      "  1/119 [..............................] - ETA: 13s - loss: 2.7185"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 2.6971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (3) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 48s 409ms/step - loss: 2.6971 - val_loss: 2.6517 - precision: 0.1180 - recall: 0.1095 - f1: 0.0756\n",
      "Epoch 4/30\n",
      "  1/119 [..............................] - ETA: 16s - loss: 2.6976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 2.6218"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (4) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 397ms/step - loss: 2.6218 - val_loss: 2.4804 - precision: 0.1664 - recall: 0.1615 - f1: 0.1192\n",
      "Epoch 5/30\n",
      "  1/119 [..............................] - ETA: 13s - loss: 2.8288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 2.3698"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (5) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 399ms/step - loss: 2.3698 - val_loss: 2.0353 - precision: 0.3138 - recall: 0.2890 - f1: 0.2595\n",
      "Epoch 6/30\n",
      "  1/119 [..............................] - ETA: 13s - loss: 2.2832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 1.8887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (6) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 400ms/step - loss: 1.8887 - val_loss: 1.4317 - precision: 0.6096 - recall: 0.5270 - f1: 0.4886\n",
      "Epoch 7/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 1.1104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (7) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 48s 402ms/step - loss: 1.1104 - val_loss: 0.8991 - precision: 0.7507 - recall: 0.6395 - f1: 0.6443\n",
      "Epoch 8/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.7810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (8) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 397ms/step - loss: 0.7810 - val_loss: 0.8057 - precision: 0.7283 - recall: 0.6790 - f1: 0.6815\n",
      "Epoch 9/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.6463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (9) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 400ms/step - loss: 0.6463 - val_loss: 0.6800 - precision: 0.7842 - recall: 0.7219 - f1: 0.7312\n",
      "Epoch 10/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.5507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (10) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 401ms/step - loss: 0.5507 - val_loss: 0.6747 - precision: 0.7784 - recall: 0.7263 - f1: 0.7414\n",
      "Epoch 11/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.4679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (11) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 48s 403ms/step - loss: 0.4679 - val_loss: 0.6156 - precision: 0.7788 - recall: 0.7624 - f1: 0.7654\n",
      "Epoch 12/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.4313"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (12) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 48s 403ms/step - loss: 0.4313 - val_loss: 0.6102 - precision: 0.8000 - recall: 0.7801 - f1: 0.7815\n",
      "Epoch 13/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.3696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (13) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 400ms/step - loss: 0.3696 - val_loss: 0.5972 - precision: 0.8143 - recall: 0.7900 - f1: 0.7950\n",
      "Epoch 14/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.3365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (14) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 400ms/step - loss: 0.3365 - val_loss: 0.5437 - precision: 0.8330 - recall: 0.8131 - f1: 0.8183\n",
      "Epoch 15/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.2866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (15) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 399ms/step - loss: 0.2866 - val_loss: 0.5637 - precision: 0.8285 - recall: 0.7971 - f1: 0.8071\n",
      "Epoch 16/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.2492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (16) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 401ms/step - loss: 0.2492 - val_loss: 0.5682 - precision: 0.8540 - recall: 0.8202 - f1: 0.8318\n",
      "Epoch 17/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.2392"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (17) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 401ms/step - loss: 0.2392 - val_loss: 0.5496 - precision: 0.8269 - recall: 0.8087 - f1: 0.8135\n",
      "Epoch 18/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.2029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (18) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 401ms/step - loss: 0.2029 - val_loss: 0.6076 - precision: 0.8496 - recall: 0.7997 - f1: 0.8125\n",
      "Epoch 19/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.2062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (19) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 48s 409ms/step - loss: 0.2062 - val_loss: 0.5368 - precision: 0.8557 - recall: 0.8284 - f1: 0.8351\n",
      "Epoch 20/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (20) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 48s 403ms/step - loss: 0.1898 - val_loss: 0.5434 - precision: 0.8444 - recall: 0.8251 - f1: 0.8308\n",
      "Epoch 21/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (21) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 399ms/step - loss: 0.1670 - val_loss: 0.5434 - precision: 0.8455 - recall: 0.8164 - f1: 0.8247\n",
      "Epoch 22/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (22) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 398ms/step - loss: 0.1682 - val_loss: 0.5403 - precision: 0.8668 - recall: 0.8322 - f1: 0.8443\n",
      "Epoch 23/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1650"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (23) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 401ms/step - loss: 0.1650 - val_loss: 0.5830 - precision: 0.8634 - recall: 0.8210 - f1: 0.8336\n",
      "Epoch 24/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (24) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 400ms/step - loss: 0.1326 - val_loss: 0.5400 - precision: 0.8530 - recall: 0.8279 - f1: 0.8362\n",
      "Epoch 25/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (25) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 400ms/step - loss: 0.1366 - val_loss: 0.5497 - precision: 0.8863 - recall: 0.8524 - f1: 0.8629\n",
      "Epoch 26/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (26) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 47s 402ms/step - loss: 0.1148 - val_loss: 0.5432 - precision: 0.8751 - recall: 0.8481 - f1: 0.8565\n",
      "Epoch 27/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1263"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (27) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 48s 403ms/step - loss: 0.1263 - val_loss: 0.5662 - precision: 0.8748 - recall: 0.8320 - f1: 0.8458\n",
      "Epoch 28/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (28) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 48s 402ms/step - loss: 0.1171 - val_loss: 0.5591 - precision: 0.8605 - recall: 0.8295 - f1: 0.8392\n",
      "Epoch 29/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (29) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 48s 404ms/step - loss: 0.1075 - val_loss: 0.5445 - precision: 0.8654 - recall: 0.8379 - f1: 0.8467\n",
      "Epoch 30/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (30) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 48s 404ms/step - loss: 0.1004 - val_loss: 0.5468 - precision: 0.8711 - recall: 0.8437 - f1: 0.8523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (31) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "EOF\n",
      "EOF\n",
      "error: failed to push some refs to 'https://huggingface.co/kasrahabib/gpt2-finetuned-iso29148-req-detector'\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "EOF\nEOF\nerror: failed to push some refs to 'https://huggingface.co/kasrahabib/gpt2-finetuned-iso29148-req-detector'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m optimizer)\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_valid_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1229\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1228\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/transformers/keras_callbacks.py:413\u001b[0m, in \u001b[0;36mPushToHubCallback.on_train_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    412\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(model_card)\n\u001b[0;32m--> 413\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnd of training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/huggingface_hub/repository.py:1325\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_add(auto_lfs_track\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_commit(commit_message)\n\u001b[0;32m-> 1325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgit_push\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_branch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/huggingface_hub/repository.py:1120\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocking:\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstatus_method\u001b[39m():\n",
      "\u001b[0;31mOSError\u001b[0m: EOF\nEOF\nerror: failed to push some refs to 'https://huggingface.co/kasrahabib/gpt2-finetuned-iso29148-req-detector'\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = optimizer)\n",
    "history = model.fit(tf_train_dataset, validation_data = (tf_valid_dataset), epochs = num_epochs, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a93f86b2284256a6289f28c27eba13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715264632.iste.735681.0.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36808bc8ddc4cc1bf2c644b18692f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715264960.iste.740663.1.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed98ef605ac48bf98e5a1bed721e881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715265874.iste.746549.0.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fb2ff028ad45d79e830e75513d9802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715264715.iste.740663.0.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b7334c0e614881aa199b6ca7a602e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 14 LFS files:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f4aab1af57444d85dadb856ae58879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715265195.iste.740663.2.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c3e3c2c19b4044abbc2b67b2106a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715265886.iste.746549.1.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6697adb6188142acad34dfa80449aacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715266154.iste.746549.2.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16444cf776b14950b16a8698317b1b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715266268.iste.746549.3.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886bfb156fb545808d45a2edfbcb09bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715266585.iste.746549.4.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3314c035a24c89afeb75e8ce75da74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715266792.iste.747601.0.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158a8ae50277442ba2037588690a7502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715266929.iste.748139.0.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e5b3b526f94ac3849c435e82b43d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715267006.iste.748518.0.v2:   0%|          | 0.00/2.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2d4fb9489846dc8a8019fda3833c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715267040.iste.748518.1.v2:   0%|          | 0.00/4.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18188ede53b4b58926ab21fbf370a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/kasrahabib/gpt2-finetuned-iso29148-req-detector/commit/338204e8f6d3ecbcbdaa253b06aa089975603342', commit_message='Upload folder using huggingface_hub', commit_description='', oid='338204e8f6d3ecbcbdaa253b06aa089975603342', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path = \"./requirement_detector_model_save_2\",\n",
    "    repo_id = \"kasrahabib/\" + push_to_hub_model_id,\n",
    "    repo_type = \"model\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "metal-engine",
   "language": "python",
   "name": "metal-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
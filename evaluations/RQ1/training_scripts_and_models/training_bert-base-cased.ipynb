{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUGJ4FNObH9C",
    "outputId": "98db096b-a6a7-43e6-e438-2c9c36b82c10",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 134.9 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qoXjOIb1bWCZ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 15:38:44.619931: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-09 15:38:44.619968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-09 15:38:44.621251: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-09 15:38:44.627699: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-09 15:38:45.177936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# common imports\n",
    "\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "5afa48832566455881654b7a075050fc",
      "e9212e179e554fde8c4a82965db76bbc",
      "4730c04d352041ee895c3e759cfab5bd",
      "b14748f029f94f2dbb0d0537da857f1a",
      "103d00127cab4f17ae37ae25b35a2d36",
      "d7248dcabb9d4983adf1f9fbc3674a6f",
      "83e5964aa7464c7d91d3a330b969dae2",
      "a81343e882c3491eaac6382b994c2eed",
      "30696bcac17948e8815ca3181ad40f2f",
      "10dc0d75cec74637b745fb58c1552713",
      "ccb41ea913bf45e899053c66b7ddaf22",
      "51c262bef6a64f20af6c91261f4a9735",
      "b8cec805ddbc4f459c047d48ba359699",
      "30e4804b67aa4ed1b8483588ce8908b4",
      "ce9dd753d7b74f90bb321e842cb34e46",
      "0b21cb58e05d4d3b8414fb5273559baf",
      "3f5b0d4a731b4132aaa50f052b88f511",
      "ffe16eb2c2d247998133bd8d6803c91b",
      "8869a162b5aa41febdda3e7a12db5644",
      "d0271c462b6f43a5ba5c278877df3884",
      "e1e662df08e24161bb9c7c36a60ccc38",
      "62918492203b4325959fb17e6a2e2cd4",
      "9b5fe2cb5746472782a687c058b113a8",
      "55427c443afd49f5acb24b319f6cc24c",
      "8e551efd97004794bade4d94776295c6",
      "578370a1a34244829e11c6d43efd7563",
      "df5654ec7533409a9d2bbd71ab0a0ee3",
      "be79000be1bd47cf8f828e6f19b4e10d",
      "70ce6f28b95549549156797845d1af81",
      "8ad882f67b25419f9c1bdba0bddf98ec",
      "2ba5cba8cbf74e02af3b35d68e146abc",
      "0b717fe15142422e8d88f8eb85355eb8"
     ]
    },
    "id": "I2_7Pm2JhWqM",
    "outputId": "817126af-49e6-4f6a-88ce-499db6ec547d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525c0ca8181944619b659c4b1320556b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "t7q96SlFBhil"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "\n",
    "dataset = datasets.load_from_disk('./ARID/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mdr0QFwhsKKV",
    "outputId": "df128e24-6edf-4433-da67-1d6cd654afb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label'],\n",
       "        num_rows: 1916\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430,
     "referenced_widgets": [
      "98016132c64b42738a58789a93fd444d",
      "e3b2d90a1e614ac1b3a363ee11ffef46",
      "f20d8637e285496dba5f1d9723c5c357",
      "5c640d5d481f4eec9757acc13b81ca43",
      "b6cd6c1965a04b409a38af281194ca43",
      "b4f4d6b221d74a20889e5ae8b1454742",
      "d64745f382bd48ef80509aa18de5b834",
      "afa55123cccc4f72b3f250dfc5e1ad5b",
      "93ca6ce65b754906bb44a592ae405232",
      "3354614af39e495a957910865e5fb9bc",
      "7e5ba2c25e6142bcbdcbafef90d2a092",
      "6394830521854e08bc52ea2b8b88cce3",
      "c5bbdb72803f442283c72b360b65655d",
      "9eae9d399e91441a9917e5e584eb5683",
      "025bc14bcbe04db8989880c3fc49cefc",
      "865134cd5bad4a4aa4805cb819c79312",
      "5e6b264578b0493192e46c7545b7f6bd",
      "45e456d7ebaa48f691bcc3dca3cc8300",
      "d78a7fabdda7469591360b54c5eaf986",
      "bac8814de4d14ca08af87d45c5b1f02d",
      "6896c761b93e4ce3bfc3cb1aef850be2",
      "2a3dc943d799432bbfd336ebf34e4330",
      "8a4eff533b464c95a7c37e434dd00649",
      "9dc82184850b4486b200b6798eb1ec0b",
      "d8e4cc90080e4bb4bc8988a5913d1510",
      "0a8db38b8133475c93920aeb7b835cc4",
      "03129c33565b4eb1b056be4d36ef2ad0",
      "4e022d85e8d142939c70b67dc1f6e50a",
      "f510cc7f99984b0fa2da61aefb08796c",
      "4c6547ebdcf64e4ab20b864551e7d29c",
      "eaa5364e608040a1988aec2bf953b8df",
      "2635e15a65414b119fcfa1057bc39129",
      "a4741e5d707142968b8bb03f4fa711c9",
      "419134004dc441598ad824fdd757bda0",
      "e11a72de91f8444bbfab4e1635b5ed9e",
      "b410c8c91c544768a5a25a094d50778b",
      "99d5c479f4fe4717be52420dca4f73f6",
      "19a46d1dea19416f948ddecb1c0fc12e",
      "487398b37b2c48ae8e6ee0b17f6b0df7",
      "cc5ffa53c56c41179a21464afdbafbc9",
      "7c345aea455e4348b3fc98300c7ba823",
      "3fe69a1a01064c9c826c650d4e8710da",
      "dd781468aed9428f91a9104af5758eb7",
      "ceb3b62808224b8fa59fa251f5f0e601",
      "aeb60b31f79c4457a2897c6794f3efc9",
      "9b87a4d305454f80ba41186821942850",
      "910baa00963d41f3b2a3e28662b92421",
      "e1851f210e3146eca6d05605808bc9bd",
      "5a50013069cb49dd98ebe3b798fc6144",
      "5eb0043c59a44bd185bf0a40361c1619",
      "cdab6beab178463981d3117eb10c4fa7",
      "625c731746824637b0a05cd8320b4fdc",
      "19f85814e6d64d4aa5028dc991d07f6c",
      "8fce9e8a9e38475787e3245b3bd9dc27",
      "ac93f628231245c19c0916dac34cecc0",
      "f02588e5767d4857b60ee518e1adc695",
      "adc20d9b72f448d0b356c097991130b2",
      "57fa5a83701a406a9a9c8af8ca63943e",
      "200c68bffe4843c094af65ed1e108f8f",
      "feb9154d5ef04b518828adfbb8fc290c",
      "3ef9c606ce9d4590bdfeeaba110d12d2",
      "8ac000106730407eb693f66622e10096",
      "70291fc3c15c4f039e61db6dc4159c40",
      "01a20f6bcff24017966167c503c85b3e",
      "0cf8a623d82f44068a25370099cd9619",
      "36b2efbf7ddb44eeb3f21dae67c09b1a"
     ]
    },
    "id": "UR7Lrk_7bw1W",
    "outputId": "5b767ee7-6b81-4649-b6ab-3a61749f5683"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be9540199c246dcac5c584d4eb99638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d46ece230c4ac7b72ce0f511f135fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93d948d4c124488a9d1788c26428431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde8f61713094dbcbd59651420e48d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c520760f644c4da325ccf8b1cb4e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 15:39:12.357385: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.357649: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.358607: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.358838: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.359052: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.359263: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.498689: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.498953: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.499173: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.499386: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.499596: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.499804: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.522989: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.523261: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.523483: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.523696: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.523917: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.524099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22206 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-05-09 15:39:12.524450: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:39:12.524625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22277 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "lbl_ = dataset['train'].features['label'].names\n",
    "label2id = {lbl: idx for idx, lbl in enumerate(lbl_)}\n",
    "id2label = {val: key for key, val in label2id.items()}\n",
    "id2label\n",
    "\n",
    "model_ckpt = 'google-bert/bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_ckpt,\n",
    "                                                             num_labels = len(lbl_),\n",
    "                                                             id2label = id2label,\n",
    "                                                             label2id = label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0YFNjrmBcyoA"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "    return tokenizer(dataset['Requirement Sentences'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "864d301a305e43099803a1bf2f101ada",
      "0ce59739c3a2451798cf03353099f009",
      "9b336d730d1e4855a020cdff862f3e63",
      "d51ffe54a8fd431baaaf7dc1dd6bd2ac",
      "21a293fb9ab54497a09ca7ee132fa10c",
      "5cf9f6d16c9b4c3387e8dcbdf519b710",
      "986af7cb713e4b659d2318064af54869",
      "f51005bfe9fc42acb241bd917500551b",
      "5d96cc739e2c48e29a9bd15414fcc1a1",
      "4c502b382e7e4dfe915195551f1ec921",
      "2e47707aebde422fbb4d58890ea9b777",
      "da91770e50fc4afcbedfc5a52fbd7a78",
      "1b75500d63c94b2fa6986b230f5d3eb4",
      "0ba410460dd641bba17d06b2ecf56074",
      "429015e2d4ce4d4a854afdbc5be2ceeb",
      "6356d3de0fbf4a27a59d204b641045bd",
      "82a96cdb33204da09d159b056c7506a5",
      "02d7319d8b7b4220bb786e0255ed8b78",
      "6d133465efcb49b5b180a92eff4aa4f9",
      "b5534615050b4be4b04ebb3eb9a4560a",
      "5f99d060710049b19ba9803a370dbc3e",
      "3674c268a2164f56b443011fa0671482"
     ]
    },
    "id": "tRT7UwnXdah0",
    "outputId": "cbc17e9e-2a92-4f71-ea36-dec149a8396b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012ad3b7029c4cfcb54007c1620a9151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1916 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c9101446714837b58ba3fa48d77f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_encoded = dataset.map(preprocess_function, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RC3PDyxfRSR",
    "outputId": "a05d97a1-0e75-4bd8-ca44-0053ee0a0235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DWA must request DWA acknowledgment flashing when the DWA has assumed the \"armed\" state and the outer skin is closed.\n",
      "[101, 1109, 141, 11840, 1538, 4566, 141, 11840, 170, 2158, 2728, 10481, 1174, 14294, 13294, 1165, 1103, 141, 11840, 1144, 4260, 1103, 107, 4223, 107, 1352, 1105, 1103, 6144, 2241, 1110, 1804, 119, 102]\n",
      "['[CLS]', 'The', 'D', '##WA', 'must', 'request', 'D', '##WA', 'a', '##ck', '##no', '##wl', '##ed', '##gment', 'flashing', 'when', 'the', 'D', '##WA', 'has', 'assumed', 'the', '\"', 'armed', '\"', 'state', 'and', 'the', 'outer', 'skin', 'is', 'closed', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_encoded['train']['Requirement Sentences'][0])\n",
    "print(X_train_encoded['train']['input_ids'][0])\n",
    "print(tokenizer.convert_ids_to_tokens(X_train_encoded['train']['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cN4cvC-E6fQu",
    "outputId": "dc14773b-583c-4706-e135-2b286044f00e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1916\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SnG0qKqFgtGU"
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    X_train_encoded['train'],\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size,\n",
    "    tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "tf_valid_dataset = model.prepare_tf_dataset(\n",
    "    X_train_encoded['test'],\n",
    "    shuffle = False,\n",
    "    batch_size = batch_size,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OhEjcWQyg5Lv"
   },
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "num_epochs = 30\n",
    "batches_per_epoch = len(X_train_encoded['train']) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr = 2e-5, num_warmup_steps = 0, num_train_steps = total_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "m69JG3BCg7aL"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    metric1 = evaluate.load(\"precision\")\n",
    "    metric2 = evaluate.load(\"recall\")\n",
    "    metric3 = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "    predictions, labels = eval_predictions\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "\n",
    "    precision = metric1.compute(predictions = predictions, references = labels, average = 'macro')[\"precision\"]\n",
    "    recall = metric2.compute(predictions = predictions, references = labels, average = 'macro')[\"recall\"]\n",
    "    f1 = metric3.compute(predictions = predictions, references = labels, average = 'macro')[\"f1\"]\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "metric_callback = KerasMetricCallback(metric_fn = compute_metrics, eval_dataset = tf_valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2TnaIPRhAFq",
    "outputId": "0f7f6596-c678-4460-ab4c-7280cda1880a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "Cloning https://huggingface.co/kasrahabib/bert-base-cased-finetuned-iso29148-req-detector into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model_name = model_ckpt.split(\"/\")[-1]\n",
    "print(model_name)\n",
    "push_to_hub_model_id = f'{model_name}-finetuned-iso29148-req-detector'\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./requirement_detector_model_save/logs\")\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir = \"./requirement_detector_model_save\",\n",
    "    tokenizer = tokenizer,\n",
    "    hub_model_id = push_to_hub_model_id,\n",
    ")\n",
    "\n",
    "callbacks = [push_to_hub_callback, tensorboard_callback, metric_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8a0cafdc8b6b4452a3d5b751890fbf70",
      "6e9437eee8604d02ad82e730fddd1261",
      "e12e6367e092428d8f422d54ed8f12a5",
      "ddd12b87963545a4a0a91352e760d2d6",
      "fe5dfe56325b4bd9ad5e7de4ddcaa591",
      "01bcd56182dc45a195faa95a5c8d4563",
      "ea178e1fc62b4c0f93dd6570dc66ec4d",
      "d2adca5fafdf4e198ebe7669f25614a6",
      "8cefa68ad6b34475882d02deb1d7dd95",
      "efe461131dd5490db01740bf7c0a7f13",
      "bfee86796ccb4f3594c226da52daea7d",
      "5d54b86e1ea746418341e3e2c08f433e",
      "63b4c446e21b42aebd216122c62ea178",
      "a314f91f87414c4094dc3897f9cde532",
      "cdfefb83b68349fda516226ae082cc10",
      "387f0c53a2b744eca2bd3335191f50f9",
      "62d8e3df70e344ca94e2bb0ee97378fc",
      "67bbe91f4b22422aa419e0663aa80470",
      "f8e665e9d44f4feb938af4a5de37281d",
      "0cad3b78aaac4267947c8a1adcd67868",
      "ebacdd7671264c50bbcbdf963dd0f800",
      "46f5b63f4d17421f9b7c602df2994c3f",
      "4d08e9451f2d41c984681fd5f4d8b743",
      "899599fc878e4ddfb535cce7b9940182",
      "ce0edf70b781464cbbc29ed3b9b8fa8a",
      "681751c762134a00a3e1da2ed08ceb27",
      "11fd4035396046a9a89f8adce9841581",
      "d0d67ff6264c4a65a2b6dc10c056aa47",
      "9f015e06e52447de95b1ce84b2d1c2af",
      "b6cf2ff97c0748b6b232dcbb962efa68",
      "3fc0dbdec19742e69891d50902731b62",
      "60b6e29b7a6648329f3c327cf7eae043",
      "9df8264671f54c00928c94f3943daa50"
     ]
    },
    "id": "LtlqcfYPhOGL",
    "outputId": "73e00738-713c-4ec6-e418-4a280d6fb5b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 15:39:50.894863: I external/local_xla/xla/service/service.cc:168] XLA service 0x74d5fb4d4fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-09 15:39:50.894892: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-05-09 15:39:50.894902: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-05-09 15:39:50.906600: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-09 15:39:50.938318: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715261991.015275  613061 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 62s 315ms/step - loss: 2.4480 - val_loss: 1.6442 - precision: 0.3951 - recall: 0.4170 - f1: 0.3312\n",
      "Epoch 2/30\n",
      "  1/119 [..............................] - ETA: 12s - loss: 1.4730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 1.3378"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 375ms/step - loss: 1.3378 - val_loss: 0.9792 - precision: 0.7736 - recall: 0.6747 - f1: 0.6784\n",
      "Epoch 3/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.8492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (3) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 43s 363ms/step - loss: 0.8492 - val_loss: 0.7320 - precision: 0.8168 - recall: 0.7476 - f1: 0.7601\n",
      "Epoch 4/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.5922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (4) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 358ms/step - loss: 0.5922 - val_loss: 0.6017 - precision: 0.8483 - recall: 0.7772 - f1: 0.7931\n",
      "Epoch 5/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.4316"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (5) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 359ms/step - loss: 0.4316 - val_loss: 0.5206 - precision: 0.8470 - recall: 0.8192 - f1: 0.8278\n",
      "Epoch 6/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.3071"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (6) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 360ms/step - loss: 0.3071 - val_loss: 0.5053 - precision: 0.8245 - recall: 0.7993 - f1: 0.8061\n",
      "Epoch 7/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.2353"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (7) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 353ms/step - loss: 0.2353 - val_loss: 0.5071 - precision: 0.8378 - recall: 0.8050 - f1: 0.8149\n",
      "Epoch 8/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (8) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 350ms/step - loss: 0.1666 - val_loss: 0.4643 - precision: 0.8666 - recall: 0.8324 - f1: 0.8427\n",
      "Epoch 9/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (9) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 355ms/step - loss: 0.1324 - val_loss: 0.4386 - precision: 0.8513 - recall: 0.8424 - f1: 0.8449\n",
      "Epoch 10/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1098"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (10) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 41s 345ms/step - loss: 0.1098 - val_loss: 0.4460 - precision: 0.8517 - recall: 0.8367 - f1: 0.8426\n",
      "Epoch 11/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (11) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 41s 349ms/step - loss: 0.0923 - val_loss: 0.4525 - precision: 0.8419 - recall: 0.8415 - f1: 0.8400\n",
      "Epoch 12/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0808"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (12) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 41s 350ms/step - loss: 0.0808 - val_loss: 0.4382 - precision: 0.8581 - recall: 0.8487 - f1: 0.8527\n",
      "Epoch 13/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (13) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 41s 349ms/step - loss: 0.0676 - val_loss: 0.4699 - precision: 0.8562 - recall: 0.8340 - f1: 0.8426\n",
      "Epoch 14/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0581"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (14) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 354ms/step - loss: 0.0581 - val_loss: 0.4628 - precision: 0.8509 - recall: 0.8377 - f1: 0.8410\n",
      "Epoch 15/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (15) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 41s 347ms/step - loss: 0.0627 - val_loss: 0.4889 - precision: 0.8308 - recall: 0.8207 - f1: 0.8216\n",
      "Epoch 16/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (16) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 41s 350ms/step - loss: 0.0534 - val_loss: 0.4837 - precision: 0.8405 - recall: 0.8279 - f1: 0.8320\n",
      "Epoch 17/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0482"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (17) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 353ms/step - loss: 0.0482 - val_loss: 0.4609 - precision: 0.8446 - recall: 0.8322 - f1: 0.8370\n",
      "Epoch 18/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (18) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 352ms/step - loss: 0.0459 - val_loss: 0.4586 - precision: 0.8514 - recall: 0.8456 - f1: 0.8472\n",
      "Epoch 19/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (19) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 352ms/step - loss: 0.0474 - val_loss: 0.4725 - precision: 0.8408 - recall: 0.8428 - f1: 0.8398\n",
      "Epoch 20/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0419"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (20) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 41s 347ms/step - loss: 0.0419 - val_loss: 0.4758 - precision: 0.8532 - recall: 0.8373 - f1: 0.8429\n",
      "Epoch 21/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (21) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 354ms/step - loss: 0.0391 - val_loss: 0.4964 - precision: 0.8349 - recall: 0.8360 - f1: 0.8336\n",
      "Epoch 22/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (22) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 353ms/step - loss: 0.0387 - val_loss: 0.4799 - precision: 0.8591 - recall: 0.8442 - f1: 0.8499\n",
      "Epoch 23/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (23) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 41s 348ms/step - loss: 0.0375 - val_loss: 0.4705 - precision: 0.8591 - recall: 0.8514 - f1: 0.8545\n",
      "Epoch 24/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0347"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (24) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 353ms/step - loss: 0.0347 - val_loss: 0.4780 - precision: 0.8529 - recall: 0.8416 - f1: 0.8464\n",
      "Epoch 25/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (25) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 351ms/step - loss: 0.0349 - val_loss: 0.4844 - precision: 0.8522 - recall: 0.8408 - f1: 0.8452\n",
      "Epoch 26/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (26) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 352ms/step - loss: 0.0335 - val_loss: 0.4862 - precision: 0.8477 - recall: 0.8375 - f1: 0.8417\n",
      "Epoch 27/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (27) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 41s 347ms/step - loss: 0.0308 - val_loss: 0.4862 - precision: 0.8554 - recall: 0.8430 - f1: 0.8482\n",
      "Epoch 28/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (28) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 354ms/step - loss: 0.0291 - val_loss: 0.4903 - precision: 0.8554 - recall: 0.8430 - f1: 0.8482\n",
      "Epoch 29/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (29) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 353ms/step - loss: 0.0293 - val_loss: 0.4886 - precision: 0.8571 - recall: 0.8461 - f1: 0.8507\n",
      "Epoch 30/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (30) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 42s 352ms/step - loss: 0.0299 - val_loss: 0.4860 - precision: 0.8571 - recall: 0.8461 - f1: 0.8507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (31) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "EOF\n",
      "error: failed to push some refs to 'https://huggingface.co/kasrahabib/bert-base-cased-finetuned-iso29148-req-detector'\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "EOF\nerror: failed to push some refs to 'https://huggingface.co/kasrahabib/bert-base-cased-finetuned-iso29148-req-detector'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m optimizer)\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_valid_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1229\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1228\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/transformers/keras_callbacks.py:413\u001b[0m, in \u001b[0;36mPushToHubCallback.on_train_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    412\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(model_card)\n\u001b[0;32m--> 413\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnd of training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/huggingface_hub/repository.py:1325\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_add(auto_lfs_track\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_commit(commit_message)\n\u001b[0;32m-> 1325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgit_push\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_branch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/huggingface_hub/repository.py:1120\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocking:\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstatus_method\u001b[39m():\n",
      "\u001b[0;31mOSError\u001b[0m: EOF\nerror: failed to push some refs to 'https://huggingface.co/kasrahabib/bert-base-cased-finetuned-iso29148-req-detector'\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = optimizer)\n",
    "history = model.fit(tf_train_dataset, validation_data = (tf_valid_dataset), epochs = num_epochs, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd7f3be20ef4a1eb2eb8ef602f8266a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/434M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452283abcaa743f681a00037bd3ea8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922d2299f6444e6d925de9c16c326050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715261975.iste.612877.0.v2:   0%|          | 0.00/3.53M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f77524414b412781b63fe1db907676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715262022.iste.612877.1.v2:   0%|          | 0.00/4.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/kasrahabib/bert-base-cased-finetuned-iso29148-req-detector/commit/03e4485e5bbed8c6d45e23d28e5e08ba80a3e882', commit_message='Upload folder using huggingface_hub', commit_description='', oid='03e4485e5bbed8c6d45e23d28e5e08ba80a3e882', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path = \"./requirement_detector_model_save\",\n",
    "    repo_id = \"kasrahabib/\" + push_to_hub_model_id,\n",
    "    repo_type = \"model\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "metal-engine",
   "language": "python",
   "name": "metal-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
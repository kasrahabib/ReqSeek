{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUGJ4FNObH9C",
    "outputId": "98db096b-a6a7-43e6-e438-2c9c36b82c10",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 134.9 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qoXjOIb1bWCZ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 19:10:39.361729: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-09 19:10:39.361768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-09 19:10:39.363050: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-09 19:10:39.369351: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-09 19:10:39.914032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# common imports\n",
    "\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "5afa48832566455881654b7a075050fc",
      "e9212e179e554fde8c4a82965db76bbc",
      "4730c04d352041ee895c3e759cfab5bd",
      "b14748f029f94f2dbb0d0537da857f1a",
      "103d00127cab4f17ae37ae25b35a2d36",
      "d7248dcabb9d4983adf1f9fbc3674a6f",
      "83e5964aa7464c7d91d3a330b969dae2",
      "a81343e882c3491eaac6382b994c2eed",
      "30696bcac17948e8815ca3181ad40f2f",
      "10dc0d75cec74637b745fb58c1552713",
      "ccb41ea913bf45e899053c66b7ddaf22",
      "51c262bef6a64f20af6c91261f4a9735",
      "b8cec805ddbc4f459c047d48ba359699",
      "30e4804b67aa4ed1b8483588ce8908b4",
      "ce9dd753d7b74f90bb321e842cb34e46",
      "0b21cb58e05d4d3b8414fb5273559baf",
      "3f5b0d4a731b4132aaa50f052b88f511",
      "ffe16eb2c2d247998133bd8d6803c91b",
      "8869a162b5aa41febdda3e7a12db5644",
      "d0271c462b6f43a5ba5c278877df3884",
      "e1e662df08e24161bb9c7c36a60ccc38",
      "62918492203b4325959fb17e6a2e2cd4",
      "9b5fe2cb5746472782a687c058b113a8",
      "55427c443afd49f5acb24b319f6cc24c",
      "8e551efd97004794bade4d94776295c6",
      "578370a1a34244829e11c6d43efd7563",
      "df5654ec7533409a9d2bbd71ab0a0ee3",
      "be79000be1bd47cf8f828e6f19b4e10d",
      "70ce6f28b95549549156797845d1af81",
      "8ad882f67b25419f9c1bdba0bddf98ec",
      "2ba5cba8cbf74e02af3b35d68e146abc",
      "0b717fe15142422e8d88f8eb85355eb8"
     ]
    },
    "id": "I2_7Pm2JhWqM",
    "outputId": "817126af-49e6-4f6a-88ce-499db6ec547d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60d027efd274f739cb84cb2b0279ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "t7q96SlFBhil"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_from_disk('../../datasets/ARID_supporting_scripts/5_1_training_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mdr0QFwhsKKV",
    "outputId": "df128e24-6edf-4433-da67-1d6cd654afb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label'],\n",
       "        num_rows: 1916\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430,
     "referenced_widgets": [
      "98016132c64b42738a58789a93fd444d",
      "e3b2d90a1e614ac1b3a363ee11ffef46",
      "f20d8637e285496dba5f1d9723c5c357",
      "5c640d5d481f4eec9757acc13b81ca43",
      "b6cd6c1965a04b409a38af281194ca43",
      "b4f4d6b221d74a20889e5ae8b1454742",
      "d64745f382bd48ef80509aa18de5b834",
      "afa55123cccc4f72b3f250dfc5e1ad5b",
      "93ca6ce65b754906bb44a592ae405232",
      "3354614af39e495a957910865e5fb9bc",
      "7e5ba2c25e6142bcbdcbafef90d2a092",
      "6394830521854e08bc52ea2b8b88cce3",
      "c5bbdb72803f442283c72b360b65655d",
      "9eae9d399e91441a9917e5e584eb5683",
      "025bc14bcbe04db8989880c3fc49cefc",
      "865134cd5bad4a4aa4805cb819c79312",
      "5e6b264578b0493192e46c7545b7f6bd",
      "45e456d7ebaa48f691bcc3dca3cc8300",
      "d78a7fabdda7469591360b54c5eaf986",
      "bac8814de4d14ca08af87d45c5b1f02d",
      "6896c761b93e4ce3bfc3cb1aef850be2",
      "2a3dc943d799432bbfd336ebf34e4330",
      "8a4eff533b464c95a7c37e434dd00649",
      "9dc82184850b4486b200b6798eb1ec0b",
      "d8e4cc90080e4bb4bc8988a5913d1510",
      "0a8db38b8133475c93920aeb7b835cc4",
      "03129c33565b4eb1b056be4d36ef2ad0",
      "4e022d85e8d142939c70b67dc1f6e50a",
      "f510cc7f99984b0fa2da61aefb08796c",
      "4c6547ebdcf64e4ab20b864551e7d29c",
      "eaa5364e608040a1988aec2bf953b8df",
      "2635e15a65414b119fcfa1057bc39129",
      "a4741e5d707142968b8bb03f4fa711c9",
      "419134004dc441598ad824fdd757bda0",
      "e11a72de91f8444bbfab4e1635b5ed9e",
      "b410c8c91c544768a5a25a094d50778b",
      "99d5c479f4fe4717be52420dca4f73f6",
      "19a46d1dea19416f948ddecb1c0fc12e",
      "487398b37b2c48ae8e6ee0b17f6b0df7",
      "cc5ffa53c56c41179a21464afdbafbc9",
      "7c345aea455e4348b3fc98300c7ba823",
      "3fe69a1a01064c9c826c650d4e8710da",
      "dd781468aed9428f91a9104af5758eb7",
      "ceb3b62808224b8fa59fa251f5f0e601",
      "aeb60b31f79c4457a2897c6794f3efc9",
      "9b87a4d305454f80ba41186821942850",
      "910baa00963d41f3b2a3e28662b92421",
      "e1851f210e3146eca6d05605808bc9bd",
      "5a50013069cb49dd98ebe3b798fc6144",
      "5eb0043c59a44bd185bf0a40361c1619",
      "cdab6beab178463981d3117eb10c4fa7",
      "625c731746824637b0a05cd8320b4fdc",
      "19f85814e6d64d4aa5028dc991d07f6c",
      "8fce9e8a9e38475787e3245b3bd9dc27",
      "ac93f628231245c19c0916dac34cecc0",
      "f02588e5767d4857b60ee518e1adc695",
      "adc20d9b72f448d0b356c097991130b2",
      "57fa5a83701a406a9a9c8af8ca63943e",
      "200c68bffe4843c094af65ed1e108f8f",
      "feb9154d5ef04b518828adfbb8fc290c",
      "3ef9c606ce9d4590bdfeeaba110d12d2",
      "8ac000106730407eb693f66622e10096",
      "70291fc3c15c4f039e61db6dc4159c40",
      "01a20f6bcff24017966167c503c85b3e",
      "0cf8a623d82f44068a25370099cd9619",
      "36b2efbf7ddb44eeb3f21dae67c09b1a"
     ]
    },
    "id": "UR7Lrk_7bw1W",
    "outputId": "5b767ee7-6b81-4649-b6ab-3a61749f5683"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-05-09 19:10:55.542756: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.543030: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.543981: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.544205: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.544417: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.544628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.699048: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.699303: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.699524: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.699732: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.699939: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.700146: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.723402: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.723673: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.723894: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.724106: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.724326: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.724513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22206 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-05-09 19:10:55.724874: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 19:10:55.725049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22277 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "lbl_ = dataset['train'].features['label'].names\n",
    "label2id = {lbl: idx for idx, lbl in enumerate(lbl_)}\n",
    "id2label = {val: key for key, val in label2id.items()}\n",
    "id2label\n",
    "\n",
    "model_ckpt = 'FacebookAI/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_ckpt,\n",
    "                                                        num_labels = len(lbl_),\n",
    "                                                        id2label = id2label,\n",
    "                                                        label2id = label2id,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0YFNjrmBcyoA"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "    return tokenizer(dataset['Requirement Sentences'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "864d301a305e43099803a1bf2f101ada",
      "0ce59739c3a2451798cf03353099f009",
      "9b336d730d1e4855a020cdff862f3e63",
      "d51ffe54a8fd431baaaf7dc1dd6bd2ac",
      "21a293fb9ab54497a09ca7ee132fa10c",
      "5cf9f6d16c9b4c3387e8dcbdf519b710",
      "986af7cb713e4b659d2318064af54869",
      "f51005bfe9fc42acb241bd917500551b",
      "5d96cc739e2c48e29a9bd15414fcc1a1",
      "4c502b382e7e4dfe915195551f1ec921",
      "2e47707aebde422fbb4d58890ea9b777",
      "da91770e50fc4afcbedfc5a52fbd7a78",
      "1b75500d63c94b2fa6986b230f5d3eb4",
      "0ba410460dd641bba17d06b2ecf56074",
      "429015e2d4ce4d4a854afdbc5be2ceeb",
      "6356d3de0fbf4a27a59d204b641045bd",
      "82a96cdb33204da09d159b056c7506a5",
      "02d7319d8b7b4220bb786e0255ed8b78",
      "6d133465efcb49b5b180a92eff4aa4f9",
      "b5534615050b4be4b04ebb3eb9a4560a",
      "5f99d060710049b19ba9803a370dbc3e",
      "3674c268a2164f56b443011fa0671482"
     ]
    },
    "id": "tRT7UwnXdah0",
    "outputId": "cbc17e9e-2a92-4f71-ea36-dec149a8396b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516eb9116c1f4623a79b54139006ff87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1916 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ebf6c3b8a04dec92530f0e1ae0b236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_encoded = dataset.map(preprocess_function, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RC3PDyxfRSR",
    "outputId": "a05d97a1-0e75-4bd8-ca44-0053ee0a0235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DWA must request DWA acknowledgment flashing when the DWA has assumed the \"armed\" state and the outer skin is closed.\n",
      "[0, 133, 211, 8460, 531, 2069, 211, 8460, 38169, 22643, 77, 5, 211, 8460, 34, 9159, 5, 22, 17651, 113, 194, 8, 5, 15705, 3024, 16, 1367, 4, 2]\n",
      "['<s>', 'The', 'ĠD', 'WA', 'Ġmust', 'Ġrequest', 'ĠD', 'WA', 'Ġacknowledgment', 'Ġflashing', 'Ġwhen', 'Ġthe', 'ĠD', 'WA', 'Ġhas', 'Ġassumed', 'Ġthe', 'Ġ\"', 'armed', '\"', 'Ġstate', 'Ġand', 'Ġthe', 'Ġouter', 'Ġskin', 'Ġis', 'Ġclosed', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_encoded['train']['Requirement Sentences'][0])\n",
    "print(X_train_encoded['train']['input_ids'][0])\n",
    "print(tokenizer.convert_ids_to_tokens(X_train_encoded['train']['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cN4cvC-E6fQu",
    "outputId": "dc14773b-583c-4706-e135-2b286044f00e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1916\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['REQID', 'REQID_expanded', 'Requirement Sentences', 'Open/ Closed Source', 'class', 'signal_keyword', 'Source', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SnG0qKqFgtGU"
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    X_train_encoded['train'],\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size,\n",
    "    tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "tf_valid_dataset = model.prepare_tf_dataset(\n",
    "    X_train_encoded['test'],\n",
    "    shuffle = False,\n",
    "    batch_size = batch_size,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OhEjcWQyg5Lv"
   },
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "num_epochs = 30\n",
    "batches_per_epoch = len(X_train_encoded['train']) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr = 2e-5, num_warmup_steps = 0, num_train_steps = total_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "m69JG3BCg7aL"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    metric1 = evaluate.load(\"precision\")\n",
    "    metric2 = evaluate.load(\"recall\")\n",
    "    metric3 = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "    predictions, labels = eval_predictions\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "\n",
    "    precision = metric1.compute(predictions = predictions, references = labels, average = 'macro')[\"precision\"]\n",
    "    recall = metric2.compute(predictions = predictions, references = labels, average = 'macro')[\"recall\"]\n",
    "    f1 = metric3.compute(predictions = predictions, references = labels, average = 'macro')[\"f1\"]\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "metric_callback = KerasMetricCallback(metric_fn = compute_metrics, eval_dataset = tf_valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2TnaIPRhAFq",
    "outputId": "0f7f6596-c678-4460-ab4c-7280cda1880a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/home/kasra/classification/requirement_detector_model_save is already a clone of https://huggingface.co/kasrahabib/roberta-base-finetuned-iso29148-req-detector. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n"
     ]
    }
   ],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model_name = model_ckpt.split(\"/\")[-1]\n",
    "print(model_name)\n",
    "push_to_hub_model_id = f'{model_name}-finetuned-iso29148-req-detector'\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./requirement_detector_model_save/logs\")\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir = \"./requirement_detector_model_save\",\n",
    "    tokenizer = tokenizer,\n",
    "    hub_model_id = push_to_hub_model_id,\n",
    ")\n",
    "\n",
    "callbacks = [push_to_hub_callback, tensorboard_callback, metric_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8a0cafdc8b6b4452a3d5b751890fbf70",
      "6e9437eee8604d02ad82e730fddd1261",
      "e12e6367e092428d8f422d54ed8f12a5",
      "ddd12b87963545a4a0a91352e760d2d6",
      "fe5dfe56325b4bd9ad5e7de4ddcaa591",
      "01bcd56182dc45a195faa95a5c8d4563",
      "ea178e1fc62b4c0f93dd6570dc66ec4d",
      "d2adca5fafdf4e198ebe7669f25614a6",
      "8cefa68ad6b34475882d02deb1d7dd95",
      "efe461131dd5490db01740bf7c0a7f13",
      "bfee86796ccb4f3594c226da52daea7d",
      "5d54b86e1ea746418341e3e2c08f433e",
      "63b4c446e21b42aebd216122c62ea178",
      "a314f91f87414c4094dc3897f9cde532",
      "cdfefb83b68349fda516226ae082cc10",
      "387f0c53a2b744eca2bd3335191f50f9",
      "62d8e3df70e344ca94e2bb0ee97378fc",
      "67bbe91f4b22422aa419e0663aa80470",
      "f8e665e9d44f4feb938af4a5de37281d",
      "0cad3b78aaac4267947c8a1adcd67868",
      "ebacdd7671264c50bbcbdf963dd0f800",
      "46f5b63f4d17421f9b7c602df2994c3f",
      "4d08e9451f2d41c984681fd5f4d8b743",
      "899599fc878e4ddfb535cce7b9940182",
      "ce0edf70b781464cbbc29ed3b9b8fa8a",
      "681751c762134a00a3e1da2ed08ceb27",
      "11fd4035396046a9a89f8adce9841581",
      "d0d67ff6264c4a65a2b6dc10c056aa47",
      "9f015e06e52447de95b1ce84b2d1c2af",
      "b6cf2ff97c0748b6b232dcbb962efa68",
      "3fc0dbdec19742e69891d50902731b62",
      "60b6e29b7a6648329f3c327cf7eae043",
      "9df8264671f54c00928c94f3943daa50"
     ]
    },
    "id": "LtlqcfYPhOGL",
    "outputId": "73e00738-713c-4ec6-e418-4a280d6fb5b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 19:11:20.486812: I external/local_xla/xla/service/service.cc:168] XLA service 0x7bd188952750 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-09 19:11:20.486853: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-05-09 19:11:20.486863: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-05-09 19:11:20.494859: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-09 19:11:20.522049: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715274680.598352  810694 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 62s 312ms/step - loss: 2.4054 - val_loss: 1.3529 - precision: 0.4290 - recall: 0.4778 - f1: 0.4136\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 1.0479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 48s 403ms/step - loss: 1.0479 - val_loss: 0.6862 - precision: 0.8089 - recall: 0.7682 - f1: 0.7735\n",
      "Epoch 3/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.6251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (3) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 46s 386ms/step - loss: 0.6251 - val_loss: 0.5206 - precision: 0.8480 - recall: 0.7846 - f1: 0.7982\n",
      "Epoch 4/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.4259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (4) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 45s 377ms/step - loss: 0.4259 - val_loss: 0.4428 - precision: 0.8610 - recall: 0.8280 - f1: 0.8371\n",
      "Epoch 5/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.2732"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (5) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 373ms/step - loss: 0.2732 - val_loss: 0.4007 - precision: 0.8691 - recall: 0.8501 - f1: 0.8501\n",
      "Epoch 6/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1769"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (6) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 371ms/step - loss: 0.1769 - val_loss: 0.3710 - precision: 0.8915 - recall: 0.8879 - f1: 0.8870\n",
      "Epoch 7/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.1238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (7) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 371ms/step - loss: 0.1238 - val_loss: 0.3657 - precision: 0.8865 - recall: 0.8753 - f1: 0.8782\n",
      "Epoch 8/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0966"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (8) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 370ms/step - loss: 0.0966 - val_loss: 0.3575 - precision: 0.8909 - recall: 0.8792 - f1: 0.8821\n",
      "Epoch 9/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (9) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 43s 366ms/step - loss: 0.0893 - val_loss: 0.3619 - precision: 0.9031 - recall: 0.8920 - f1: 0.8953\n",
      "Epoch 10/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (10) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 370ms/step - loss: 0.0800 - val_loss: 0.3985 - precision: 0.9008 - recall: 0.8921 - f1: 0.8948\n",
      "Epoch 11/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (11) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 371ms/step - loss: 0.0624 - val_loss: 0.3854 - precision: 0.8982 - recall: 0.8927 - f1: 0.8939\n",
      "Epoch 12/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0630"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (12) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 370ms/step - loss: 0.0630 - val_loss: 0.3802 - precision: 0.9009 - recall: 0.8836 - f1: 0.8903\n",
      "Epoch 13/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0596"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (13) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 371ms/step - loss: 0.0596 - val_loss: 0.3671 - precision: 0.9010 - recall: 0.8908 - f1: 0.8933\n",
      "Epoch 14/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (14) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 370ms/step - loss: 0.0492 - val_loss: 0.4555 - precision: 0.8976 - recall: 0.8730 - f1: 0.8793\n",
      "Epoch 15/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (15) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 374ms/step - loss: 0.0497 - val_loss: 0.3371 - precision: 0.9234 - recall: 0.9208 - f1: 0.9208\n",
      "Epoch 16/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0434"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (16) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 370ms/step - loss: 0.0434 - val_loss: 0.3504 - precision: 0.9030 - recall: 0.9007 - f1: 0.9008\n",
      "Epoch 17/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0450"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (17) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 375ms/step - loss: 0.0450 - val_loss: 0.4149 - precision: 0.8987 - recall: 0.8914 - f1: 0.8927\n",
      "Epoch 18/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0399"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (18) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 368ms/step - loss: 0.0399 - val_loss: 0.4440 - precision: 0.8846 - recall: 0.8785 - f1: 0.8784\n",
      "Epoch 19/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (19) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 368ms/step - loss: 0.0367 - val_loss: 0.4434 - precision: 0.9027 - recall: 0.8912 - f1: 0.8948\n",
      "Epoch 20/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (20) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 369ms/step - loss: 0.0381 - val_loss: 0.4439 - precision: 0.8973 - recall: 0.8818 - f1: 0.8873\n",
      "Epoch 21/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0372"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (21) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 371ms/step - loss: 0.0372 - val_loss: 0.4125 - precision: 0.9080 - recall: 0.9023 - f1: 0.9031\n",
      "Epoch 22/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (22) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 370ms/step - loss: 0.0318 - val_loss: 0.4081 - precision: 0.9012 - recall: 0.8937 - f1: 0.8962\n",
      "Epoch 23/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (23) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 43s 366ms/step - loss: 0.0318 - val_loss: 0.3984 - precision: 0.9078 - recall: 0.9075 - f1: 0.9064\n",
      "Epoch 24/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (24) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 368ms/step - loss: 0.0300 - val_loss: 0.3933 - precision: 0.9109 - recall: 0.9102 - f1: 0.9094\n",
      "Epoch 25/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (25) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 372ms/step - loss: 0.0306 - val_loss: 0.4012 - precision: 0.9030 - recall: 0.9029 - f1: 0.9016\n",
      "Epoch 26/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (26) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 43s 364ms/step - loss: 0.0282 - val_loss: 0.4103 - precision: 0.9056 - recall: 0.9015 - f1: 0.9023\n",
      "Epoch 27/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0263"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (27) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 368ms/step - loss: 0.0263 - val_loss: 0.4319 - precision: 0.9033 - recall: 0.8907 - f1: 0.8949\n",
      "Epoch 28/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0263"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (28) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 43s 366ms/step - loss: 0.0263 - val_loss: 0.4132 - precision: 0.9108 - recall: 0.9059 - f1: 0.9071\n",
      "Epoch 29/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (29) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 43s 366ms/step - loss: 0.0251 - val_loss: 0.4190 - precision: 0.9107 - recall: 0.9015 - f1: 0.9046\n",
      "Epoch 30/30\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.0257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (30) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 44s 370ms/step - loss: 0.0257 - val_loss: 0.4146 - precision: 0.9137 - recall: 0.9086 - f1: 0.9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (31) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "EOF\n",
      "error: failed to push some refs to 'https://huggingface.co/kasrahabib/roberta-base-finetuned-iso29148-req-detector'\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "EOF\nerror: failed to push some refs to 'https://huggingface.co/kasrahabib/roberta-base-finetuned-iso29148-req-detector'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m optimizer)\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_valid_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1229\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1228\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/transformers/keras_callbacks.py:413\u001b[0m, in \u001b[0;36mPushToHubCallback.on_train_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    412\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(model_card)\n\u001b[0;32m--> 413\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnd of training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/huggingface_hub/repository.py:1325\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_add(auto_lfs_track\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_commit(commit_message)\n\u001b[0;32m-> 1325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgit_push\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_branch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/metal-engine/lib/python3.10/site-packages/huggingface_hub/repository.py:1120\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocking:\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstatus_method\u001b[39m():\n",
      "\u001b[0;31mOSError\u001b[0m: EOF\nerror: failed to push some refs to 'https://huggingface.co/kasrahabib/roberta-base-finetuned-iso29148-req-detector'\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = optimizer)\n",
    "history = model.fit(tf_train_dataset, validation_data = (tf_valid_dataset), epochs = num_epochs, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e80c736d5e497b8b8fcfee1a74a68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715274594.iste.810010.0.v2:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2901429592324a60bdec83bfee7a08bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715274665.iste.810516.0.v2:   0%|          | 0.00/3.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bf5cd400104d94bf705b17c46bad8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce8d0b14ae14a2d91baeeae7164157b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1715274710.iste.810516.1.v2:   0%|          | 0.00/4.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45abe271ff04636b7a7ab1c9f4d2d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/kasrahabib/roberta-base-finetuned-iso29148-req-detector/commit/95a8d774cfadb889cd64fdf1f0d017f27d7eaf0f', commit_message='Upload folder using huggingface_hub', commit_description='', oid='95a8d774cfadb889cd64fdf1f0d017f27d7eaf0f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path = \"./requirement_detector_model_save\",\n",
    "    repo_id = \"kasrahabib/\" + push_to_hub_model_id,\n",
    "    repo_type = \"model\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "metal-engine",
   "language": "python",
   "name": "metal-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

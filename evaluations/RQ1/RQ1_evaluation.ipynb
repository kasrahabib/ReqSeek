{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ed1281-7049-4738-ad98-70b94086369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 20:17:39.323177: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-21 20:17:39.323215: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-21 20:17:39.324512: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-21 20:17:39.331360: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-21 20:17:39.917846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# common imports\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../datasets/ARID_supporting_scripts\")\n",
    "\n",
    "import os\n",
    "import random\n",
    "import mapper\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54cd79-ec78-467f-af18-c08c324d9ad3",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80864f2-0e6a-4036-8342-da352f0cc31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset  \n",
    "\n",
    "evaluation_set = datasets.load_from_disk('../datasets/ARID_supporting_scripts/5_1_training_set')['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729a01b9-91a1-47de-a2f8-4205cebaf59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_ = evaluation_set.features['label'].names\n",
    "label2id = {lbl: idx for idx, lbl in enumerate(lbl_)}\n",
    "id2label = {val: key for key, val in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad080d5-7439-428a-9573-8273b5fefe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "    return tokenizer(dataset['Requirement Sentences'], padding = 'max_length', max_length = 256, truncation = True, return_tensors = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c10e92d-652e-49d8-a478-237ff259f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    inputs = {'input_ids': tf.convert_to_tensor(batch['input_ids']),\n",
    "             'attention_mask': tf.convert_to_tensor(batch['attention_mask'])}\n",
    "    true_labels = tf.convert_to_tensor(batch['label'])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model(**inputs)\n",
    "        predicted_labels = tf.argmax(output.logits, axis = -1).numpy()\n",
    "        probas = tf.nn.softmax(output.logits, axis = -1).numpy()\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(true_labels, output.logits)\n",
    "\n",
    "    loss = loss.numpy()\n",
    "\n",
    "    return {\"loss\": loss, \n",
    "            \"y_preds\": [id2label[lbl] for lbl in predicted_labels],\n",
    "            \"y_probas\": [probas[i][predicted_labels[i]] for i in range(len(predicted_labels))]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a468a230-41d9-448a-98b2-19b92a67f4e4",
   "metadata": {},
   "source": [
    "# Benchmark: All Fine-tuned Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be5d4ac5-4f48-46c5-b7da-aa57db549470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('models/benchmark/tuned/reqseek_gpt2_finetuned'),\n",
       " PosixPath('models/benchmark/tuned/reqseek_roberta-base_finetuned'),\n",
       " PosixPath('models/benchmark/tuned/reqseek_bert-base-cased_finetuned'),\n",
       " PosixPath('models/benchmark/tuned/reqseek_all-MiniLM-L6-v2_finetuned')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_benchmark_models_path = Path('./models/benchmark/tuned/')\n",
    "\n",
    "tuned_benchmark_models = [folder for folder in tuned_benchmark_models_path.iterdir() if folder.is_dir() and not folder.name.startswith('.')]\n",
    "tuned_benchmark_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b53c59a-f057-42c3-91a4-fbcde7702c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': PosixPath('models/benchmark/tuned/reqseek_gpt2_finetuned'),\n",
       " 'roberta-base': PosixPath('models/benchmark/tuned/reqseek_roberta-base_finetuned'),\n",
       " 'bert-base-cased': PosixPath('models/benchmark/tuned/reqseek_bert-base-cased_finetuned'),\n",
       " 'all-MiniLM-L6-v2': PosixPath('models/benchmark/tuned/reqseek_all-MiniLM-L6-v2_finetuned')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tuned_models = {}\n",
    "\n",
    "for mdl in tuned_benchmark_models:\n",
    "    split_mdl_id = mdl.name.split('_')\n",
    "    model_name = split_mdl_id[1]\n",
    "    all_tuned_models[model_name] = mdl\n",
    "\n",
    "all_tuned_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3d3f14-8d18-45c5-b8c0-c170dce175a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 20:17:42.083026: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.084915: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.088327: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.089873: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.092634: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.094130: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.340032: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.341631: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.343212: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.344728: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.346255: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.347777: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.377322: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.378900: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.380444: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.381957: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.383490: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.384973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22095 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-03-21 20:17:42.385349: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 20:17:42.386843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 15806 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "All model checkpoint layers were used when initializing TFGPT2ForSequenceClassification.\n",
      "\n",
      "All the layers of TFGPT2ForSequenceClassification were initialized from the model checkpoint at models/benchmark/tuned/reqseek_gpt2_finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2ForSequenceClassification for predictions without further training.\n",
      "/home/kasra/metal-engine/lib/python3.10/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b7d18e82db460296577898ef8a9b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 20:17:45.698530: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at models/benchmark/tuned/reqseek_roberta-base_finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc06465f4786481990ca99a282da0dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at models/benchmark/tuned/reqseek_bert-base-cased_finetuned were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at models/benchmark/tuned/reqseek_bert-base-cased_finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6201e206236d41d48118a533587bf2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at models/benchmark/tuned/reqseek_all-MiniLM-L6-v2_finetuned were not used when initializing TFBertForSequenceClassification: ['dropout_39']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at models/benchmark/tuned/reqseek_all-MiniLM-L6-v2_finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886dfe00517844ddbdf916f8d7247532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "all_tuned_models_prediction = {}\n",
    "\n",
    "for mdl_id in list(all_tuned_models.keys()):\n",
    "    model_path = all_tuned_models[mdl_id]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    if mdl_id == 'gpt2':\n",
    "        if model.config.pad_token_id is None:\n",
    "            print(\"Pad token ID is not set. Setting now...\")\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "            model.config.pad_token_id = tokenizer.pad_token_id\n",
    "            tokenizer.padding_side = \"left\"\n",
    "            print(\"New Pad Token ID set:\", model.config.pad_token_id)\n",
    "    evaluation_set_encoded = evaluation_set.map(preprocess_function, batched = True)\n",
    "    evaluation_set_predicted = evaluation_set_encoded.map(forward_pass_with_label, batched = True, batch_size = 8)        \n",
    "    all_tuned_models_prediction[mdl_id] = evaluation_set_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70441dc1-fa94-4fdf-838d-a0622a50a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(y_true, y_pred, average = 'macro'):\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred, average = average)}\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred, average = average)}\")\n",
    "    print(f\"F1-Score: {f1_score(y_true, y_pred, average = average)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "454f28b9-bb5e-43fd-87d3-3d6e55b7d545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned: Models Performance Benchmark\n",
      "\n",
      "gpt2\n",
      "Precision: 0.6285157843485584\n",
      "Recall: 0.5295238095238095\n",
      "F1-Score: 0.4512597059471009\n",
      "\n",
      "\n",
      "roberta-base\n",
      "Precision: 0.9541119708891043\n",
      "Recall: 0.9517460317460317\n",
      "F1-Score: 0.9528933151427276\n",
      "\n",
      "\n",
      "bert-base-cased\n",
      "Precision: 0.9379420599040573\n",
      "Recall: 0.9319047619047618\n",
      "F1-Score: 0.9347329572480018\n",
      "\n",
      "\n",
      "all-MiniLM-L6-v2\n",
      "Precision: 0.9430809116003013\n",
      "Recall: 0.9322222222222222\n",
      "F1-Score: 0.9369875105206669\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Fine-tuned: Models Performance Benchmark\\n')\n",
    "for key, value in  all_tuned_models_prediction.items():\n",
    "    y_true = mapper.map(value['signal_keyword'])\n",
    "    y_pred = mapper.map(value['y_preds'])\n",
    "    print(key)\n",
    "    evaluate(y_true, y_pred)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab124167-03fc-46fc-9f21-4d2d15f424ba",
   "metadata": {},
   "source": [
    "# Benchmark: All Untuned Baseline Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "091f0680-c2ae-446f-b89e-b65ced0d132e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('models/benchmark/untuned/untuned_gpt2'),\n",
       " PosixPath('models/benchmark/untuned/untuned_roberta-base'),\n",
       " PosixPath('models/benchmark/untuned/untuned_all-MiniLM-L6-v2'),\n",
       " PosixPath('models/benchmark/untuned/untuned_bert-base-cased')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untuned_benchmark_models_path = Path('./training_scripts_and_models/models/untuned/')\n",
    "\n",
    "untuned_benchmark_models = [folder for folder in untuned_benchmark_models_path.iterdir() if folder.is_dir() and not folder.name.startswith('.')]\n",
    "untuned_benchmark_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcd71ebe-bc20-41d3-95af-10fc374970d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': PosixPath('models/benchmark/untuned/untuned_gpt2'),\n",
       " 'roberta-base': PosixPath('models/benchmark/untuned/untuned_roberta-base'),\n",
       " 'all-MiniLM-L6-v2': PosixPath('models/benchmark/untuned/untuned_all-MiniLM-L6-v2'),\n",
       " 'bert-base-cased': PosixPath('models/benchmark/untuned/untuned_bert-base-cased')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_untuned_models = {}\n",
    "\n",
    "for mdl in untuned_benchmark_models:\n",
    "    split_mdl_id = mdl.name.split('_')\n",
    "    model_name = split_mdl_id[1]\n",
    "    all_untuned_models[model_name] = mdl\n",
    "\n",
    "all_untuned_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e39b335e-2dee-415f-9122-8069b3bcd02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2ForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFGPT2ForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token ID is not set. Setting now...\n",
      "New Pad Token ID set: 50256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5868f14c83f04d81ac5a1a141c416101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d6c140f2294259b36894242e3bff02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14e183b97204a4db97127ca2cb779a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c024f5fb99234574bd2b0a49f927e4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "all_untuned_models_prediction = {}\n",
    "\n",
    "for mdl_id in list(all_untuned_models.keys()):\n",
    "    model_path = all_untuned_models[mdl_id]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    if mdl_id == 'gpt2':\n",
    "        if model.config.pad_token_id is None:\n",
    "            print(\"Pad token ID is not set. Setting now...\")\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "            model.config.pad_token_id = tokenizer.pad_token_id\n",
    "            tokenizer.padding_side = \"left\"\n",
    "            print(\"New Pad Token ID set:\", model.config.pad_token_id)\n",
    "    evaluation_set_encoded = evaluation_set.map(preprocess_function, batched = True)\n",
    "    evaluation_set_predicted = evaluation_set_encoded.map(forward_pass_with_label, batched = True, batch_size = 8)        \n",
    "    all_untuned_models_prediction[mdl_id] = evaluation_set_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89373bdb-062a-430a-84cd-68e85de73b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untune: Models Performance Benchmark\n",
      "\n",
      "gpt2\n",
      "Precision: 0.22680812184075774\n",
      "Recall: 0.3337301587301587\n",
      "F1-Score: 0.26973085615332687\n",
      "\n",
      "\n",
      "roberta-base\n",
      "Precision: 0.14583333333333334\n",
      "Recall: 0.3333333333333333\n",
      "F1-Score: 0.2028985507246377\n",
      "\n",
      "\n",
      "all-MiniLM-L6-v2\n",
      "Precision: 0.22465580704858357\n",
      "Recall: 0.32261904761904764\n",
      "F1-Score: 0.16988707593550076\n",
      "\n",
      "\n",
      "bert-base-cased\n",
      "Precision: 0.14583333333333334\n",
      "Recall: 0.3333333333333333\n",
      "F1-Score: 0.2028985507246377\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kasra/metal-engine/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Untune: Models Performance Benchmark\\n')\n",
    "for key, value in  all_untuned_models_prediction.items():\n",
    "    y_true = mapper.map(value['signal_keyword'])\n",
    "    y_pred = mapper.map(value['y_preds'])\n",
    "    print(key)\n",
    "    evaluate(y_true, y_pred)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal-engine",
   "language": "python",
   "name": "metal-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
